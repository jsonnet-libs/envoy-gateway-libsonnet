{
  local d = (import 'doc-util/main.libsonnet'),
  '#':: d.pkg(name='envoyProxy', url='', help='"EnvoyProxy is the schema for the envoyproxies API."'),
  '#metadata':: d.obj(help='"ObjectMeta is metadata that all persisted resources must have, which includes all objects users must create."'),
  metadata: {
    '#withAnnotations':: d.fn(help='"Annotations is an unstructured key value map stored with a resource that may be set by external tools to store and retrieve arbitrary metadata. They are not queryable and should be preserved when modifying objects. More info: http://kubernetes.io/docs/user-guide/annotations"', args=[d.arg(name='annotations', type=d.T.object)]),
    withAnnotations(annotations): { metadata+: { annotations: annotations } },
    '#withAnnotationsMixin':: d.fn(help='"Annotations is an unstructured key value map stored with a resource that may be set by external tools to store and retrieve arbitrary metadata. They are not queryable and should be preserved when modifying objects. More info: http://kubernetes.io/docs/user-guide/annotations"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='annotations', type=d.T.object)]),
    withAnnotationsMixin(annotations): { metadata+: { annotations+: annotations } },
    '#withClusterName':: d.fn(help='"The name of the cluster which the object belongs to. This is used to distinguish resources with same name and namespace in different clusters. This field is not set anywhere right now and apiserver is going to ignore it if set in create or update request."', args=[d.arg(name='clusterName', type=d.T.string)]),
    withClusterName(clusterName): { metadata+: { clusterName: clusterName } },
    '#withCreationTimestamp':: d.fn(help='"Time is a wrapper around time.Time which supports correct marshaling to YAML and JSON.  Wrappers are provided for many of the factory methods that the time package offers."', args=[d.arg(name='creationTimestamp', type=d.T.string)]),
    withCreationTimestamp(creationTimestamp): { metadata+: { creationTimestamp: creationTimestamp } },
    '#withDeletionGracePeriodSeconds':: d.fn(help='"Number of seconds allowed for this object to gracefully terminate before it will be removed from the system. Only set when deletionTimestamp is also set. May only be shortened. Read-only."', args=[d.arg(name='deletionGracePeriodSeconds', type=d.T.integer)]),
    withDeletionGracePeriodSeconds(deletionGracePeriodSeconds): { metadata+: { deletionGracePeriodSeconds: deletionGracePeriodSeconds } },
    '#withDeletionTimestamp':: d.fn(help='"Time is a wrapper around time.Time which supports correct marshaling to YAML and JSON.  Wrappers are provided for many of the factory methods that the time package offers."', args=[d.arg(name='deletionTimestamp', type=d.T.string)]),
    withDeletionTimestamp(deletionTimestamp): { metadata+: { deletionTimestamp: deletionTimestamp } },
    '#withFinalizers':: d.fn(help='"Must be empty before the object is deleted from the registry. Each entry is an identifier for the responsible component that will remove the entry from the list. If the deletionTimestamp of the object is non-nil, entries in this list can only be removed. Finalizers may be processed and removed in any order.  Order is NOT enforced because it introduces significant risk of stuck finalizers. finalizers is a shared field, any actor with permission can reorder it. If the finalizer list is processed in order, then this can lead to a situation in which the component responsible for the first finalizer in the list is waiting for a signal (field value, external system, or other) produced by a component responsible for a finalizer later in the list, resulting in a deadlock. Without enforced ordering finalizers are free to order amongst themselves and are not vulnerable to ordering changes in the list."', args=[d.arg(name='finalizers', type=d.T.array)]),
    withFinalizers(finalizers): { metadata+: { finalizers: if std.isArray(v=finalizers) then finalizers else [finalizers] } },
    '#withFinalizersMixin':: d.fn(help='"Must be empty before the object is deleted from the registry. Each entry is an identifier for the responsible component that will remove the entry from the list. If the deletionTimestamp of the object is non-nil, entries in this list can only be removed. Finalizers may be processed and removed in any order.  Order is NOT enforced because it introduces significant risk of stuck finalizers. finalizers is a shared field, any actor with permission can reorder it. If the finalizer list is processed in order, then this can lead to a situation in which the component responsible for the first finalizer in the list is waiting for a signal (field value, external system, or other) produced by a component responsible for a finalizer later in the list, resulting in a deadlock. Without enforced ordering finalizers are free to order amongst themselves and are not vulnerable to ordering changes in the list."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='finalizers', type=d.T.array)]),
    withFinalizersMixin(finalizers): { metadata+: { finalizers+: if std.isArray(v=finalizers) then finalizers else [finalizers] } },
    '#withGenerateName':: d.fn(help='"GenerateName is an optional prefix, used by the server, to generate a unique name ONLY IF the Name field has not been provided. If this field is used, the name returned to the client will be different than the name passed. This value will also be combined with a unique suffix. The provided value has the same validation rules as the Name field, and may be truncated by the length of the suffix required to make the value unique on the server.\\n\\nIf this field is specified and the generated name exists, the server will NOT return a 409 - instead, it will either return 201 Created or 500 with Reason ServerTimeout indicating a unique name could not be found in the time allotted, and the client should retry (optionally after the time indicated in the Retry-After header).\\n\\nApplied only if Name is not specified. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency"', args=[d.arg(name='generateName', type=d.T.string)]),
    withGenerateName(generateName): { metadata+: { generateName: generateName } },
    '#withGeneration':: d.fn(help='"A sequence number representing a specific generation of the desired state. Populated by the system. Read-only."', args=[d.arg(name='generation', type=d.T.integer)]),
    withGeneration(generation): { metadata+: { generation: generation } },
    '#withLabels':: d.fn(help='"Map of string keys and values that can be used to organize and categorize (scope and select) objects. May match selectors of replication controllers and services. More info: http://kubernetes.io/docs/user-guide/labels"', args=[d.arg(name='labels', type=d.T.object)]),
    withLabels(labels): { metadata+: { labels: labels } },
    '#withLabelsMixin':: d.fn(help='"Map of string keys and values that can be used to organize and categorize (scope and select) objects. May match selectors of replication controllers and services. More info: http://kubernetes.io/docs/user-guide/labels"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labels', type=d.T.object)]),
    withLabelsMixin(labels): { metadata+: { labels+: labels } },
    '#withName':: d.fn(help='"Name must be unique within a namespace. Is required when creating resources, although some resources may allow a client to request the generation of an appropriate name automatically. Name is primarily intended for creation idempotence and configuration definition. Cannot be updated. More info: http://kubernetes.io/docs/user-guide/identifiers#names"', args=[d.arg(name='name', type=d.T.string)]),
    withName(name): { metadata+: { name: name } },
    '#withNamespace':: d.fn(help='"Namespace defines the space within which each name must be unique. An empty namespace is equivalent to the \\"default\\" namespace, but \\"default\\" is the canonical representation. Not all objects are required to be scoped to a namespace - the value of this field for those objects will be empty.\\n\\nMust be a DNS_LABEL. Cannot be updated. More info: http://kubernetes.io/docs/user-guide/namespaces"', args=[d.arg(name='namespace', type=d.T.string)]),
    withNamespace(namespace): { metadata+: { namespace: namespace } },
    '#withOwnerReferences':: d.fn(help='"List of objects depended by this object. If ALL objects in the list have been deleted, this object will be garbage collected. If this object is managed by a controller, then an entry in this list will point to this controller, with the controller field set to true. There cannot be more than one managing controller."', args=[d.arg(name='ownerReferences', type=d.T.array)]),
    withOwnerReferences(ownerReferences): { metadata+: { ownerReferences: if std.isArray(v=ownerReferences) then ownerReferences else [ownerReferences] } },
    '#withOwnerReferencesMixin':: d.fn(help='"List of objects depended by this object. If ALL objects in the list have been deleted, this object will be garbage collected. If this object is managed by a controller, then an entry in this list will point to this controller, with the controller field set to true. There cannot be more than one managing controller."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='ownerReferences', type=d.T.array)]),
    withOwnerReferencesMixin(ownerReferences): { metadata+: { ownerReferences+: if std.isArray(v=ownerReferences) then ownerReferences else [ownerReferences] } },
    '#withResourceVersion':: d.fn(help='"An opaque value that represents the internal version of this object that can be used by clients to determine when objects have changed. May be used for optimistic concurrency, change detection, and the watch operation on a resource or set of resources. Clients must treat these values as opaque and passed unmodified back to the server. They may only be valid for a particular resource or set of resources.\\n\\nPopulated by the system. Read-only. Value must be treated as opaque by clients and . More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency"', args=[d.arg(name='resourceVersion', type=d.T.string)]),
    withResourceVersion(resourceVersion): { metadata+: { resourceVersion: resourceVersion } },
    '#withSelfLink':: d.fn(help='"SelfLink is a URL representing this object. Populated by the system. Read-only.\\n\\nDEPRECATED Kubernetes will stop propagating this field in 1.20 release and the field is planned to be removed in 1.21 release."', args=[d.arg(name='selfLink', type=d.T.string)]),
    withSelfLink(selfLink): { metadata+: { selfLink: selfLink } },
    '#withUid':: d.fn(help='"UID is the unique in time and space value for this object. It is typically generated by the server on successful creation of a resource and is not allowed to change on PUT operations.\\n\\nPopulated by the system. Read-only. More info: http://kubernetes.io/docs/user-guide/identifiers#uids"', args=[d.arg(name='uid', type=d.T.string)]),
    withUid(uid): { metadata+: { uid: uid } },
  },
  '#new':: d.fn(help='new returns an instance of EnvoyProxy', args=[d.arg(name='name', type=d.T.string)]),
  new(name): {
    apiVersion: 'gateway.envoyproxy.io/v1alpha1',
    kind: 'EnvoyProxy',
  } + self.metadata.withName(name=name),
  '#spec':: d.obj(help='"EnvoyProxySpec defines the desired state of EnvoyProxy."'),
  spec: {
    '#backendTLS':: d.obj(help='"BackendTLS is the TLS configuration for the Envoy proxy to use when connecting to backends.\\nThese settings are applied on backends for which TLS policies are specified."'),
    backendTLS: {
      '#clientCertificateRef':: d.obj(help='"ClientCertificateRef defines the reference to a Kubernetes Secret that contains\\nthe client certificate and private key for Envoy to use when connecting to\\nbackend services and external services, such as ExtAuth, ALS, OpenTelemetry, etc.\\nThis secret should be located within the same namespace as the Envoy proxy resource that references it."'),
      clientCertificateRef: {
        '#withGroup':: d.fn(help='"Group is the group of the referent. For example, \\"gateway.networking.k8s.io\\".\\nWhen unspecified or empty string, core API group is inferred."', args=[d.arg(name='group', type=d.T.string)]),
        withGroup(group): { spec+: { backendTLS+: { clientCertificateRef+: { group: group } } } },
        '#withKind':: d.fn(help='"Kind is kind of the referent. For example \\"Secret\\"."', args=[d.arg(name='kind', type=d.T.string)]),
        withKind(kind): { spec+: { backendTLS+: { clientCertificateRef+: { kind: kind } } } },
        '#withName':: d.fn(help='"Name is the name of the referent."', args=[d.arg(name='name', type=d.T.string)]),
        withName(name): { spec+: { backendTLS+: { clientCertificateRef+: { name: name } } } },
        '#withNamespace':: d.fn(help="\"Namespace is the namespace of the referenced object. When unspecified, the local\\nnamespace is inferred.\\n\\nNote that when a namespace different than the local namespace is specified,\\na ReferenceGrant object is required in the referent namespace to allow that\\nnamespace's owner to accept the reference. See the ReferenceGrant\\ndocumentation for details.\\n\\nSupport: Core\"", args=[d.arg(name='namespace', type=d.T.string)]),
        withNamespace(namespace): { spec+: { backendTLS+: { clientCertificateRef+: { namespace: namespace } } } },
      },
      '#withAlpnProtocols':: d.fn(help='"ALPNProtocols supplies the list of ALPN protocols that should be\\nexposed by the listener or used by the proxy to connect to the backend.\\nDefaults:\\n1. HTTPS Routes: h2 and http/1.1 are enabled in listener context.\\n2. Other Routes: ALPN is disabled.\\n3. Backends: proxy uses the appropriate ALPN options for the backend protocol.\\nWhen an empty list is provided, the ALPN TLS extension is disabled.\\nSupported values are:\\n- http/1.0\\n- http/1.1\\n- h2"', args=[d.arg(name='alpnProtocols', type=d.T.array)]),
      withAlpnProtocols(alpnProtocols): { spec+: { backendTLS+: { alpnProtocols: if std.isArray(v=alpnProtocols) then alpnProtocols else [alpnProtocols] } } },
      '#withAlpnProtocolsMixin':: d.fn(help='"ALPNProtocols supplies the list of ALPN protocols that should be\\nexposed by the listener or used by the proxy to connect to the backend.\\nDefaults:\\n1. HTTPS Routes: h2 and http/1.1 are enabled in listener context.\\n2. Other Routes: ALPN is disabled.\\n3. Backends: proxy uses the appropriate ALPN options for the backend protocol.\\nWhen an empty list is provided, the ALPN TLS extension is disabled.\\nSupported values are:\\n- http/1.0\\n- http/1.1\\n- h2"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='alpnProtocols', type=d.T.array)]),
      withAlpnProtocolsMixin(alpnProtocols): { spec+: { backendTLS+: { alpnProtocols+: if std.isArray(v=alpnProtocols) then alpnProtocols else [alpnProtocols] } } },
      '#withCiphers':: d.fn(help='"Ciphers specifies the set of cipher suites supported when\\nnegotiating TLS 1.0 - 1.2. This setting has no effect for TLS 1.3.\\nIn non-FIPS Envoy Proxy builds the default cipher list is:\\n- [ECDHE-ECDSA-AES128-GCM-SHA256|ECDHE-ECDSA-CHACHA20-POLY1305]\\n- [ECDHE-RSA-AES128-GCM-SHA256|ECDHE-RSA-CHACHA20-POLY1305]\\n- ECDHE-ECDSA-AES256-GCM-SHA384\\n- ECDHE-RSA-AES256-GCM-SHA384\\nIn builds using BoringSSL FIPS the default cipher list is:\\n- ECDHE-ECDSA-AES128-GCM-SHA256\\n- ECDHE-RSA-AES128-GCM-SHA256\\n- ECDHE-ECDSA-AES256-GCM-SHA384\\n- ECDHE-RSA-AES256-GCM-SHA384"', args=[d.arg(name='ciphers', type=d.T.array)]),
      withCiphers(ciphers): { spec+: { backendTLS+: { ciphers: if std.isArray(v=ciphers) then ciphers else [ciphers] } } },
      '#withCiphersMixin':: d.fn(help='"Ciphers specifies the set of cipher suites supported when\\nnegotiating TLS 1.0 - 1.2. This setting has no effect for TLS 1.3.\\nIn non-FIPS Envoy Proxy builds the default cipher list is:\\n- [ECDHE-ECDSA-AES128-GCM-SHA256|ECDHE-ECDSA-CHACHA20-POLY1305]\\n- [ECDHE-RSA-AES128-GCM-SHA256|ECDHE-RSA-CHACHA20-POLY1305]\\n- ECDHE-ECDSA-AES256-GCM-SHA384\\n- ECDHE-RSA-AES256-GCM-SHA384\\nIn builds using BoringSSL FIPS the default cipher list is:\\n- ECDHE-ECDSA-AES128-GCM-SHA256\\n- ECDHE-RSA-AES128-GCM-SHA256\\n- ECDHE-ECDSA-AES256-GCM-SHA384\\n- ECDHE-RSA-AES256-GCM-SHA384"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='ciphers', type=d.T.array)]),
      withCiphersMixin(ciphers): { spec+: { backendTLS+: { ciphers+: if std.isArray(v=ciphers) then ciphers else [ciphers] } } },
      '#withEcdhCurves':: d.fn(help='"ECDHCurves specifies the set of supported ECDH curves.\\nIn non-FIPS Envoy Proxy builds the default curves are:\\n- X25519\\n- P-256\\nIn builds using BoringSSL FIPS the default curve is:\\n- P-256"', args=[d.arg(name='ecdhCurves', type=d.T.array)]),
      withEcdhCurves(ecdhCurves): { spec+: { backendTLS+: { ecdhCurves: if std.isArray(v=ecdhCurves) then ecdhCurves else [ecdhCurves] } } },
      '#withEcdhCurvesMixin':: d.fn(help='"ECDHCurves specifies the set of supported ECDH curves.\\nIn non-FIPS Envoy Proxy builds the default curves are:\\n- X25519\\n- P-256\\nIn builds using BoringSSL FIPS the default curve is:\\n- P-256"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='ecdhCurves', type=d.T.array)]),
      withEcdhCurvesMixin(ecdhCurves): { spec+: { backendTLS+: { ecdhCurves+: if std.isArray(v=ecdhCurves) then ecdhCurves else [ecdhCurves] } } },
      '#withMaxVersion':: d.fn(help='"Max specifies the maximal TLS protocol version to allow\\nThe default is TLS 1.3 if this is not specified."', args=[d.arg(name='maxVersion', type=d.T.string)]),
      withMaxVersion(maxVersion): { spec+: { backendTLS+: { maxVersion: maxVersion } } },
      '#withMinVersion':: d.fn(help='"Min specifies the minimal TLS protocol version to allow.\\nThe default is TLS 1.2 if this is not specified."', args=[d.arg(name='minVersion', type=d.T.string)]),
      withMinVersion(minVersion): { spec+: { backendTLS+: { minVersion: minVersion } } },
      '#withSignatureAlgorithms':: d.fn(help='"SignatureAlgorithms specifies which signature algorithms the listener should\\nsupport."', args=[d.arg(name='signatureAlgorithms', type=d.T.array)]),
      withSignatureAlgorithms(signatureAlgorithms): { spec+: { backendTLS+: { signatureAlgorithms: if std.isArray(v=signatureAlgorithms) then signatureAlgorithms else [signatureAlgorithms] } } },
      '#withSignatureAlgorithmsMixin':: d.fn(help='"SignatureAlgorithms specifies which signature algorithms the listener should\\nsupport."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='signatureAlgorithms', type=d.T.array)]),
      withSignatureAlgorithmsMixin(signatureAlgorithms): { spec+: { backendTLS+: { signatureAlgorithms+: if std.isArray(v=signatureAlgorithms) then signatureAlgorithms else [signatureAlgorithms] } } },
    },
    '#bootstrap':: d.obj(help='"Bootstrap defines the Envoy Bootstrap as a YAML string.\\nVisit https://www.envoyproxy.io/docs/envoy/latest/api-v3/config/bootstrap/v3/bootstrap.proto#envoy-v3-api-msg-config-bootstrap-v3-bootstrap\\nto learn more about the syntax.\\nIf set, this is the Bootstrap configuration used for the managed Envoy Proxy fleet instead of the default Bootstrap configuration\\nset by Envoy Gateway.\\nSome fields within the Bootstrap that are required to communicate with the xDS Server (Envoy Gateway) and receive xDS resources\\nfrom it are not configurable and will result in the `EnvoyProxy` resource being rejected.\\nBackward compatibility across minor versions is not guaranteed.\\nWe strongly recommend using `egctl x translate` to generate a `EnvoyProxy` resource with the `Bootstrap` field set to the default\\nBootstrap configuration used. You can edit this configuration, and rerun `egctl x translate` to ensure there are no validation errors."'),
    bootstrap: {
      '#jsonPatches':: d.obj(help='"JSONPatches is an array of JSONPatches to be applied to the default bootstrap. Patches are\\napplied in the order in which they are defined."'),
      jsonPatches: {
        '#withFrom':: d.fn(help='"From is the source location of the value to be copied or moved. Only valid\\nfor move or copy operations\\nRefer to https://datatracker.ietf.org/doc/html/rfc6901 for more details."', args=[d.arg(name='from', type=d.T.string)]),
        withFrom(from): { from: from },
        '#withJsonPath':: d.fn(help="\"JSONPath is a JSONPath expression. Refer to https://datatracker.ietf.org/doc/rfc9535/ for more details.\\nIt produces one or more JSONPointer expressions based on the given JSON document.\\nIf no JSONPointer is found, it will result in an error.\\nIf the 'Path' property is also set, it will be appended to the resulting JSONPointer expressions from the JSONPath evaluation.\\nThis is useful when creating a property that does not yet exist in the JSON document.\\nThe final JSONPointer expressions specifies the locations in the target document/field where the operation will be applied.\"", args=[d.arg(name='jsonPath', type=d.T.string)]),
        withJsonPath(jsonPath): { jsonPath: jsonPath },
        '#withOp':: d.fn(help='"Op is the type of operation to perform"', args=[d.arg(name='op', type=d.T.string)]),
        withOp(op): { op: op },
        '#withPath':: d.fn(help='"Path is a JSONPointer expression. Refer to https://datatracker.ietf.org/doc/html/rfc6901 for more details.\\nIt specifies the location of the target document/field where the operation will be performed"', args=[d.arg(name='path', type=d.T.string)]),
        withPath(path): { path: path },
        '#withValue':: d.fn(help='"Value is the new value of the path location. The value is only used by\\nthe `add` and `replace` operations."', args=[d.arg(name='value', type=d.T.any)]),
        withValue(value): { value: value },
      },
      '#withJsonPatches':: d.fn(help='"JSONPatches is an array of JSONPatches to be applied to the default bootstrap. Patches are\\napplied in the order in which they are defined."', args=[d.arg(name='jsonPatches', type=d.T.array)]),
      withJsonPatches(jsonPatches): { spec+: { bootstrap+: { jsonPatches: if std.isArray(v=jsonPatches) then jsonPatches else [jsonPatches] } } },
      '#withJsonPatchesMixin':: d.fn(help='"JSONPatches is an array of JSONPatches to be applied to the default bootstrap. Patches are\\napplied in the order in which they are defined."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='jsonPatches', type=d.T.array)]),
      withJsonPatchesMixin(jsonPatches): { spec+: { bootstrap+: { jsonPatches+: if std.isArray(v=jsonPatches) then jsonPatches else [jsonPatches] } } },
      '#withType':: d.fn(help='"Type is the type of the bootstrap configuration, it should be either **Replace**,  **Merge**, or **JSONPatch**.\\nIf unspecified, it defaults to Replace."', args=[d.arg(name='type', type=d.T.string)]),
      withType(type): { spec+: { bootstrap+: { type: type } } },
      '#withValue':: d.fn(help='"Value is a YAML string of the bootstrap."', args=[d.arg(name='value', type=d.T.string)]),
      withValue(value): { spec+: { bootstrap+: { value: value } } },
    },
    '#filterOrder':: d.obj(help="\"FilterOrder defines the order of filters in the Envoy proxy's HTTP filter chain.\\nThe FilterPosition in the list will be applied in the order they are defined.\\nIf unspecified, the default filter order is applied.\\nDefault filter order is:\\n\\n- envoy.filters.http.health_check\\n\\n- envoy.filters.http.fault\\n\\n- envoy.filters.http.cors\\n\\n- envoy.filters.http.ext_authz\\n\\n- envoy.filters.http.basic_auth\\n\\n- envoy.filters.http.oauth2\\n\\n- envoy.filters.http.jwt_authn\\n\\n- envoy.filters.http.stateful_session\\n\\n- envoy.filters.http.lua\\n\\n- envoy.filters.http.ext_proc\\n\\n- envoy.filters.http.wasm\\n\\n- envoy.filters.http.rbac\\n\\n- envoy.filters.http.local_ratelimit\\n\\n- envoy.filters.http.ratelimit\\n\\n- envoy.filters.http.custom_response\\n\\n- envoy.filters.http.router\\n\\nNote: \\\"envoy.filters.http.router\\\" cannot be reordered, it's always the last filter in the chain.\""),
    filterOrder: {
      '#withAfter':: d.fn(help='"After defines the filter that should come after the filter.\\nOnly one of Before or After must be set."', args=[d.arg(name='after', type=d.T.string)]),
      withAfter(after): { after: after },
      '#withBefore':: d.fn(help='"Before defines the filter that should come before the filter.\\nOnly one of Before or After must be set."', args=[d.arg(name='before', type=d.T.string)]),
      withBefore(before): { before: before },
      '#withName':: d.fn(help='"Name of the filter."', args=[d.arg(name='name', type=d.T.string)]),
      withName(name): { name: name },
    },
    '#logging':: d.obj(help='"Logging defines logging parameters for managed proxies."'),
    logging: {
      '#withLevel':: d.fn(help='"Level is a map of logging level per component, where the component is the key\\nand the log level is the value. If unspecified, defaults to \\"default: warn\\"."', args=[d.arg(name='level', type=d.T.object)]),
      withLevel(level): { spec+: { logging+: { level: level } } },
      '#withLevelMixin':: d.fn(help='"Level is a map of logging level per component, where the component is the key\\nand the log level is the value. If unspecified, defaults to \\"default: warn\\"."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='level', type=d.T.object)]),
      withLevelMixin(level): { spec+: { logging+: { level+: level } } },
    },
    '#provider':: d.obj(help='"Provider defines the desired resource provider and provider-specific configuration.\\nIf unspecified, the \\"Kubernetes\\" resource provider is used with default configuration\\nparameters."'),
    provider: {
      '#kubernetes':: d.obj(help='"Kubernetes defines the desired state of the Kubernetes resource provider.\\nKubernetes provides infrastructure resources for running the data plane,\\ne.g. Envoy proxy. If unspecified and type is \\"Kubernetes\\", default settings\\nfor managed Kubernetes resources are applied."'),
      kubernetes: {
        '#envoyDaemonSet':: d.obj(help='"EnvoyDaemonSet defines the desired state of the Envoy daemonset resource.\\nDisabled by default, a deployment resource is used instead to provision the Envoy Proxy fleet"'),
        envoyDaemonSet: {
          '#container':: d.obj(help='"Container defines the desired specification of main container."'),
          container: {
            '#env':: d.obj(help='"List of environment variables to set in the container."'),
            env: {
              '#valueFrom':: d.obj(help="\"Source for the environment variable's value. Cannot be used if value is not empty.\""),
              valueFrom: {
                '#configMapKeyRef':: d.obj(help='"Selects a key of a ConfigMap."'),
                configMapKeyRef: {
                  '#withKey':: d.fn(help='"The key to select."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { valueFrom+: { configMapKeyRef+: { key: key } } },
                  '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
                  withName(name): { valueFrom+: { configMapKeyRef+: { name: name } } },
                  '#withOptional':: d.fn(help='"Specify whether the ConfigMap or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
                  withOptional(optional): { valueFrom+: { configMapKeyRef+: { optional: optional } } },
                },
                '#fieldRef':: d.obj(help="\"Selects a field of the pod: supports metadata.name, metadata.namespace, `metadata.labels['\u003cKEY\u003e']`, `metadata.annotations['\u003cKEY\u003e']`,\\nspec.nodeName, spec.serviceAccountName, status.hostIP, status.podIP, status.podIPs.\""),
                fieldRef: {
                  '#withApiVersion':: d.fn(help='"Version of the schema the FieldPath is written in terms of, defaults to \\"v1\\"."', args=[d.arg(name='apiVersion', type=d.T.string)]),
                  withApiVersion(apiVersion): { valueFrom+: { fieldRef+: { apiVersion: apiVersion } } },
                  '#withFieldPath':: d.fn(help='"Path of the field to select in the specified API version."', args=[d.arg(name='fieldPath', type=d.T.string)]),
                  withFieldPath(fieldPath): { valueFrom+: { fieldRef+: { fieldPath: fieldPath } } },
                },
                '#resourceFieldRef':: d.obj(help='"Selects a resource of the container: only resources limits and requests\\n(limits.cpu, limits.memory, limits.ephemeral-storage, requests.cpu, requests.memory and requests.ephemeral-storage) are currently supported."'),
                resourceFieldRef: {
                  '#withContainerName':: d.fn(help='"Container name: required for volumes, optional for env vars"', args=[d.arg(name='containerName', type=d.T.string)]),
                  withContainerName(containerName): { valueFrom+: { resourceFieldRef+: { containerName: containerName } } },
                  '#withDivisor':: d.fn(help='"Specifies the output format of the exposed resources, defaults to \\"1\\', args=[d.arg(name='divisor', type=d.T.any)]),
                  withDivisor(divisor): { valueFrom+: { resourceFieldRef+: { divisor: divisor } } },
                  '#withResource':: d.fn(help='"Required: resource to select"', args=[d.arg(name='resource', type=d.T.string)]),
                  withResource(resource): { valueFrom+: { resourceFieldRef+: { resource: resource } } },
                },
                '#secretKeyRef':: d.obj(help="\"Selects a key of a secret in the pod's namespace\""),
                secretKeyRef: {
                  '#withKey':: d.fn(help='"The key of the secret to select from.  Must be a valid secret key."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { valueFrom+: { secretKeyRef+: { key: key } } },
                  '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
                  withName(name): { valueFrom+: { secretKeyRef+: { name: name } } },
                  '#withOptional':: d.fn(help='"Specify whether the Secret or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
                  withOptional(optional): { valueFrom+: { secretKeyRef+: { optional: optional } } },
                },
              },
              '#withName':: d.fn(help='"Name of the environment variable. Must be a C_IDENTIFIER."', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { name: name },
              '#withValue':: d.fn(help='"Variable references $(VAR_NAME) are expanded\\nusing the previously defined environment variables in the container and\\nany service environment variables. If a variable cannot be resolved,\\nthe reference in the input string will be unchanged. Double $$ are reduced\\nto a single $, which allows for escaping the $(VAR_NAME) syntax: i.e.\\n\\"$$(VAR_NAME)\\" will produce the string literal \\"$(VAR_NAME)\\".\\nEscaped references will never be expanded, regardless of whether the variable\\nexists or not.\\nDefaults to \\"\\"."', args=[d.arg(name='value', type=d.T.string)]),
              withValue(value): { value: value },
            },
            '#resources':: d.obj(help='"Resources required by this container.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"'),
            resources: {
              '#claims':: d.obj(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis is an alpha field and requires enabling the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."'),
              claims: {
                '#withName':: d.fn(help='"Name must match the name of one entry in pod.spec.resourceClaims of\\nthe Pod where this field is used. It makes that resource available\\ninside a container."', args=[d.arg(name='name', type=d.T.string)]),
                withName(name): { name: name },
                '#withRequest':: d.fn(help='"Request is the name chosen for a request in the referenced claim.\\nIf empty, everything from the claim is made available, otherwise\\nonly the result of this request."', args=[d.arg(name='request', type=d.T.string)]),
                withRequest(request): { request: request },
              },
              '#withClaims':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis is an alpha field and requires enabling the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."', args=[d.arg(name='claims', type=d.T.array)]),
              withClaims(claims): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { container+: { resources+: { claims: if std.isArray(v=claims) then claims else [claims] } } } } } } },
              '#withClaimsMixin':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis is an alpha field and requires enabling the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='claims', type=d.T.array)]),
              withClaimsMixin(claims): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { container+: { resources+: { claims+: if std.isArray(v=claims) then claims else [claims] } } } } } } },
              '#withLimits':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='limits', type=d.T.object)]),
              withLimits(limits): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { container+: { resources+: { limits: limits } } } } } } },
              '#withLimitsMixin':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='limits', type=d.T.object)]),
              withLimitsMixin(limits): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { container+: { resources+: { limits+: limits } } } } } } },
              '#withRequests':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='requests', type=d.T.object)]),
              withRequests(requests): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { container+: { resources+: { requests: requests } } } } } } },
              '#withRequestsMixin':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requests', type=d.T.object)]),
              withRequestsMixin(requests): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { container+: { resources+: { requests+: requests } } } } } } },
            },
            '#securityContext':: d.obj(help='"SecurityContext defines the security options the container should be run with.\\nIf set, the fields of SecurityContext override the equivalent fields of PodSecurityContext.\\nMore info: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/"'),
            securityContext: {
              '#appArmorProfile':: d.obj(help="\"appArmorProfile is the AppArmor options to use by this container. If set, this profile\\noverrides the pod's appArmorProfile.\\nNote that this field cannot be set when spec.os.name is windows.\""),
              appArmorProfile: {
                '#withLocalhostProfile':: d.fn(help='"localhostProfile indicates a profile loaded on the node that should be used.\\nThe profile must be preconfigured on the node to work.\\nMust match the loaded name of the profile.\\nMust be set if and only if type is \\"Localhost\\"."', args=[d.arg(name='localhostProfile', type=d.T.string)]),
                withLocalhostProfile(localhostProfile): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { container+: { securityContext+: { appArmorProfile+: { localhostProfile: localhostProfile } } } } } } } },
                '#withType':: d.fn(help="\"type indicates which kind of AppArmor profile will be applied.\\nValid options are:\\n  Localhost - a profile pre-loaded on the node.\\n  RuntimeDefault - the container runtime's default profile.\\n  Unconfined - no AppArmor enforcement.\"", args=[d.arg(name='type', type=d.T.string)]),
                withType(type): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { container+: { securityContext+: { appArmorProfile+: { type: type } } } } } } } },
              },
              '#capabilities':: d.obj(help='"The capabilities to add/drop when running containers.\\nDefaults to the default set of capabilities granted by the container runtime.\\nNote that this field cannot be set when spec.os.name is windows."'),
              capabilities: {
                '#withAdd':: d.fn(help='"Added capabilities"', args=[d.arg(name='add', type=d.T.array)]),
                withAdd(add): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { container+: { securityContext+: { capabilities+: { add: if std.isArray(v=add) then add else [add] } } } } } } } },
                '#withAddMixin':: d.fn(help='"Added capabilities"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='add', type=d.T.array)]),
                withAddMixin(add): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { container+: { securityContext+: { capabilities+: { add+: if std.isArray(v=add) then add else [add] } } } } } } } },
                '#withDrop':: d.fn(help='"Removed capabilities"', args=[d.arg(name='drop', type=d.T.array)]),
                withDrop(drop): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { container+: { securityContext+: { capabilities+: { drop: if std.isArray(v=drop) then drop else [drop] } } } } } } } },
                '#withDropMixin':: d.fn(help='"Removed capabilities"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='drop', type=d.T.array)]),
                withDropMixin(drop): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { container+: { securityContext+: { capabilities+: { drop+: if std.isArray(v=drop) then drop else [drop] } } } } } } } },
              },
              '#seLinuxOptions':: d.obj(help='"The SELinux context to be applied to the container.\\nIf unspecified, the container runtime will allocate a random SELinux context for each\\ncontainer.  May also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is windows."'),
              seLinuxOptions: {
                '#withLevel':: d.fn(help='"Level is SELinux level label that applies to the container."', args=[d.arg(name='level', type=d.T.string)]),
                withLevel(level): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { container+: { securityContext+: { seLinuxOptions+: { level: level } } } } } } } },
                '#withRole':: d.fn(help='"Role is a SELinux role label that applies to the container."', args=[d.arg(name='role', type=d.T.string)]),
                withRole(role): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { container+: { securityContext+: { seLinuxOptions+: { role: role } } } } } } } },
                '#withType':: d.fn(help='"Type is a SELinux type label that applies to the container."', args=[d.arg(name='type', type=d.T.string)]),
                withType(type): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { container+: { securityContext+: { seLinuxOptions+: { type: type } } } } } } } },
                '#withUser':: d.fn(help='"User is a SELinux user label that applies to the container."', args=[d.arg(name='user', type=d.T.string)]),
                withUser(user): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { container+: { securityContext+: { seLinuxOptions+: { user: user } } } } } } } },
              },
              '#seccompProfile':: d.obj(help='"The seccomp options to use by this container. If seccomp options are\\nprovided at both the pod & container level, the container options\\noverride the pod options.\\nNote that this field cannot be set when spec.os.name is windows."'),
              seccompProfile: {
                '#withLocalhostProfile':: d.fn(help="\"localhostProfile indicates a profile defined in a file on the node should be used.\\nThe profile must be preconfigured on the node to work.\\nMust be a descending path, relative to the kubelet's configured seccomp profile location.\\nMust be set if type is \\\"Localhost\\\". Must NOT be set for any other type.\"", args=[d.arg(name='localhostProfile', type=d.T.string)]),
                withLocalhostProfile(localhostProfile): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { container+: { securityContext+: { seccompProfile+: { localhostProfile: localhostProfile } } } } } } } },
                '#withType':: d.fn(help='"type indicates which kind of seccomp profile will be applied.\\nValid options are:\\n\\nLocalhost - a profile defined in a file on the node should be used.\\nRuntimeDefault - the container runtime default profile should be used.\\nUnconfined - no profile should be applied."', args=[d.arg(name='type', type=d.T.string)]),
                withType(type): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { container+: { securityContext+: { seccompProfile+: { type: type } } } } } } } },
              },
              '#windowsOptions':: d.obj(help='"The Windows specific settings applied to all containers.\\nIf unspecified, the options from the PodSecurityContext will be used.\\nIf set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is linux."'),
              windowsOptions: {
                '#withGmsaCredentialSpec':: d.fn(help='"GMSACredentialSpec is where the GMSA admission webhook\\n(https://github.com/kubernetes-sigs/windows-gmsa) inlines the contents of the\\nGMSA credential spec named by the GMSACredentialSpecName field."', args=[d.arg(name='gmsaCredentialSpec', type=d.T.string)]),
                withGmsaCredentialSpec(gmsaCredentialSpec): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { container+: { securityContext+: { windowsOptions+: { gmsaCredentialSpec: gmsaCredentialSpec } } } } } } } },
                '#withGmsaCredentialSpecName':: d.fn(help='"GMSACredentialSpecName is the name of the GMSA credential spec to use."', args=[d.arg(name='gmsaCredentialSpecName', type=d.T.string)]),
                withGmsaCredentialSpecName(gmsaCredentialSpecName): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { container+: { securityContext+: { windowsOptions+: { gmsaCredentialSpecName: gmsaCredentialSpecName } } } } } } } },
                '#withHostProcess':: d.fn(help="\"HostProcess determines if a container should be run as a 'Host Process' container.\\nAll of a Pod's containers must have the same effective HostProcess value\\n(it is not allowed to have a mix of HostProcess containers and non-HostProcess containers).\\nIn addition, if HostProcess is true then HostNetwork must also be set to true.\"", args=[d.arg(name='hostProcess', type=d.T.boolean)]),
                withHostProcess(hostProcess): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { container+: { securityContext+: { windowsOptions+: { hostProcess: hostProcess } } } } } } } },
                '#withRunAsUserName':: d.fn(help='"The UserName in Windows to run the entrypoint of the container process.\\nDefaults to the user specified in image metadata if unspecified.\\nMay also be set in PodSecurityContext. If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence."', args=[d.arg(name='runAsUserName', type=d.T.string)]),
                withRunAsUserName(runAsUserName): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { container+: { securityContext+: { windowsOptions+: { runAsUserName: runAsUserName } } } } } } } },
              },
              '#withAllowPrivilegeEscalation':: d.fn(help='"AllowPrivilegeEscalation controls whether a process can gain more\\nprivileges than its parent process. This bool directly controls if\\nthe no_new_privs flag will be set on the container process.\\nAllowPrivilegeEscalation is true always when the container is:\\n1) run as Privileged\\n2) has CAP_SYS_ADMIN\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='allowPrivilegeEscalation', type=d.T.boolean)]),
              withAllowPrivilegeEscalation(allowPrivilegeEscalation): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { container+: { securityContext+: { allowPrivilegeEscalation: allowPrivilegeEscalation } } } } } } },
              '#withPrivileged':: d.fn(help='"Run container in privileged mode.\\nProcesses in privileged containers are essentially equivalent to root on the host.\\nDefaults to false.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='privileged', type=d.T.boolean)]),
              withPrivileged(privileged): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { container+: { securityContext+: { privileged: privileged } } } } } } },
              '#withProcMount':: d.fn(help='"procMount denotes the type of proc mount to use for the containers.\\nThe default value is Default which uses the container runtime defaults for\\nreadonly paths and masked paths.\\nThis requires the ProcMountType feature flag to be enabled.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='procMount', type=d.T.string)]),
              withProcMount(procMount): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { container+: { securityContext+: { procMount: procMount } } } } } } },
              '#withReadOnlyRootFilesystem':: d.fn(help='"Whether this container has a read-only root filesystem.\\nDefault is false.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='readOnlyRootFilesystem', type=d.T.boolean)]),
              withReadOnlyRootFilesystem(readOnlyRootFilesystem): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { container+: { securityContext+: { readOnlyRootFilesystem: readOnlyRootFilesystem } } } } } } },
              '#withRunAsGroup':: d.fn(help='"The GID to run the entrypoint of the container process.\\nUses runtime default if unset.\\nMay also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='runAsGroup', type=d.T.integer)]),
              withRunAsGroup(runAsGroup): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { container+: { securityContext+: { runAsGroup: runAsGroup } } } } } } },
              '#withRunAsNonRoot':: d.fn(help='"Indicates that the container must run as a non-root user.\\nIf true, the Kubelet will validate the image at runtime to ensure that it\\ndoes not run as UID 0 (root) and fail to start the container if it does.\\nIf unset or false, no such validation will be performed.\\nMay also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence."', args=[d.arg(name='runAsNonRoot', type=d.T.boolean)]),
              withRunAsNonRoot(runAsNonRoot): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { container+: { securityContext+: { runAsNonRoot: runAsNonRoot } } } } } } },
              '#withRunAsUser':: d.fn(help='"The UID to run the entrypoint of the container process.\\nDefaults to user specified in image metadata if unspecified.\\nMay also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='runAsUser', type=d.T.integer)]),
              withRunAsUser(runAsUser): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { container+: { securityContext+: { runAsUser: runAsUser } } } } } } },
            },
            '#volumeMounts':: d.obj(help="\"VolumeMounts are volumes to mount into the container's filesystem.\\nCannot be updated.\""),
            volumeMounts: {
              '#withMountPath':: d.fn(help="\"Path within the container at which the volume should be mounted.  Must\\nnot contain ':'.\"", args=[d.arg(name='mountPath', type=d.T.string)]),
              withMountPath(mountPath): { mountPath: mountPath },
              '#withMountPropagation':: d.fn(help='"mountPropagation determines how mounts are propagated from the host\\nto container and the other way around.\\nWhen not set, MountPropagationNone is used.\\nThis field is beta in 1.10.\\nWhen RecursiveReadOnly is set to IfPossible or to Enabled, MountPropagation must be None or unspecified\\n(which defaults to None)."', args=[d.arg(name='mountPropagation', type=d.T.string)]),
              withMountPropagation(mountPropagation): { mountPropagation: mountPropagation },
              '#withName':: d.fn(help='"This must match the Name of a Volume."', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { name: name },
              '#withReadOnly':: d.fn(help='"Mounted read-only if true, read-write otherwise (false or unspecified).\\nDefaults to false."', args=[d.arg(name='readOnly', type=d.T.boolean)]),
              withReadOnly(readOnly): { readOnly: readOnly },
              '#withRecursiveReadOnly':: d.fn(help='"RecursiveReadOnly specifies whether read-only mounts should be handled\\nrecursively.\\n\\nIf ReadOnly is false, this field has no meaning and must be unspecified.\\n\\nIf ReadOnly is true, and this field is set to Disabled, the mount is not made\\nrecursively read-only.  If this field is set to IfPossible, the mount is made\\nrecursively read-only, if it is supported by the container runtime.  If this\\nfield is set to Enabled, the mount is made recursively read-only if it is\\nsupported by the container runtime, otherwise the pod will not be started and\\nan error will be generated to indicate the reason.\\n\\nIf this field is set to IfPossible or Enabled, MountPropagation must be set to\\nNone (or be unspecified, which defaults to None).\\n\\nIf this field is not specified, it is treated as an equivalent of Disabled."', args=[d.arg(name='recursiveReadOnly', type=d.T.string)]),
              withRecursiveReadOnly(recursiveReadOnly): { recursiveReadOnly: recursiveReadOnly },
              '#withSubPath':: d.fn(help="\"Path within the volume from which the container's volume should be mounted.\\nDefaults to \\\"\\\" (volume's root).\"", args=[d.arg(name='subPath', type=d.T.string)]),
              withSubPath(subPath): { subPath: subPath },
              '#withSubPathExpr':: d.fn(help="\"Expanded path within the volume from which the container's volume should be mounted.\\nBehaves similarly to SubPath but environment variable references $(VAR_NAME) are expanded using the container's environment.\\nDefaults to \\\"\\\" (volume's root).\\nSubPathExpr and SubPath are mutually exclusive.\"", args=[d.arg(name='subPathExpr', type=d.T.string)]),
              withSubPathExpr(subPathExpr): { subPathExpr: subPathExpr },
            },
            '#withEnv':: d.fn(help='"List of environment variables to set in the container."', args=[d.arg(name='env', type=d.T.array)]),
            withEnv(env): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { container+: { env: if std.isArray(v=env) then env else [env] } } } } } },
            '#withEnvMixin':: d.fn(help='"List of environment variables to set in the container."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='env', type=d.T.array)]),
            withEnvMixin(env): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { container+: { env+: if std.isArray(v=env) then env else [env] } } } } } },
            '#withImage':: d.fn(help='"Image specifies the EnvoyProxy container image to be used, instead of the default image."', args=[d.arg(name='image', type=d.T.string)]),
            withImage(image): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { container+: { image: image } } } } } },
            '#withVolumeMounts':: d.fn(help="\"VolumeMounts are volumes to mount into the container's filesystem.\\nCannot be updated.\"", args=[d.arg(name='volumeMounts', type=d.T.array)]),
            withVolumeMounts(volumeMounts): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { container+: { volumeMounts: if std.isArray(v=volumeMounts) then volumeMounts else [volumeMounts] } } } } } },
            '#withVolumeMountsMixin':: d.fn(help="\"VolumeMounts are volumes to mount into the container's filesystem.\\nCannot be updated.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='volumeMounts', type=d.T.array)]),
            withVolumeMountsMixin(volumeMounts): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { container+: { volumeMounts+: if std.isArray(v=volumeMounts) then volumeMounts else [volumeMounts] } } } } } },
          },
          '#patch':: d.obj(help='"Patch defines how to perform the patch operation to daemonset"'),
          patch: {
            '#withType':: d.fn(help='"Type is the type of merge operation to perform\\n\\nBy default, StrategicMerge is used as the patch type."', args=[d.arg(name='type', type=d.T.string)]),
            withType(type): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { patch+: { type: type } } } } } },
            '#withValue':: d.fn(help='"Object contains the raw configuration for merged object"', args=[d.arg(name='value', type=d.T.any)]),
            withValue(value): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { patch+: { value: value } } } } } },
          },
          '#pod':: d.obj(help='"Pod defines the desired specification of pod."'),
          pod: {
            '#affinity':: d.obj(help="\"If specified, the pod's scheduling constraints.\""),
            affinity: {
              '#nodeAffinity':: d.obj(help='"Describes node affinity scheduling rules for the pod."'),
              nodeAffinity: {
                '#preferredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node matches the corresponding matchExpressions; the\\nnode(s) with the highest sum are the most preferred."'),
                preferredDuringSchedulingIgnoredDuringExecution: {
                  '#preference':: d.obj(help='"A node selector term, associated with the corresponding weight."'),
                  preference: {
                    '#matchExpressions':: d.obj(help="\"A list of node selector requirements by node's labels.\""),
                    matchExpressions: {
                      '#withKey':: d.fn(help='"The label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                      withKey(key): { key: key },
                      '#withOperator':: d.fn(help="\"Represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.\"", args=[d.arg(name='operator', type=d.T.string)]),
                      withOperator(operator): { operator: operator },
                      '#withValues':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."', args=[d.arg(name='values', type=d.T.array)]),
                      withValues(values): { values: if std.isArray(v=values) then values else [values] },
                      '#withValuesMixin':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                      withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                    },
                    '#matchFields':: d.obj(help="\"A list of node selector requirements by node's fields.\""),
                    matchFields: {
                      '#withKey':: d.fn(help='"The label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                      withKey(key): { key: key },
                      '#withOperator':: d.fn(help="\"Represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.\"", args=[d.arg(name='operator', type=d.T.string)]),
                      withOperator(operator): { operator: operator },
                      '#withValues':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."', args=[d.arg(name='values', type=d.T.array)]),
                      withValues(values): { values: if std.isArray(v=values) then values else [values] },
                      '#withValuesMixin':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                      withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                    },
                    '#withMatchExpressions':: d.fn(help="\"A list of node selector requirements by node's labels.\"", args=[d.arg(name='matchExpressions', type=d.T.array)]),
                    withMatchExpressions(matchExpressions): { preference+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                    '#withMatchExpressionsMixin':: d.fn(help="\"A list of node selector requirements by node's labels.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchExpressions', type=d.T.array)]),
                    withMatchExpressionsMixin(matchExpressions): { preference+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                    '#withMatchFields':: d.fn(help="\"A list of node selector requirements by node's fields.\"", args=[d.arg(name='matchFields', type=d.T.array)]),
                    withMatchFields(matchFields): { preference+: { matchFields: if std.isArray(v=matchFields) then matchFields else [matchFields] } },
                    '#withMatchFieldsMixin':: d.fn(help="\"A list of node selector requirements by node's fields.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchFields', type=d.T.array)]),
                    withMatchFieldsMixin(matchFields): { preference+: { matchFields+: if std.isArray(v=matchFields) then matchFields else [matchFields] } },
                  },
                  '#withWeight':: d.fn(help='"Weight associated with matching the corresponding nodeSelectorTerm, in the range 1-100."', args=[d.arg(name='weight', type=d.T.integer)]),
                  withWeight(weight): { weight: weight },
                },
                '#requiredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"If the affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to an update), the system\\nmay or may not try to eventually evict the pod from its node."'),
                requiredDuringSchedulingIgnoredDuringExecution: {
                  '#nodeSelectorTerms':: d.obj(help='"Required. A list of node selector terms. The terms are ORed."'),
                  nodeSelectorTerms: {
                    '#matchExpressions':: d.obj(help="\"A list of node selector requirements by node's labels.\""),
                    matchExpressions: {
                      '#withKey':: d.fn(help='"The label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                      withKey(key): { key: key },
                      '#withOperator':: d.fn(help="\"Represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.\"", args=[d.arg(name='operator', type=d.T.string)]),
                      withOperator(operator): { operator: operator },
                      '#withValues':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."', args=[d.arg(name='values', type=d.T.array)]),
                      withValues(values): { values: if std.isArray(v=values) then values else [values] },
                      '#withValuesMixin':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                      withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                    },
                    '#matchFields':: d.obj(help="\"A list of node selector requirements by node's fields.\""),
                    matchFields: {
                      '#withKey':: d.fn(help='"The label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                      withKey(key): { key: key },
                      '#withOperator':: d.fn(help="\"Represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.\"", args=[d.arg(name='operator', type=d.T.string)]),
                      withOperator(operator): { operator: operator },
                      '#withValues':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."', args=[d.arg(name='values', type=d.T.array)]),
                      withValues(values): { values: if std.isArray(v=values) then values else [values] },
                      '#withValuesMixin':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                      withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                    },
                    '#withMatchExpressions':: d.fn(help="\"A list of node selector requirements by node's labels.\"", args=[d.arg(name='matchExpressions', type=d.T.array)]),
                    withMatchExpressions(matchExpressions): { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] },
                    '#withMatchExpressionsMixin':: d.fn(help="\"A list of node selector requirements by node's labels.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchExpressions', type=d.T.array)]),
                    withMatchExpressionsMixin(matchExpressions): { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] },
                    '#withMatchFields':: d.fn(help="\"A list of node selector requirements by node's fields.\"", args=[d.arg(name='matchFields', type=d.T.array)]),
                    withMatchFields(matchFields): { matchFields: if std.isArray(v=matchFields) then matchFields else [matchFields] },
                    '#withMatchFieldsMixin':: d.fn(help="\"A list of node selector requirements by node's fields.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchFields', type=d.T.array)]),
                    withMatchFieldsMixin(matchFields): { matchFields+: if std.isArray(v=matchFields) then matchFields else [matchFields] },
                  },
                  '#withNodeSelectorTerms':: d.fn(help='"Required. A list of node selector terms. The terms are ORed."', args=[d.arg(name='nodeSelectorTerms', type=d.T.array)]),
                  withNodeSelectorTerms(nodeSelectorTerms): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { pod+: { affinity+: { nodeAffinity+: { requiredDuringSchedulingIgnoredDuringExecution+: { nodeSelectorTerms: if std.isArray(v=nodeSelectorTerms) then nodeSelectorTerms else [nodeSelectorTerms] } } } } } } } } },
                  '#withNodeSelectorTermsMixin':: d.fn(help='"Required. A list of node selector terms. The terms are ORed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='nodeSelectorTerms', type=d.T.array)]),
                  withNodeSelectorTermsMixin(nodeSelectorTerms): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { pod+: { affinity+: { nodeAffinity+: { requiredDuringSchedulingIgnoredDuringExecution+: { nodeSelectorTerms+: if std.isArray(v=nodeSelectorTerms) then nodeSelectorTerms else [nodeSelectorTerms] } } } } } } } } },
                },
                '#withPreferredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node matches the corresponding matchExpressions; the\\nnode(s) with the highest sum are the most preferred."', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
                withPreferredDuringSchedulingIgnoredDuringExecution(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { pod+: { affinity+: { nodeAffinity+: { preferredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } } } },
                '#withPreferredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node matches the corresponding matchExpressions; the\\nnode(s) with the highest sum are the most preferred."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
                withPreferredDuringSchedulingIgnoredDuringExecutionMixin(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { pod+: { affinity+: { nodeAffinity+: { preferredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } } } },
              },
              '#podAffinity':: d.obj(help='"Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s))."'),
              podAffinity: {
                '#preferredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."'),
                preferredDuringSchedulingIgnoredDuringExecution: {
                  '#podAffinityTerm':: d.obj(help='"Required. A pod affinity term, associated with the corresponding weight."'),
                  podAffinityTerm: {
                    '#labelSelector':: d.obj(help="\"A label query over a set of resources, in this case pods.\\nIf it's null, this PodAffinityTerm matches with no Pods.\""),
                    labelSelector: {
                      '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                      matchExpressions: {
                        '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                        withKey(key): { key: key },
                        '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                        withOperator(operator): { operator: operator },
                        '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                        withValues(values): { values: if std.isArray(v=values) then values else [values] },
                        '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                        withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                      },
                      '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                      withMatchExpressions(matchExpressions): { podAffinityTerm+: { labelSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                      '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                      withMatchExpressionsMixin(matchExpressions): { podAffinityTerm+: { labelSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                      '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                      withMatchLabels(matchLabels): { podAffinityTerm+: { labelSelector+: { matchLabels: matchLabels } } },
                      '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                      withMatchLabelsMixin(matchLabels): { podAffinityTerm+: { labelSelector+: { matchLabels+: matchLabels } } },
                    },
                    '#namespaceSelector':: d.obj(help="\"A label query over the set of namespaces that the term applies to.\\nThe term is applied to the union of the namespaces selected by this field\\nand the ones listed in the namespaces field.\\nnull selector and null or empty namespaces list means \\\"this pod's namespace\\\".\\nAn empty selector ({}) matches all namespaces.\""),
                    namespaceSelector: {
                      '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                      matchExpressions: {
                        '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                        withKey(key): { key: key },
                        '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                        withOperator(operator): { operator: operator },
                        '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                        withValues(values): { values: if std.isArray(v=values) then values else [values] },
                        '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                        withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                      },
                      '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                      withMatchExpressions(matchExpressions): { podAffinityTerm+: { namespaceSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                      '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                      withMatchExpressionsMixin(matchExpressions): { podAffinityTerm+: { namespaceSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                      '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                      withMatchLabels(matchLabels): { podAffinityTerm+: { namespaceSelector+: { matchLabels: matchLabels } } },
                      '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                      withMatchLabelsMixin(matchLabels): { podAffinityTerm+: { namespaceSelector+: { matchLabels+: matchLabels } } },
                    },
                    '#withMatchLabelKeys':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                    withMatchLabelKeys(matchLabelKeys): { podAffinityTerm+: { matchLabelKeys: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] } },
                    '#withMatchLabelKeysMixin':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                    withMatchLabelKeysMixin(matchLabelKeys): { podAffinityTerm+: { matchLabelKeys+: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] } },
                    '#withMismatchLabelKeys':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                    withMismatchLabelKeys(mismatchLabelKeys): { podAffinityTerm+: { mismatchLabelKeys: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] } },
                    '#withMismatchLabelKeysMixin':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                    withMismatchLabelKeysMixin(mismatchLabelKeys): { podAffinityTerm+: { mismatchLabelKeys+: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] } },
                    '#withNamespaces':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"", args=[d.arg(name='namespaces', type=d.T.array)]),
                    withNamespaces(namespaces): { podAffinityTerm+: { namespaces: if std.isArray(v=namespaces) then namespaces else [namespaces] } },
                    '#withNamespacesMixin':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='namespaces', type=d.T.array)]),
                    withNamespacesMixin(namespaces): { podAffinityTerm+: { namespaces+: if std.isArray(v=namespaces) then namespaces else [namespaces] } },
                    '#withTopologyKey':: d.fn(help='"This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching\\nthe labelSelector in the specified namespaces, where co-located is defined as running on a node\\nwhose value of the label with key topologyKey matches that of any node on which any of the\\nselected pods is running.\\nEmpty topologyKey is not allowed."', args=[d.arg(name='topologyKey', type=d.T.string)]),
                    withTopologyKey(topologyKey): { podAffinityTerm+: { topologyKey: topologyKey } },
                  },
                  '#withWeight':: d.fn(help='"weight associated with matching the corresponding podAffinityTerm,\\nin the range 1-100."', args=[d.arg(name='weight', type=d.T.integer)]),
                  withWeight(weight): { weight: weight },
                },
                '#requiredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"If the affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."'),
                requiredDuringSchedulingIgnoredDuringExecution: {
                  '#labelSelector':: d.obj(help="\"A label query over a set of resources, in this case pods.\\nIf it's null, this PodAffinityTerm matches with no Pods.\""),
                  labelSelector: {
                    '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                    matchExpressions: {
                      '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                      withKey(key): { key: key },
                      '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                      withOperator(operator): { operator: operator },
                      '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                      withValues(values): { values: if std.isArray(v=values) then values else [values] },
                      '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                      withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                    },
                    '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                    withMatchExpressions(matchExpressions): { labelSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                    '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                    withMatchExpressionsMixin(matchExpressions): { labelSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                    '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                    withMatchLabels(matchLabels): { labelSelector+: { matchLabels: matchLabels } },
                    '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                    withMatchLabelsMixin(matchLabels): { labelSelector+: { matchLabels+: matchLabels } },
                  },
                  '#namespaceSelector':: d.obj(help="\"A label query over the set of namespaces that the term applies to.\\nThe term is applied to the union of the namespaces selected by this field\\nand the ones listed in the namespaces field.\\nnull selector and null or empty namespaces list means \\\"this pod's namespace\\\".\\nAn empty selector ({}) matches all namespaces.\""),
                  namespaceSelector: {
                    '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                    matchExpressions: {
                      '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                      withKey(key): { key: key },
                      '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                      withOperator(operator): { operator: operator },
                      '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                      withValues(values): { values: if std.isArray(v=values) then values else [values] },
                      '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                      withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                    },
                    '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                    withMatchExpressions(matchExpressions): { namespaceSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                    '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                    withMatchExpressionsMixin(matchExpressions): { namespaceSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                    '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                    withMatchLabels(matchLabels): { namespaceSelector+: { matchLabels: matchLabels } },
                    '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                    withMatchLabelsMixin(matchLabels): { namespaceSelector+: { matchLabels+: matchLabels } },
                  },
                  '#withMatchLabelKeys':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                  withMatchLabelKeys(matchLabelKeys): { matchLabelKeys: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] },
                  '#withMatchLabelKeysMixin':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                  withMatchLabelKeysMixin(matchLabelKeys): { matchLabelKeys+: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] },
                  '#withMismatchLabelKeys':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                  withMismatchLabelKeys(mismatchLabelKeys): { mismatchLabelKeys: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] },
                  '#withMismatchLabelKeysMixin':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                  withMismatchLabelKeysMixin(mismatchLabelKeys): { mismatchLabelKeys+: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] },
                  '#withNamespaces':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"", args=[d.arg(name='namespaces', type=d.T.array)]),
                  withNamespaces(namespaces): { namespaces: if std.isArray(v=namespaces) then namespaces else [namespaces] },
                  '#withNamespacesMixin':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='namespaces', type=d.T.array)]),
                  withNamespacesMixin(namespaces): { namespaces+: if std.isArray(v=namespaces) then namespaces else [namespaces] },
                  '#withTopologyKey':: d.fn(help='"This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching\\nthe labelSelector in the specified namespaces, where co-located is defined as running on a node\\nwhose value of the label with key topologyKey matches that of any node on which any of the\\nselected pods is running.\\nEmpty topologyKey is not allowed."', args=[d.arg(name='topologyKey', type=d.T.string)]),
                  withTopologyKey(topologyKey): { topologyKey: topologyKey },
                },
                '#withPreferredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
                withPreferredDuringSchedulingIgnoredDuringExecution(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { pod+: { affinity+: { podAffinity+: { preferredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } } } },
                '#withPreferredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
                withPreferredDuringSchedulingIgnoredDuringExecutionMixin(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { pod+: { affinity+: { podAffinity+: { preferredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } } } },
                '#withRequiredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"If the affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."', args=[d.arg(name='requiredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
                withRequiredDuringSchedulingIgnoredDuringExecution(requiredDuringSchedulingIgnoredDuringExecution): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { pod+: { affinity+: { podAffinity+: { requiredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=requiredDuringSchedulingIgnoredDuringExecution) then requiredDuringSchedulingIgnoredDuringExecution else [requiredDuringSchedulingIgnoredDuringExecution] } } } } } } } },
                '#withRequiredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"If the affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requiredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
                withRequiredDuringSchedulingIgnoredDuringExecutionMixin(requiredDuringSchedulingIgnoredDuringExecution): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { pod+: { affinity+: { podAffinity+: { requiredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=requiredDuringSchedulingIgnoredDuringExecution) then requiredDuringSchedulingIgnoredDuringExecution else [requiredDuringSchedulingIgnoredDuringExecution] } } } } } } } },
              },
              '#podAntiAffinity':: d.obj(help='"Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s))."'),
              podAntiAffinity: {
                '#preferredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe anti-affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling anti-affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."'),
                preferredDuringSchedulingIgnoredDuringExecution: {
                  '#podAffinityTerm':: d.obj(help='"Required. A pod affinity term, associated with the corresponding weight."'),
                  podAffinityTerm: {
                    '#labelSelector':: d.obj(help="\"A label query over a set of resources, in this case pods.\\nIf it's null, this PodAffinityTerm matches with no Pods.\""),
                    labelSelector: {
                      '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                      matchExpressions: {
                        '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                        withKey(key): { key: key },
                        '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                        withOperator(operator): { operator: operator },
                        '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                        withValues(values): { values: if std.isArray(v=values) then values else [values] },
                        '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                        withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                      },
                      '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                      withMatchExpressions(matchExpressions): { podAffinityTerm+: { labelSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                      '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                      withMatchExpressionsMixin(matchExpressions): { podAffinityTerm+: { labelSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                      '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                      withMatchLabels(matchLabels): { podAffinityTerm+: { labelSelector+: { matchLabels: matchLabels } } },
                      '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                      withMatchLabelsMixin(matchLabels): { podAffinityTerm+: { labelSelector+: { matchLabels+: matchLabels } } },
                    },
                    '#namespaceSelector':: d.obj(help="\"A label query over the set of namespaces that the term applies to.\\nThe term is applied to the union of the namespaces selected by this field\\nand the ones listed in the namespaces field.\\nnull selector and null or empty namespaces list means \\\"this pod's namespace\\\".\\nAn empty selector ({}) matches all namespaces.\""),
                    namespaceSelector: {
                      '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                      matchExpressions: {
                        '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                        withKey(key): { key: key },
                        '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                        withOperator(operator): { operator: operator },
                        '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                        withValues(values): { values: if std.isArray(v=values) then values else [values] },
                        '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                        withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                      },
                      '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                      withMatchExpressions(matchExpressions): { podAffinityTerm+: { namespaceSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                      '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                      withMatchExpressionsMixin(matchExpressions): { podAffinityTerm+: { namespaceSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                      '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                      withMatchLabels(matchLabels): { podAffinityTerm+: { namespaceSelector+: { matchLabels: matchLabels } } },
                      '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                      withMatchLabelsMixin(matchLabels): { podAffinityTerm+: { namespaceSelector+: { matchLabels+: matchLabels } } },
                    },
                    '#withMatchLabelKeys':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                    withMatchLabelKeys(matchLabelKeys): { podAffinityTerm+: { matchLabelKeys: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] } },
                    '#withMatchLabelKeysMixin':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                    withMatchLabelKeysMixin(matchLabelKeys): { podAffinityTerm+: { matchLabelKeys+: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] } },
                    '#withMismatchLabelKeys':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                    withMismatchLabelKeys(mismatchLabelKeys): { podAffinityTerm+: { mismatchLabelKeys: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] } },
                    '#withMismatchLabelKeysMixin':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                    withMismatchLabelKeysMixin(mismatchLabelKeys): { podAffinityTerm+: { mismatchLabelKeys+: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] } },
                    '#withNamespaces':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"", args=[d.arg(name='namespaces', type=d.T.array)]),
                    withNamespaces(namespaces): { podAffinityTerm+: { namespaces: if std.isArray(v=namespaces) then namespaces else [namespaces] } },
                    '#withNamespacesMixin':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='namespaces', type=d.T.array)]),
                    withNamespacesMixin(namespaces): { podAffinityTerm+: { namespaces+: if std.isArray(v=namespaces) then namespaces else [namespaces] } },
                    '#withTopologyKey':: d.fn(help='"This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching\\nthe labelSelector in the specified namespaces, where co-located is defined as running on a node\\nwhose value of the label with key topologyKey matches that of any node on which any of the\\nselected pods is running.\\nEmpty topologyKey is not allowed."', args=[d.arg(name='topologyKey', type=d.T.string)]),
                    withTopologyKey(topologyKey): { podAffinityTerm+: { topologyKey: topologyKey } },
                  },
                  '#withWeight':: d.fn(help='"weight associated with matching the corresponding podAffinityTerm,\\nin the range 1-100."', args=[d.arg(name='weight', type=d.T.integer)]),
                  withWeight(weight): { weight: weight },
                },
                '#requiredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"If the anti-affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the anti-affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."'),
                requiredDuringSchedulingIgnoredDuringExecution: {
                  '#labelSelector':: d.obj(help="\"A label query over a set of resources, in this case pods.\\nIf it's null, this PodAffinityTerm matches with no Pods.\""),
                  labelSelector: {
                    '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                    matchExpressions: {
                      '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                      withKey(key): { key: key },
                      '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                      withOperator(operator): { operator: operator },
                      '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                      withValues(values): { values: if std.isArray(v=values) then values else [values] },
                      '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                      withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                    },
                    '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                    withMatchExpressions(matchExpressions): { labelSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                    '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                    withMatchExpressionsMixin(matchExpressions): { labelSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                    '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                    withMatchLabels(matchLabels): { labelSelector+: { matchLabels: matchLabels } },
                    '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                    withMatchLabelsMixin(matchLabels): { labelSelector+: { matchLabels+: matchLabels } },
                  },
                  '#namespaceSelector':: d.obj(help="\"A label query over the set of namespaces that the term applies to.\\nThe term is applied to the union of the namespaces selected by this field\\nand the ones listed in the namespaces field.\\nnull selector and null or empty namespaces list means \\\"this pod's namespace\\\".\\nAn empty selector ({}) matches all namespaces.\""),
                  namespaceSelector: {
                    '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                    matchExpressions: {
                      '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                      withKey(key): { key: key },
                      '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                      withOperator(operator): { operator: operator },
                      '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                      withValues(values): { values: if std.isArray(v=values) then values else [values] },
                      '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                      withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                    },
                    '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                    withMatchExpressions(matchExpressions): { namespaceSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                    '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                    withMatchExpressionsMixin(matchExpressions): { namespaceSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                    '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                    withMatchLabels(matchLabels): { namespaceSelector+: { matchLabels: matchLabels } },
                    '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                    withMatchLabelsMixin(matchLabels): { namespaceSelector+: { matchLabels+: matchLabels } },
                  },
                  '#withMatchLabelKeys':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                  withMatchLabelKeys(matchLabelKeys): { matchLabelKeys: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] },
                  '#withMatchLabelKeysMixin':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                  withMatchLabelKeysMixin(matchLabelKeys): { matchLabelKeys+: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] },
                  '#withMismatchLabelKeys':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                  withMismatchLabelKeys(mismatchLabelKeys): { mismatchLabelKeys: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] },
                  '#withMismatchLabelKeysMixin':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                  withMismatchLabelKeysMixin(mismatchLabelKeys): { mismatchLabelKeys+: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] },
                  '#withNamespaces':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"", args=[d.arg(name='namespaces', type=d.T.array)]),
                  withNamespaces(namespaces): { namespaces: if std.isArray(v=namespaces) then namespaces else [namespaces] },
                  '#withNamespacesMixin':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='namespaces', type=d.T.array)]),
                  withNamespacesMixin(namespaces): { namespaces+: if std.isArray(v=namespaces) then namespaces else [namespaces] },
                  '#withTopologyKey':: d.fn(help='"This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching\\nthe labelSelector in the specified namespaces, where co-located is defined as running on a node\\nwhose value of the label with key topologyKey matches that of any node on which any of the\\nselected pods is running.\\nEmpty topologyKey is not allowed."', args=[d.arg(name='topologyKey', type=d.T.string)]),
                  withTopologyKey(topologyKey): { topologyKey: topologyKey },
                },
                '#withPreferredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe anti-affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling anti-affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
                withPreferredDuringSchedulingIgnoredDuringExecution(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { pod+: { affinity+: { podAntiAffinity+: { preferredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } } } },
                '#withPreferredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe anti-affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling anti-affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
                withPreferredDuringSchedulingIgnoredDuringExecutionMixin(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { pod+: { affinity+: { podAntiAffinity+: { preferredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } } } },
                '#withRequiredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"If the anti-affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the anti-affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."', args=[d.arg(name='requiredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
                withRequiredDuringSchedulingIgnoredDuringExecution(requiredDuringSchedulingIgnoredDuringExecution): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { pod+: { affinity+: { podAntiAffinity+: { requiredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=requiredDuringSchedulingIgnoredDuringExecution) then requiredDuringSchedulingIgnoredDuringExecution else [requiredDuringSchedulingIgnoredDuringExecution] } } } } } } } },
                '#withRequiredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"If the anti-affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the anti-affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requiredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
                withRequiredDuringSchedulingIgnoredDuringExecutionMixin(requiredDuringSchedulingIgnoredDuringExecution): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { pod+: { affinity+: { podAntiAffinity+: { requiredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=requiredDuringSchedulingIgnoredDuringExecution) then requiredDuringSchedulingIgnoredDuringExecution else [requiredDuringSchedulingIgnoredDuringExecution] } } } } } } } },
              },
            },
            '#imagePullSecrets':: d.obj(help='"ImagePullSecrets is an optional list of references to secrets\\nin the same namespace to use for pulling any of the images used by this PodSpec.\\nIf specified, these secrets will be passed to individual puller implementations for them to use.\\nMore info: https://kubernetes.io/docs/concepts/containers/images#specifying-imagepullsecrets-on-a-pod"'),
            imagePullSecrets: {
              '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { name: name },
            },
            '#securityContext':: d.obj(help='"SecurityContext holds pod-level security attributes and common container settings.\\nOptional: Defaults to empty.  See type description for default values of each field."'),
            securityContext: {
              '#appArmorProfile':: d.obj(help='"appArmorProfile is the AppArmor options to use by the containers in this pod.\\nNote that this field cannot be set when spec.os.name is windows."'),
              appArmorProfile: {
                '#withLocalhostProfile':: d.fn(help='"localhostProfile indicates a profile loaded on the node that should be used.\\nThe profile must be preconfigured on the node to work.\\nMust match the loaded name of the profile.\\nMust be set if and only if type is \\"Localhost\\"."', args=[d.arg(name='localhostProfile', type=d.T.string)]),
                withLocalhostProfile(localhostProfile): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { pod+: { securityContext+: { appArmorProfile+: { localhostProfile: localhostProfile } } } } } } } },
                '#withType':: d.fn(help="\"type indicates which kind of AppArmor profile will be applied.\\nValid options are:\\n  Localhost - a profile pre-loaded on the node.\\n  RuntimeDefault - the container runtime's default profile.\\n  Unconfined - no AppArmor enforcement.\"", args=[d.arg(name='type', type=d.T.string)]),
                withType(type): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { pod+: { securityContext+: { appArmorProfile+: { type: type } } } } } } } },
              },
              '#seLinuxOptions':: d.obj(help='"The SELinux context to be applied to all containers.\\nIf unspecified, the container runtime will allocate a random SELinux context for each\\ncontainer.  May also be set in SecurityContext.  If set in\\nboth SecurityContext and PodSecurityContext, the value specified in SecurityContext\\ntakes precedence for that container.\\nNote that this field cannot be set when spec.os.name is windows."'),
              seLinuxOptions: {
                '#withLevel':: d.fn(help='"Level is SELinux level label that applies to the container."', args=[d.arg(name='level', type=d.T.string)]),
                withLevel(level): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { pod+: { securityContext+: { seLinuxOptions+: { level: level } } } } } } } },
                '#withRole':: d.fn(help='"Role is a SELinux role label that applies to the container."', args=[d.arg(name='role', type=d.T.string)]),
                withRole(role): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { pod+: { securityContext+: { seLinuxOptions+: { role: role } } } } } } } },
                '#withType':: d.fn(help='"Type is a SELinux type label that applies to the container."', args=[d.arg(name='type', type=d.T.string)]),
                withType(type): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { pod+: { securityContext+: { seLinuxOptions+: { type: type } } } } } } } },
                '#withUser':: d.fn(help='"User is a SELinux user label that applies to the container."', args=[d.arg(name='user', type=d.T.string)]),
                withUser(user): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { pod+: { securityContext+: { seLinuxOptions+: { user: user } } } } } } } },
              },
              '#seccompProfile':: d.obj(help='"The seccomp options to use by the containers in this pod.\\nNote that this field cannot be set when spec.os.name is windows."'),
              seccompProfile: {
                '#withLocalhostProfile':: d.fn(help="\"localhostProfile indicates a profile defined in a file on the node should be used.\\nThe profile must be preconfigured on the node to work.\\nMust be a descending path, relative to the kubelet's configured seccomp profile location.\\nMust be set if type is \\\"Localhost\\\". Must NOT be set for any other type.\"", args=[d.arg(name='localhostProfile', type=d.T.string)]),
                withLocalhostProfile(localhostProfile): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { pod+: { securityContext+: { seccompProfile+: { localhostProfile: localhostProfile } } } } } } } },
                '#withType':: d.fn(help='"type indicates which kind of seccomp profile will be applied.\\nValid options are:\\n\\nLocalhost - a profile defined in a file on the node should be used.\\nRuntimeDefault - the container runtime default profile should be used.\\nUnconfined - no profile should be applied."', args=[d.arg(name='type', type=d.T.string)]),
                withType(type): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { pod+: { securityContext+: { seccompProfile+: { type: type } } } } } } } },
              },
              '#sysctls':: d.obj(help='"Sysctls hold a list of namespaced sysctls used for the pod. Pods with unsupported\\nsysctls (by the container runtime) might fail to launch.\\nNote that this field cannot be set when spec.os.name is windows."'),
              sysctls: {
                '#withName':: d.fn(help='"Name of a property to set"', args=[d.arg(name='name', type=d.T.string)]),
                withName(name): { name: name },
                '#withValue':: d.fn(help='"Value of a property to set"', args=[d.arg(name='value', type=d.T.string)]),
                withValue(value): { value: value },
              },
              '#windowsOptions':: d.obj(help="\"The Windows specific settings applied to all containers.\\nIf unspecified, the options within a container's SecurityContext will be used.\\nIf set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is linux.\""),
              windowsOptions: {
                '#withGmsaCredentialSpec':: d.fn(help='"GMSACredentialSpec is where the GMSA admission webhook\\n(https://github.com/kubernetes-sigs/windows-gmsa) inlines the contents of the\\nGMSA credential spec named by the GMSACredentialSpecName field."', args=[d.arg(name='gmsaCredentialSpec', type=d.T.string)]),
                withGmsaCredentialSpec(gmsaCredentialSpec): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { pod+: { securityContext+: { windowsOptions+: { gmsaCredentialSpec: gmsaCredentialSpec } } } } } } } },
                '#withGmsaCredentialSpecName':: d.fn(help='"GMSACredentialSpecName is the name of the GMSA credential spec to use."', args=[d.arg(name='gmsaCredentialSpecName', type=d.T.string)]),
                withGmsaCredentialSpecName(gmsaCredentialSpecName): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { pod+: { securityContext+: { windowsOptions+: { gmsaCredentialSpecName: gmsaCredentialSpecName } } } } } } } },
                '#withHostProcess':: d.fn(help="\"HostProcess determines if a container should be run as a 'Host Process' container.\\nAll of a Pod's containers must have the same effective HostProcess value\\n(it is not allowed to have a mix of HostProcess containers and non-HostProcess containers).\\nIn addition, if HostProcess is true then HostNetwork must also be set to true.\"", args=[d.arg(name='hostProcess', type=d.T.boolean)]),
                withHostProcess(hostProcess): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { pod+: { securityContext+: { windowsOptions+: { hostProcess: hostProcess } } } } } } } },
                '#withRunAsUserName':: d.fn(help='"The UserName in Windows to run the entrypoint of the container process.\\nDefaults to the user specified in image metadata if unspecified.\\nMay also be set in PodSecurityContext. If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence."', args=[d.arg(name='runAsUserName', type=d.T.string)]),
                withRunAsUserName(runAsUserName): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { pod+: { securityContext+: { windowsOptions+: { runAsUserName: runAsUserName } } } } } } } },
              },
              '#withFsGroup':: d.fn(help="\"A special supplemental group that applies to all containers in a pod.\\nSome volume types allow the Kubelet to change the ownership of that volume\\nto be owned by the pod:\\n\\n1. The owning GID will be the FSGroup\\n2. The setgid bit is set (new files created in the volume will be owned by FSGroup)\\n3. The permission bits are OR'd with rw-rw----\\n\\nIf unset, the Kubelet will not modify the ownership and permissions of any volume.\\nNote that this field cannot be set when spec.os.name is windows.\"", args=[d.arg(name='fsGroup', type=d.T.integer)]),
              withFsGroup(fsGroup): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { pod+: { securityContext+: { fsGroup: fsGroup } } } } } } },
              '#withFsGroupChangePolicy':: d.fn(help='"fsGroupChangePolicy defines behavior of changing ownership and permission of the volume\\nbefore being exposed inside Pod. This field will only apply to\\nvolume types which support fsGroup based ownership(and permissions).\\nIt will have no effect on ephemeral volume types such as: secret, configmaps\\nand emptydir.\\nValid values are \\"OnRootMismatch\\" and \\"Always\\". If not specified, \\"Always\\" is used.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='fsGroupChangePolicy', type=d.T.string)]),
              withFsGroupChangePolicy(fsGroupChangePolicy): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { pod+: { securityContext+: { fsGroupChangePolicy: fsGroupChangePolicy } } } } } } },
              '#withRunAsGroup':: d.fn(help='"The GID to run the entrypoint of the container process.\\nUses runtime default if unset.\\nMay also be set in SecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence\\nfor that container.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='runAsGroup', type=d.T.integer)]),
              withRunAsGroup(runAsGroup): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { pod+: { securityContext+: { runAsGroup: runAsGroup } } } } } } },
              '#withRunAsNonRoot':: d.fn(help='"Indicates that the container must run as a non-root user.\\nIf true, the Kubelet will validate the image at runtime to ensure that it\\ndoes not run as UID 0 (root) and fail to start the container if it does.\\nIf unset or false, no such validation will be performed.\\nMay also be set in SecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence."', args=[d.arg(name='runAsNonRoot', type=d.T.boolean)]),
              withRunAsNonRoot(runAsNonRoot): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { pod+: { securityContext+: { runAsNonRoot: runAsNonRoot } } } } } } },
              '#withRunAsUser':: d.fn(help='"The UID to run the entrypoint of the container process.\\nDefaults to user specified in image metadata if unspecified.\\nMay also be set in SecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence\\nfor that container.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='runAsUser', type=d.T.integer)]),
              withRunAsUser(runAsUser): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { pod+: { securityContext+: { runAsUser: runAsUser } } } } } } },
              '#withSeLinuxChangePolicy':: d.fn(help="\"seLinuxChangePolicy defines how the container's SELinux label is applied to all volumes used by the Pod.\\nIt has no effect on nodes that do not support SELinux or to volumes does not support SELinux.\\nValid values are \\\"MountOption\\\" and \\\"Recursive\\\".\\n\\n\\\"Recursive\\\" means relabeling of all files on all Pod volumes by the container runtime.\\nThis may be slow for large volumes, but allows mixing privileged and unprivileged Pods sharing the same volume on the same node.\\n\\n\\\"MountOption\\\" mounts all eligible Pod volumes with `-o context` mount option.\\nThis requires all Pods that share the same volume to use the same SELinux label.\\nIt is not possible to share the same volume among privileged and unprivileged Pods.\\nEligible volumes are in-tree FibreChannel and iSCSI volumes, and all CSI volumes\\nwhose CSI driver announces SELinux support by setting spec.seLinuxMount: true in their\\nCSIDriver instance. Other volumes are always re-labelled recursively.\\n\\\"MountOption\\\" value is allowed only when SELinuxMount feature gate is enabled.\\n\\nIf not specified and SELinuxMount feature gate is enabled, \\\"MountOption\\\" is used.\\nIf not specified and SELinuxMount feature gate is disabled, \\\"MountOption\\\" is used for ReadWriteOncePod volumes\\nand \\\"Recursive\\\" for all other volumes.\\n\\nThis field affects only Pods that have SELinux label set, either in PodSecurityContext or in SecurityContext of all containers.\\n\\nAll Pods that use the same volume should use the same seLinuxChangePolicy, otherwise some pods can get stuck in ContainerCreating state.\\nNote that this field cannot be set when spec.os.name is windows.\"", args=[d.arg(name='seLinuxChangePolicy', type=d.T.string)]),
              withSeLinuxChangePolicy(seLinuxChangePolicy): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { pod+: { securityContext+: { seLinuxChangePolicy: seLinuxChangePolicy } } } } } } },
              '#withSupplementalGroups':: d.fn(help="\"A list of groups applied to the first process run in each container, in\\naddition to the container's primary GID and fsGroup (if specified).  If\\nthe SupplementalGroupsPolicy feature is enabled, the\\nsupplementalGroupsPolicy field determines whether these are in addition\\nto or instead of any group memberships defined in the container image.\\nIf unspecified, no additional groups are added, though group memberships\\ndefined in the container image may still be used, depending on the\\nsupplementalGroupsPolicy field.\\nNote that this field cannot be set when spec.os.name is windows.\"", args=[d.arg(name='supplementalGroups', type=d.T.array)]),
              withSupplementalGroups(supplementalGroups): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { pod+: { securityContext+: { supplementalGroups: if std.isArray(v=supplementalGroups) then supplementalGroups else [supplementalGroups] } } } } } } },
              '#withSupplementalGroupsMixin':: d.fn(help="\"A list of groups applied to the first process run in each container, in\\naddition to the container's primary GID and fsGroup (if specified).  If\\nthe SupplementalGroupsPolicy feature is enabled, the\\nsupplementalGroupsPolicy field determines whether these are in addition\\nto or instead of any group memberships defined in the container image.\\nIf unspecified, no additional groups are added, though group memberships\\ndefined in the container image may still be used, depending on the\\nsupplementalGroupsPolicy field.\\nNote that this field cannot be set when spec.os.name is windows.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='supplementalGroups', type=d.T.array)]),
              withSupplementalGroupsMixin(supplementalGroups): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { pod+: { securityContext+: { supplementalGroups+: if std.isArray(v=supplementalGroups) then supplementalGroups else [supplementalGroups] } } } } } } },
              '#withSupplementalGroupsPolicy':: d.fn(help='"Defines how supplemental groups of the first container processes are calculated.\\nValid values are \\"Merge\\" and \\"Strict\\". If not specified, \\"Merge\\" is used.\\n(Alpha) Using the field requires the SupplementalGroupsPolicy feature gate to be enabled\\nand the container runtime must implement support for this feature.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='supplementalGroupsPolicy', type=d.T.string)]),
              withSupplementalGroupsPolicy(supplementalGroupsPolicy): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { pod+: { securityContext+: { supplementalGroupsPolicy: supplementalGroupsPolicy } } } } } } },
              '#withSysctls':: d.fn(help='"Sysctls hold a list of namespaced sysctls used for the pod. Pods with unsupported\\nsysctls (by the container runtime) might fail to launch.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='sysctls', type=d.T.array)]),
              withSysctls(sysctls): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { pod+: { securityContext+: { sysctls: if std.isArray(v=sysctls) then sysctls else [sysctls] } } } } } } },
              '#withSysctlsMixin':: d.fn(help='"Sysctls hold a list of namespaced sysctls used for the pod. Pods with unsupported\\nsysctls (by the container runtime) might fail to launch.\\nNote that this field cannot be set when spec.os.name is windows."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='sysctls', type=d.T.array)]),
              withSysctlsMixin(sysctls): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { pod+: { securityContext+: { sysctls+: if std.isArray(v=sysctls) then sysctls else [sysctls] } } } } } } },
            },
            '#tolerations':: d.obj(help="\"If specified, the pod's tolerations.\""),
            tolerations: {
              '#withEffect':: d.fn(help='"Effect indicates the taint effect to match. Empty means match all taint effects.\\nWhen specified, allowed values are NoSchedule, PreferNoSchedule and NoExecute."', args=[d.arg(name='effect', type=d.T.string)]),
              withEffect(effect): { effect: effect },
              '#withKey':: d.fn(help='"Key is the taint key that the toleration applies to. Empty means match all taint keys.\\nIf the key is empty, operator must be Exists; this combination means to match all values and all keys."', args=[d.arg(name='key', type=d.T.string)]),
              withKey(key): { key: key },
              '#withOperator':: d.fn(help="\"Operator represents a key's relationship to the value.\\nValid operators are Exists and Equal. Defaults to Equal.\\nExists is equivalent to wildcard for value, so that a pod can\\ntolerate all taints of a particular category.\"", args=[d.arg(name='operator', type=d.T.string)]),
              withOperator(operator): { operator: operator },
              '#withTolerationSeconds':: d.fn(help='"TolerationSeconds represents the period of time the toleration (which must be\\nof effect NoExecute, otherwise this field is ignored) tolerates the taint. By default,\\nit is not set, which means tolerate the taint forever (do not evict). Zero and\\nnegative values will be treated as 0 (evict immediately) by the system."', args=[d.arg(name='tolerationSeconds', type=d.T.integer)]),
              withTolerationSeconds(tolerationSeconds): { tolerationSeconds: tolerationSeconds },
              '#withValue':: d.fn(help='"Value is the taint value the toleration matches to.\\nIf the operator is Exists, the value should be empty, otherwise just a regular string."', args=[d.arg(name='value', type=d.T.string)]),
              withValue(value): { value: value },
            },
            '#topologySpreadConstraints':: d.obj(help='"TopologySpreadConstraints describes how a group of pods ought to spread across topology\\ndomains. Scheduler will schedule pods in a way which abides by the constraints.\\nAll topologySpreadConstraints are ANDed."'),
            topologySpreadConstraints: {
              '#labelSelector':: d.obj(help='"LabelSelector is used to find matching pods.\\nPods that match this label selector are counted to determine the number of pods\\nin their corresponding topology domain."'),
              labelSelector: {
                '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                matchExpressions: {
                  '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { key: key },
                  '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                  withOperator(operator): { operator: operator },
                  '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                  withValues(values): { values: if std.isArray(v=values) then values else [values] },
                  '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                  withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                },
                '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressions(matchExpressions): { labelSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressionsMixin(matchExpressions): { labelSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabels(matchLabels): { labelSelector+: { matchLabels: matchLabels } },
                '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabelsMixin(matchLabels): { labelSelector+: { matchLabels+: matchLabels } },
              },
              '#withMatchLabelKeys':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select the pods over which\\nspreading will be calculated. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are ANDed with labelSelector\\nto select the group of existing pods over which spreading will be calculated\\nfor the incoming pod. The same key is forbidden to exist in both MatchLabelKeys and LabelSelector.\\nMatchLabelKeys cannot be set when LabelSelector isn't set.\\nKeys that don't exist in the incoming pod labels will\\nbe ignored. A null or empty list means only match against labelSelector.\\n\\nThis is a beta field and requires the MatchLabelKeysInPodTopologySpread feature gate to be enabled (enabled by default).\"", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
              withMatchLabelKeys(matchLabelKeys): { matchLabelKeys: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] },
              '#withMatchLabelKeysMixin':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select the pods over which\\nspreading will be calculated. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are ANDed with labelSelector\\nto select the group of existing pods over which spreading will be calculated\\nfor the incoming pod. The same key is forbidden to exist in both MatchLabelKeys and LabelSelector.\\nMatchLabelKeys cannot be set when LabelSelector isn't set.\\nKeys that don't exist in the incoming pod labels will\\nbe ignored. A null or empty list means only match against labelSelector.\\n\\nThis is a beta field and requires the MatchLabelKeysInPodTopologySpread feature gate to be enabled (enabled by default).\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
              withMatchLabelKeysMixin(matchLabelKeys): { matchLabelKeys+: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] },
              '#withMaxSkew':: d.fn(help="\"MaxSkew describes the degree to which pods may be unevenly distributed.\\nWhen `whenUnsatisfiable=DoNotSchedule`, it is the maximum permitted difference\\nbetween the number of matching pods in the target topology and the global minimum.\\nThe global minimum is the minimum number of matching pods in an eligible domain\\nor zero if the number of eligible domains is less than MinDomains.\\nFor example, in a 3-zone cluster, MaxSkew is set to 1, and pods with the same\\nlabelSelector spread as 2/2/1:\\nIn this case, the global minimum is 1.\\n| zone1 | zone2 | zone3 |\\n|  P P  |  P P  |   P   |\\n- if MaxSkew is 1, incoming pod can only be scheduled to zone3 to become 2/2/2;\\nscheduling it onto zone1(zone2) would make the ActualSkew(3-1) on zone1(zone2)\\nviolate MaxSkew(1).\\n- if MaxSkew is 2, incoming pod can be scheduled onto any zone.\\nWhen `whenUnsatisfiable=ScheduleAnyway`, it is used to give higher precedence\\nto topologies that satisfy it.\\nIt's a required field. Default value is 1 and 0 is not allowed.\"", args=[d.arg(name='maxSkew', type=d.T.integer)]),
              withMaxSkew(maxSkew): { maxSkew: maxSkew },
              '#withMinDomains':: d.fn(help="\"MinDomains indicates a minimum number of eligible domains.\\nWhen the number of eligible domains with matching topology keys is less than minDomains,\\nPod Topology Spread treats \\\"global minimum\\\" as 0, and then the calculation of Skew is performed.\\nAnd when the number of eligible domains with matching topology keys equals or greater than minDomains,\\nthis value has no effect on scheduling.\\nAs a result, when the number of eligible domains is less than minDomains,\\nscheduler won't schedule more than maxSkew Pods to those domains.\\nIf value is nil, the constraint behaves as if MinDomains is equal to 1.\\nValid values are integers greater than 0.\\nWhen value is not nil, WhenUnsatisfiable must be DoNotSchedule.\\n\\nFor example, in a 3-zone cluster, MaxSkew is set to 2, MinDomains is set to 5 and pods with the same\\nlabelSelector spread as 2/2/2:\\n| zone1 | zone2 | zone3 |\\n|  P P  |  P P  |  P P  |\\nThe number of domains is less than 5(MinDomains), so \\\"global minimum\\\" is treated as 0.\\nIn this situation, new pod with the same labelSelector cannot be scheduled,\\nbecause computed skew will be 3(3 - 0) if new Pod is scheduled to any of the three zones,\\nit will violate MaxSkew.\"", args=[d.arg(name='minDomains', type=d.T.integer)]),
              withMinDomains(minDomains): { minDomains: minDomains },
              '#withNodeAffinityPolicy':: d.fn(help="\"NodeAffinityPolicy indicates how we will treat Pod's nodeAffinity/nodeSelector\\nwhen calculating pod topology spread skew. Options are:\\n- Honor: only nodes matching nodeAffinity/nodeSelector are included in the calculations.\\n- Ignore: nodeAffinity/nodeSelector are ignored. All nodes are included in the calculations.\\n\\nIf this value is nil, the behavior is equivalent to the Honor policy.\"", args=[d.arg(name='nodeAffinityPolicy', type=d.T.string)]),
              withNodeAffinityPolicy(nodeAffinityPolicy): { nodeAffinityPolicy: nodeAffinityPolicy },
              '#withNodeTaintsPolicy':: d.fn(help='"NodeTaintsPolicy indicates how we will treat node taints when calculating\\npod topology spread skew. Options are:\\n- Honor: nodes without taints, along with tainted nodes for which the incoming pod\\nhas a toleration, are included.\\n- Ignore: node taints are ignored. All nodes are included.\\n\\nIf this value is nil, the behavior is equivalent to the Ignore policy."', args=[d.arg(name='nodeTaintsPolicy', type=d.T.string)]),
              withNodeTaintsPolicy(nodeTaintsPolicy): { nodeTaintsPolicy: nodeTaintsPolicy },
              '#withTopologyKey':: d.fn(help="\"TopologyKey is the key of node labels. Nodes that have a label with this key\\nand identical values are considered to be in the same topology.\\nWe consider each \u003ckey, value\u003e as a \\\"bucket\\\", and try to put balanced number\\nof pods into each bucket.\\nWe define a domain as a particular instance of a topology.\\nAlso, we define an eligible domain as a domain whose nodes meet the requirements of\\nnodeAffinityPolicy and nodeTaintsPolicy.\\ne.g. If TopologyKey is \\\"kubernetes.io/hostname\\\", each Node is a domain of that topology.\\nAnd, if TopologyKey is \\\"topology.kubernetes.io/zone\\\", each zone is a domain of that topology.\\nIt's a required field.\"", args=[d.arg(name='topologyKey', type=d.T.string)]),
              withTopologyKey(topologyKey): { topologyKey: topologyKey },
              '#withWhenUnsatisfiable':: d.fn(help="\"WhenUnsatisfiable indicates how to deal with a pod if it doesn't satisfy\\nthe spread constraint.\\n- DoNotSchedule (default) tells the scheduler not to schedule it.\\n- ScheduleAnyway tells the scheduler to schedule the pod in any location,\\n  but giving higher precedence to topologies that would help reduce the\\n  skew.\\nA constraint is considered \\\"Unsatisfiable\\\" for an incoming pod\\nif and only if every possible node assignment for that pod would violate\\n\\\"MaxSkew\\\" on some topology.\\nFor example, in a 3-zone cluster, MaxSkew is set to 1, and pods with the same\\nlabelSelector spread as 3/1/1:\\n| zone1 | zone2 | zone3 |\\n| P P P |   P   |   P   |\\nIf WhenUnsatisfiable is set to DoNotSchedule, incoming pod can only be scheduled\\nto zone2(zone3) to become 3/2/1(3/1/2) as ActualSkew(2-1) on zone2(zone3) satisfies\\nMaxSkew(1). In other words, the cluster can still be imbalanced, but scheduler\\nwon't make it *more* imbalanced.\\nIt's a required field.\"", args=[d.arg(name='whenUnsatisfiable', type=d.T.string)]),
              withWhenUnsatisfiable(whenUnsatisfiable): { whenUnsatisfiable: whenUnsatisfiable },
            },
            '#volumes':: d.obj(help='"Volumes that can be mounted by containers belonging to the pod.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes"'),
            volumes: {
              '#awsElasticBlockStore':: d.obj(help="\"awsElasticBlockStore represents an AWS Disk resource that is attached to a\\nkubelet's host machine and then exposed to the pod.\\nDeprecated: AWSElasticBlockStore is deprecated. All operations for the in-tree\\nawsElasticBlockStore type are redirected to the ebs.csi.aws.com CSI driver.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore\""),
              awsElasticBlockStore: {
                '#withFsType':: d.fn(help='"fsType is the filesystem type of the volume that you want to mount.\\nTip: Ensure that the filesystem type is supported by the host operating system.\\nExamples: \\"ext4\\", \\"xfs\\", \\"ntfs\\". Implicitly inferred to be \\"ext4\\" if unspecified.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore"', args=[d.arg(name='fsType', type=d.T.string)]),
                withFsType(fsType): { awsElasticBlockStore+: { fsType: fsType } },
                '#withPartition':: d.fn(help='"partition is the partition in the volume that you want to mount.\\nIf omitted, the default is to mount by volume name.\\nExamples: For volume /dev/sda1, you specify the partition as \\"1\\".\\nSimilarly, the volume partition for /dev/sda is \\"0\\" (or you can leave the property empty)."', args=[d.arg(name='partition', type=d.T.integer)]),
                withPartition(partition): { awsElasticBlockStore+: { partition: partition } },
                '#withReadOnly':: d.fn(help='"readOnly value true will force the readOnly setting in VolumeMounts.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore"', args=[d.arg(name='readOnly', type=d.T.boolean)]),
                withReadOnly(readOnly): { awsElasticBlockStore+: { readOnly: readOnly } },
                '#withVolumeID':: d.fn(help='"volumeID is unique ID of the persistent disk resource in AWS (Amazon EBS volume).\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore"', args=[d.arg(name='volumeID', type=d.T.string)]),
                withVolumeID(volumeID): { awsElasticBlockStore+: { volumeID: volumeID } },
              },
              '#azureDisk':: d.obj(help='"azureDisk represents an Azure Data Disk mount on the host and bind mount to the pod.\\nDeprecated: AzureDisk is deprecated. All operations for the in-tree azureDisk type\\nare redirected to the disk.csi.azure.com CSI driver."'),
              azureDisk: {
                '#withCachingMode':: d.fn(help='"cachingMode is the Host Caching mode: None, Read Only, Read Write."', args=[d.arg(name='cachingMode', type=d.T.string)]),
                withCachingMode(cachingMode): { azureDisk+: { cachingMode: cachingMode } },
                '#withDiskName':: d.fn(help='"diskName is the Name of the data disk in the blob storage"', args=[d.arg(name='diskName', type=d.T.string)]),
                withDiskName(diskName): { azureDisk+: { diskName: diskName } },
                '#withDiskURI':: d.fn(help='"diskURI is the URI of data disk in the blob storage"', args=[d.arg(name='diskURI', type=d.T.string)]),
                withDiskURI(diskURI): { azureDisk+: { diskURI: diskURI } },
                '#withFsType':: d.fn(help='"fsType is Filesystem type to mount.\\nMust be a filesystem type supported by the host operating system.\\nEx. \\"ext4\\", \\"xfs\\", \\"ntfs\\". Implicitly inferred to be \\"ext4\\" if unspecified."', args=[d.arg(name='fsType', type=d.T.string)]),
                withFsType(fsType): { azureDisk+: { fsType: fsType } },
                '#withKind':: d.fn(help='"kind expected values are Shared: multiple blob disks per storage account  Dedicated: single blob disk per storage account  Managed: azure managed data disk (only in managed availability set). defaults to shared"', args=[d.arg(name='kind', type=d.T.string)]),
                withKind(kind): { azureDisk+: { kind: kind } },
                '#withReadOnly':: d.fn(help='"readOnly Defaults to false (read/write). ReadOnly here will force\\nthe ReadOnly setting in VolumeMounts."', args=[d.arg(name='readOnly', type=d.T.boolean)]),
                withReadOnly(readOnly): { azureDisk+: { readOnly: readOnly } },
              },
              '#azureFile':: d.obj(help='"azureFile represents an Azure File Service mount on the host and bind mount to the pod.\\nDeprecated: AzureFile is deprecated. All operations for the in-tree azureFile type\\nare redirected to the file.csi.azure.com CSI driver."'),
              azureFile: {
                '#withReadOnly':: d.fn(help='"readOnly defaults to false (read/write). ReadOnly here will force\\nthe ReadOnly setting in VolumeMounts."', args=[d.arg(name='readOnly', type=d.T.boolean)]),
                withReadOnly(readOnly): { azureFile+: { readOnly: readOnly } },
                '#withSecretName':: d.fn(help='"secretName is the  name of secret that contains Azure Storage Account Name and Key"', args=[d.arg(name='secretName', type=d.T.string)]),
                withSecretName(secretName): { azureFile+: { secretName: secretName } },
                '#withShareName':: d.fn(help='"shareName is the azure share Name"', args=[d.arg(name='shareName', type=d.T.string)]),
                withShareName(shareName): { azureFile+: { shareName: shareName } },
              },
              '#cephfs':: d.obj(help="\"cephFS represents a Ceph FS mount on the host that shares a pod's lifetime.\\nDeprecated: CephFS is deprecated and the in-tree cephfs type is no longer supported.\""),
              cephfs: {
                '#secretRef':: d.obj(help='"secretRef is Optional: SecretRef is reference to the authentication secret for User, default is empty.\\nMore info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it"'),
                secretRef: {
                  '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
                  withName(name): { cephfs+: { secretRef+: { name: name } } },
                },
                '#withMonitors':: d.fn(help='"monitors is Required: Monitors is a collection of Ceph monitors\\nMore info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it"', args=[d.arg(name='monitors', type=d.T.array)]),
                withMonitors(monitors): { cephfs+: { monitors: if std.isArray(v=monitors) then monitors else [monitors] } },
                '#withMonitorsMixin':: d.fn(help='"monitors is Required: Monitors is a collection of Ceph monitors\\nMore info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='monitors', type=d.T.array)]),
                withMonitorsMixin(monitors): { cephfs+: { monitors+: if std.isArray(v=monitors) then monitors else [monitors] } },
                '#withPath':: d.fn(help='"path is Optional: Used as the mounted root, rather than the full Ceph tree, default is /"', args=[d.arg(name='path', type=d.T.string)]),
                withPath(path): { cephfs+: { path: path } },
                '#withReadOnly':: d.fn(help='"readOnly is Optional: Defaults to false (read/write). ReadOnly here will force\\nthe ReadOnly setting in VolumeMounts.\\nMore info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it"', args=[d.arg(name='readOnly', type=d.T.boolean)]),
                withReadOnly(readOnly): { cephfs+: { readOnly: readOnly } },
                '#withSecretFile':: d.fn(help='"secretFile is Optional: SecretFile is the path to key ring for User, default is /etc/ceph/user.secret\\nMore info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it"', args=[d.arg(name='secretFile', type=d.T.string)]),
                withSecretFile(secretFile): { cephfs+: { secretFile: secretFile } },
                '#withUser':: d.fn(help='"user is optional: User is the rados user name, default is admin\\nMore info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it"', args=[d.arg(name='user', type=d.T.string)]),
                withUser(user): { cephfs+: { user: user } },
              },
              '#cinder':: d.obj(help='"cinder represents a cinder volume attached and mounted on kubelets host machine.\\nDeprecated: Cinder is deprecated. All operations for the in-tree cinder type\\nare redirected to the cinder.csi.openstack.org CSI driver.\\nMore info: https://examples.k8s.io/mysql-cinder-pd/README.md"'),
              cinder: {
                '#secretRef':: d.obj(help='"secretRef is optional: points to a secret object containing parameters used to connect\\nto OpenStack."'),
                secretRef: {
                  '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
                  withName(name): { cinder+: { secretRef+: { name: name } } },
                },
                '#withFsType':: d.fn(help='"fsType is the filesystem type to mount.\\nMust be a filesystem type supported by the host operating system.\\nExamples: \\"ext4\\", \\"xfs\\", \\"ntfs\\". Implicitly inferred to be \\"ext4\\" if unspecified.\\nMore info: https://examples.k8s.io/mysql-cinder-pd/README.md"', args=[d.arg(name='fsType', type=d.T.string)]),
                withFsType(fsType): { cinder+: { fsType: fsType } },
                '#withReadOnly':: d.fn(help='"readOnly defaults to false (read/write). ReadOnly here will force\\nthe ReadOnly setting in VolumeMounts.\\nMore info: https://examples.k8s.io/mysql-cinder-pd/README.md"', args=[d.arg(name='readOnly', type=d.T.boolean)]),
                withReadOnly(readOnly): { cinder+: { readOnly: readOnly } },
                '#withVolumeID':: d.fn(help='"volumeID used to identify the volume in cinder.\\nMore info: https://examples.k8s.io/mysql-cinder-pd/README.md"', args=[d.arg(name='volumeID', type=d.T.string)]),
                withVolumeID(volumeID): { cinder+: { volumeID: volumeID } },
              },
              '#configMap':: d.obj(help='"configMap represents a configMap that should populate this volume"'),
              configMap: {
                '#items':: d.obj(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nConfigMap will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the ConfigMap,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\""),
                items: {
                  '#withKey':: d.fn(help='"key is the key to project."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { key: key },
                  '#withMode':: d.fn(help='"mode is Optional: mode bits used to set permissions on this file.\\nMust be an octal value between 0000 and 0777 or a decimal value between 0 and 511.\\nYAML accepts both octal and decimal values, JSON requires decimal values for mode bits.\\nIf not specified, the volume defaultMode will be used.\\nThis might be in conflict with other options that affect the file\\nmode, like fsGroup, and the result can be other mode bits set."', args=[d.arg(name='mode', type=d.T.integer)]),
                  withMode(mode): { mode: mode },
                  '#withPath':: d.fn(help="\"path is the relative path of the file to map the key to.\\nMay not be an absolute path.\\nMay not contain the path element '..'.\\nMay not start with the string '..'.\"", args=[d.arg(name='path', type=d.T.string)]),
                  withPath(path): { path: path },
                },
                '#withDefaultMode':: d.fn(help='"defaultMode is optional: mode bits used to set permissions on created files by default.\\nMust be an octal value between 0000 and 0777 or a decimal value between 0 and 511.\\nYAML accepts both octal and decimal values, JSON requires decimal values for mode bits.\\nDefaults to 0644.\\nDirectories within the path are not affected by this setting.\\nThis might be in conflict with other options that affect the file\\nmode, like fsGroup, and the result can be other mode bits set."', args=[d.arg(name='defaultMode', type=d.T.integer)]),
                withDefaultMode(defaultMode): { configMap+: { defaultMode: defaultMode } },
                '#withItems':: d.fn(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nConfigMap will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the ConfigMap,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\"", args=[d.arg(name='items', type=d.T.array)]),
                withItems(items): { configMap+: { items: if std.isArray(v=items) then items else [items] } },
                '#withItemsMixin':: d.fn(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nConfigMap will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the ConfigMap,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='items', type=d.T.array)]),
                withItemsMixin(items): { configMap+: { items+: if std.isArray(v=items) then items else [items] } },
                '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
                withName(name): { configMap+: { name: name } },
                '#withOptional':: d.fn(help='"optional specify whether the ConfigMap or its keys must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
                withOptional(optional): { configMap+: { optional: optional } },
              },
              '#csi':: d.obj(help='"csi (Container Storage Interface) represents ephemeral storage that is handled by certain external CSI drivers."'),
              csi: {
                '#nodePublishSecretRef':: d.obj(help='"nodePublishSecretRef is a reference to the secret object containing\\nsensitive information to pass to the CSI driver to complete the CSI\\nNodePublishVolume and NodeUnpublishVolume calls.\\nThis field is optional, and  may be empty if no secret is required. If the\\nsecret object contains more than one secret, all secret references are passed."'),
                nodePublishSecretRef: {
                  '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
                  withName(name): { csi+: { nodePublishSecretRef+: { name: name } } },
                },
                '#withDriver':: d.fn(help='"driver is the name of the CSI driver that handles this volume.\\nConsult with your admin for the correct name as registered in the cluster."', args=[d.arg(name='driver', type=d.T.string)]),
                withDriver(driver): { csi+: { driver: driver } },
                '#withFsType':: d.fn(help='"fsType to mount. Ex. \\"ext4\\", \\"xfs\\", \\"ntfs\\".\\nIf not provided, the empty value is passed to the associated CSI driver\\nwhich will determine the default filesystem to apply."', args=[d.arg(name='fsType', type=d.T.string)]),
                withFsType(fsType): { csi+: { fsType: fsType } },
                '#withReadOnly':: d.fn(help='"readOnly specifies a read-only configuration for the volume.\\nDefaults to false (read/write)."', args=[d.arg(name='readOnly', type=d.T.boolean)]),
                withReadOnly(readOnly): { csi+: { readOnly: readOnly } },
                '#withVolumeAttributes':: d.fn(help="\"volumeAttributes stores driver-specific properties that are passed to the CSI\\ndriver. Consult your driver's documentation for supported values.\"", args=[d.arg(name='volumeAttributes', type=d.T.object)]),
                withVolumeAttributes(volumeAttributes): { csi+: { volumeAttributes: volumeAttributes } },
                '#withVolumeAttributesMixin':: d.fn(help="\"volumeAttributes stores driver-specific properties that are passed to the CSI\\ndriver. Consult your driver's documentation for supported values.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='volumeAttributes', type=d.T.object)]),
                withVolumeAttributesMixin(volumeAttributes): { csi+: { volumeAttributes+: volumeAttributes } },
              },
              '#downwardAPI':: d.obj(help='"downwardAPI represents downward API about the pod that should populate this volume"'),
              downwardAPI: {
                '#items':: d.obj(help='"Items is a list of downward API volume file"'),
                items: {
                  '#fieldRef':: d.obj(help='"Required: Selects a field of the pod: only annotations, labels, name, namespace and uid are supported."'),
                  fieldRef: {
                    '#withApiVersion':: d.fn(help='"Version of the schema the FieldPath is written in terms of, defaults to \\"v1\\"."', args=[d.arg(name='apiVersion', type=d.T.string)]),
                    withApiVersion(apiVersion): { fieldRef+: { apiVersion: apiVersion } },
                    '#withFieldPath':: d.fn(help='"Path of the field to select in the specified API version."', args=[d.arg(name='fieldPath', type=d.T.string)]),
                    withFieldPath(fieldPath): { fieldRef+: { fieldPath: fieldPath } },
                  },
                  '#resourceFieldRef':: d.obj(help='"Selects a resource of the container: only resources limits and requests\\n(limits.cpu, limits.memory, requests.cpu and requests.memory) are currently supported."'),
                  resourceFieldRef: {
                    '#withContainerName':: d.fn(help='"Container name: required for volumes, optional for env vars"', args=[d.arg(name='containerName', type=d.T.string)]),
                    withContainerName(containerName): { resourceFieldRef+: { containerName: containerName } },
                    '#withDivisor':: d.fn(help='"Specifies the output format of the exposed resources, defaults to \\"1\\', args=[d.arg(name='divisor', type=d.T.any)]),
                    withDivisor(divisor): { resourceFieldRef+: { divisor: divisor } },
                    '#withResource':: d.fn(help='"Required: resource to select"', args=[d.arg(name='resource', type=d.T.string)]),
                    withResource(resource): { resourceFieldRef+: { resource: resource } },
                  },
                  '#withMode':: d.fn(help='"Optional: mode bits used to set permissions on this file, must be an octal value\\nbetween 0000 and 0777 or a decimal value between 0 and 511.\\nYAML accepts both octal and decimal values, JSON requires decimal values for mode bits.\\nIf not specified, the volume defaultMode will be used.\\nThis might be in conflict with other options that affect the file\\nmode, like fsGroup, and the result can be other mode bits set."', args=[d.arg(name='mode', type=d.T.integer)]),
                  withMode(mode): { mode: mode },
                  '#withPath':: d.fn(help="\"Required: Path is  the relative path name of the file to be created. Must not be absolute or contain the '..' path. Must be utf-8 encoded. The first item of the relative path must not start with '..'\"", args=[d.arg(name='path', type=d.T.string)]),
                  withPath(path): { path: path },
                },
                '#withDefaultMode':: d.fn(help='"Optional: mode bits to use on created files by default. Must be a\\nOptional: mode bits used to set permissions on created files by default.\\nMust be an octal value between 0000 and 0777 or a decimal value between 0 and 511.\\nYAML accepts both octal and decimal values, JSON requires decimal values for mode bits.\\nDefaults to 0644.\\nDirectories within the path are not affected by this setting.\\nThis might be in conflict with other options that affect the file\\nmode, like fsGroup, and the result can be other mode bits set."', args=[d.arg(name='defaultMode', type=d.T.integer)]),
                withDefaultMode(defaultMode): { downwardAPI+: { defaultMode: defaultMode } },
                '#withItems':: d.fn(help='"Items is a list of downward API volume file"', args=[d.arg(name='items', type=d.T.array)]),
                withItems(items): { downwardAPI+: { items: if std.isArray(v=items) then items else [items] } },
                '#withItemsMixin':: d.fn(help='"Items is a list of downward API volume file"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='items', type=d.T.array)]),
                withItemsMixin(items): { downwardAPI+: { items+: if std.isArray(v=items) then items else [items] } },
              },
              '#emptyDir':: d.obj(help="\"emptyDir represents a temporary directory that shares a pod's lifetime.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#emptydir\""),
              emptyDir: {
                '#withMedium':: d.fn(help="\"medium represents what type of storage medium should back this directory.\\nThe default is \\\"\\\" which means to use the node's default medium.\\nMust be an empty string (default) or Memory.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#emptydir\"", args=[d.arg(name='medium', type=d.T.string)]),
                withMedium(medium): { emptyDir+: { medium: medium } },
                '#withSizeLimit':: d.fn(help='"sizeLimit is the total amount of local storage required for this EmptyDir volume.\\nThe size limit is also applicable for memory medium.\\nThe maximum usage on memory medium EmptyDir would be the minimum value between\\nthe SizeLimit specified here and the sum of memory limits of all containers in a pod.\\nThe default is nil which means that the limit is undefined.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#emptydir"', args=[d.arg(name='sizeLimit', type=d.T.any)]),
                withSizeLimit(sizeLimit): { emptyDir+: { sizeLimit: sizeLimit } },
              },
              '#ephemeral':: d.obj(help="\"ephemeral represents a volume that is handled by a cluster storage driver.\\nThe volume's lifecycle is tied to the pod that defines it - it will be created before the pod starts,\\nand deleted when the pod is removed.\\n\\nUse this if:\\na) the volume is only needed while the pod runs,\\nb) features of normal volumes like restoring from snapshot or capacity\\n   tracking are needed,\\nc) the storage driver is specified through a storage class, and\\nd) the storage driver supports dynamic volume provisioning through\\n   a PersistentVolumeClaim (see EphemeralVolumeSource for more\\n   information on the connection between this volume type\\n   and PersistentVolumeClaim).\\n\\nUse PersistentVolumeClaim or one of the vendor-specific\\nAPIs for volumes that persist for longer than the lifecycle\\nof an individual pod.\\n\\nUse CSI for light-weight local ephemeral volumes if the CSI driver is meant to\\nbe used that way - see the documentation of the driver for\\nmore information.\\n\\nA pod can use both types of ephemeral volumes and\\npersistent volumes at the same time.\""),
              ephemeral: {
                '#volumeClaimTemplate':: d.obj(help='"Will be used to create a stand-alone PVC to provision the volume.\\nThe pod in which this EphemeralVolumeSource is embedded will be the\\nowner of the PVC, i.e. the PVC will be deleted together with the\\npod.  The name of the PVC will be `<pod name>-<volume name>` where\\n`<volume name>` is the name from the `PodSpec.Volumes` array\\nentry. Pod validation will reject the pod if the concatenated name\\nis not valid for a PVC (for example, too long).\\n\\nAn existing PVC with that name that is not owned by the pod\\nwill *not* be used for the pod to avoid using an unrelated\\nvolume by mistake. Starting the pod is then blocked until\\nthe unrelated PVC is removed. If such a pre-created PVC is\\nmeant to be used by the pod, the PVC has to updated with an\\nowner reference to the pod once the pod exists. Normally\\nthis should not be necessary, but it may be useful when\\nmanually reconstructing a broken cluster.\\n\\nThis field is read-only and no changes will be made by Kubernetes\\nto the PVC after it has been created.\\n\\nRequired, must not be nil."'),
                volumeClaimTemplate: {
                  '#spec':: d.obj(help='"The specification for the PersistentVolumeClaim. The entire content is\\ncopied unchanged into the PVC that gets created from this\\ntemplate. The same fields as in a PersistentVolumeClaim\\nare also valid here."'),
                  spec: {
                    '#dataSource':: d.obj(help='"dataSource field can be used to specify either:\\n* An existing VolumeSnapshot object (snapshot.storage.k8s.io/VolumeSnapshot)\\n* An existing PVC (PersistentVolumeClaim)\\nIf the provisioner or an external controller can support the specified data source,\\nit will create a new volume based on the contents of the specified data source.\\nWhen the AnyVolumeDataSource feature gate is enabled, dataSource contents will be copied to dataSourceRef,\\nand dataSourceRef contents will be copied to dataSource when dataSourceRef.namespace is not specified.\\nIf the namespace is specified, then dataSourceRef will not be copied to dataSource."'),
                    dataSource: {
                      '#withApiGroup':: d.fn(help='"APIGroup is the group for the resource being referenced.\\nIf APIGroup is not specified, the specified Kind must be in the core API group.\\nFor any other third-party types, APIGroup is required."', args=[d.arg(name='apiGroup', type=d.T.string)]),
                      withApiGroup(apiGroup): { ephemeral+: { volumeClaimTemplate+: { spec+: { dataSource+: { apiGroup: apiGroup } } } } },
                      '#withKind':: d.fn(help='"Kind is the type of resource being referenced"', args=[d.arg(name='kind', type=d.T.string)]),
                      withKind(kind): { ephemeral+: { volumeClaimTemplate+: { spec+: { dataSource+: { kind: kind } } } } },
                      '#withName':: d.fn(help='"Name is the name of resource being referenced"', args=[d.arg(name='name', type=d.T.string)]),
                      withName(name): { ephemeral+: { volumeClaimTemplate+: { spec+: { dataSource+: { name: name } } } } },
                    },
                    '#dataSourceRef':: d.obj(help="\"dataSourceRef specifies the object from which to populate the volume with data, if a non-empty\\nvolume is desired. This may be any object from a non-empty API group (non\\ncore object) or a PersistentVolumeClaim object.\\nWhen this field is specified, volume binding will only succeed if the type of\\nthe specified object matches some installed volume populator or dynamic\\nprovisioner.\\nThis field will replace the functionality of the dataSource field and as such\\nif both fields are non-empty, they must have the same value. For backwards\\ncompatibility, when namespace isn't specified in dataSourceRef,\\nboth fields (dataSource and dataSourceRef) will be set to the same\\nvalue automatically if one of them is empty and the other is non-empty.\\nWhen namespace is specified in dataSourceRef,\\ndataSource isn't set to the same value and must be empty.\\nThere are three important differences between dataSource and dataSourceRef:\\n* While dataSource only allows two specific types of objects, dataSourceRef\\n  allows any non-core object, as well as PersistentVolumeClaim objects.\\n* While dataSource ignores disallowed values (dropping them), dataSourceRef\\n  preserves all values, and generates an error if a disallowed value is\\n  specified.\\n* While dataSource only allows local objects, dataSourceRef allows objects\\n  in any namespaces.\\n(Beta) Using this field requires the AnyVolumeDataSource feature gate to be enabled.\\n(Alpha) Using the namespace field of dataSourceRef requires the CrossNamespaceVolumeDataSource feature gate to be enabled.\""),
                    dataSourceRef: {
                      '#withApiGroup':: d.fn(help='"APIGroup is the group for the resource being referenced.\\nIf APIGroup is not specified, the specified Kind must be in the core API group.\\nFor any other third-party types, APIGroup is required."', args=[d.arg(name='apiGroup', type=d.T.string)]),
                      withApiGroup(apiGroup): { ephemeral+: { volumeClaimTemplate+: { spec+: { dataSourceRef+: { apiGroup: apiGroup } } } } },
                      '#withKind':: d.fn(help='"Kind is the type of resource being referenced"', args=[d.arg(name='kind', type=d.T.string)]),
                      withKind(kind): { ephemeral+: { volumeClaimTemplate+: { spec+: { dataSourceRef+: { kind: kind } } } } },
                      '#withName':: d.fn(help='"Name is the name of resource being referenced"', args=[d.arg(name='name', type=d.T.string)]),
                      withName(name): { ephemeral+: { volumeClaimTemplate+: { spec+: { dataSourceRef+: { name: name } } } } },
                      '#withNamespace':: d.fn(help="\"Namespace is the namespace of resource being referenced\\nNote that when a namespace is specified, a gateway.networking.k8s.io/ReferenceGrant object is required in the referent namespace to allow that namespace's owner to accept the reference. See the ReferenceGrant documentation for details.\\n(Alpha) This field requires the CrossNamespaceVolumeDataSource feature gate to be enabled.\"", args=[d.arg(name='namespace', type=d.T.string)]),
                      withNamespace(namespace): { ephemeral+: { volumeClaimTemplate+: { spec+: { dataSourceRef+: { namespace: namespace } } } } },
                    },
                    '#resources':: d.obj(help='"resources represents the minimum resources the volume should have.\\nIf RecoverVolumeExpansionFailure feature is enabled users are allowed to specify resource requirements\\nthat are lower than previous value but must still be higher than capacity recorded in the\\nstatus field of the claim.\\nMore info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#resources"'),
                    resources: {
                      '#withLimits':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='limits', type=d.T.object)]),
                      withLimits(limits): { ephemeral+: { volumeClaimTemplate+: { spec+: { resources+: { limits: limits } } } } },
                      '#withLimitsMixin':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='limits', type=d.T.object)]),
                      withLimitsMixin(limits): { ephemeral+: { volumeClaimTemplate+: { spec+: { resources+: { limits+: limits } } } } },
                      '#withRequests':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='requests', type=d.T.object)]),
                      withRequests(requests): { ephemeral+: { volumeClaimTemplate+: { spec+: { resources+: { requests: requests } } } } },
                      '#withRequestsMixin':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requests', type=d.T.object)]),
                      withRequestsMixin(requests): { ephemeral+: { volumeClaimTemplate+: { spec+: { resources+: { requests+: requests } } } } },
                    },
                    '#selector':: d.obj(help='"selector is a label query over volumes to consider for binding."'),
                    selector: {
                      '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                      matchExpressions: {
                        '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                        withKey(key): { key: key },
                        '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                        withOperator(operator): { operator: operator },
                        '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                        withValues(values): { values: if std.isArray(v=values) then values else [values] },
                        '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                        withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                      },
                      '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                      withMatchExpressions(matchExpressions): { ephemeral+: { volumeClaimTemplate+: { spec+: { selector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } } } },
                      '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                      withMatchExpressionsMixin(matchExpressions): { ephemeral+: { volumeClaimTemplate+: { spec+: { selector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } } } },
                      '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                      withMatchLabels(matchLabels): { ephemeral+: { volumeClaimTemplate+: { spec+: { selector+: { matchLabels: matchLabels } } } } },
                      '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                      withMatchLabelsMixin(matchLabels): { ephemeral+: { volumeClaimTemplate+: { spec+: { selector+: { matchLabels+: matchLabels } } } } },
                    },
                    '#withAccessModes':: d.fn(help='"accessModes contains the desired access modes the volume should have.\\nMore info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#access-modes-1"', args=[d.arg(name='accessModes', type=d.T.array)]),
                    withAccessModes(accessModes): { ephemeral+: { volumeClaimTemplate+: { spec+: { accessModes: if std.isArray(v=accessModes) then accessModes else [accessModes] } } } },
                    '#withAccessModesMixin':: d.fn(help='"accessModes contains the desired access modes the volume should have.\\nMore info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#access-modes-1"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='accessModes', type=d.T.array)]),
                    withAccessModesMixin(accessModes): { ephemeral+: { volumeClaimTemplate+: { spec+: { accessModes+: if std.isArray(v=accessModes) then accessModes else [accessModes] } } } },
                    '#withStorageClassName':: d.fn(help='"storageClassName is the name of the StorageClass required by the claim.\\nMore info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#class-1"', args=[d.arg(name='storageClassName', type=d.T.string)]),
                    withStorageClassName(storageClassName): { ephemeral+: { volumeClaimTemplate+: { spec+: { storageClassName: storageClassName } } } },
                    '#withVolumeAttributesClassName':: d.fn(help="\"volumeAttributesClassName may be used to set the VolumeAttributesClass used by this claim.\\nIf specified, the CSI driver will create or update the volume with the attributes defined\\nin the corresponding VolumeAttributesClass. This has a different purpose than storageClassName,\\nit can be changed after the claim is created. An empty string value means that no VolumeAttributesClass\\nwill be applied to the claim but it's not allowed to reset this field to empty string once it is set.\\nIf unspecified and the PersistentVolumeClaim is unbound, the default VolumeAttributesClass\\nwill be set by the persistentvolume controller if it exists.\\nIf the resource referred to by volumeAttributesClass does not exist, this PersistentVolumeClaim will be\\nset to a Pending state, as reflected by the modifyVolumeStatus field, until such as a resource\\nexists.\\nMore info: https://kubernetes.io/docs/concepts/storage/volume-attributes-classes/\\n(Beta) Using this field requires the VolumeAttributesClass feature gate to be enabled (off by default).\"", args=[d.arg(name='volumeAttributesClassName', type=d.T.string)]),
                    withVolumeAttributesClassName(volumeAttributesClassName): { ephemeral+: { volumeClaimTemplate+: { spec+: { volumeAttributesClassName: volumeAttributesClassName } } } },
                    '#withVolumeMode':: d.fn(help='"volumeMode defines what type of volume is required by the claim.\\nValue of Filesystem is implied when not included in claim spec."', args=[d.arg(name='volumeMode', type=d.T.string)]),
                    withVolumeMode(volumeMode): { ephemeral+: { volumeClaimTemplate+: { spec+: { volumeMode: volumeMode } } } },
                    '#withVolumeName':: d.fn(help='"volumeName is the binding reference to the PersistentVolume backing this claim."', args=[d.arg(name='volumeName', type=d.T.string)]),
                    withVolumeName(volumeName): { ephemeral+: { volumeClaimTemplate+: { spec+: { volumeName: volumeName } } } },
                  },
                  '#withMetadata':: d.fn(help='"May contain labels and annotations that will be copied into the PVC\\nwhen creating it. No other fields are allowed and will be rejected during\\nvalidation."', args=[d.arg(name='metadata', type=d.T.object)]),
                  withMetadata(metadata): { ephemeral+: { volumeClaimTemplate+: { metadata: metadata } } },
                  '#withMetadataMixin':: d.fn(help='"May contain labels and annotations that will be copied into the PVC\\nwhen creating it. No other fields are allowed and will be rejected during\\nvalidation."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='metadata', type=d.T.object)]),
                  withMetadataMixin(metadata): { ephemeral+: { volumeClaimTemplate+: { metadata+: metadata } } },
                },
              },
              '#fc':: d.obj(help="\"fc represents a Fibre Channel resource that is attached to a kubelet's host machine and then exposed to the pod.\""),
              fc: {
                '#withFsType':: d.fn(help='"fsType is the filesystem type to mount.\\nMust be a filesystem type supported by the host operating system.\\nEx. \\"ext4\\", \\"xfs\\", \\"ntfs\\". Implicitly inferred to be \\"ext4\\" if unspecified."', args=[d.arg(name='fsType', type=d.T.string)]),
                withFsType(fsType): { fc+: { fsType: fsType } },
                '#withLun':: d.fn(help='"lun is Optional: FC target lun number"', args=[d.arg(name='lun', type=d.T.integer)]),
                withLun(lun): { fc+: { lun: lun } },
                '#withReadOnly':: d.fn(help='"readOnly is Optional: Defaults to false (read/write). ReadOnly here will force\\nthe ReadOnly setting in VolumeMounts."', args=[d.arg(name='readOnly', type=d.T.boolean)]),
                withReadOnly(readOnly): { fc+: { readOnly: readOnly } },
                '#withTargetWWNs':: d.fn(help='"targetWWNs is Optional: FC target worldwide names (WWNs)"', args=[d.arg(name='targetWWNs', type=d.T.array)]),
                withTargetWWNs(targetWWNs): { fc+: { targetWWNs: if std.isArray(v=targetWWNs) then targetWWNs else [targetWWNs] } },
                '#withTargetWWNsMixin':: d.fn(help='"targetWWNs is Optional: FC target worldwide names (WWNs)"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='targetWWNs', type=d.T.array)]),
                withTargetWWNsMixin(targetWWNs): { fc+: { targetWWNs+: if std.isArray(v=targetWWNs) then targetWWNs else [targetWWNs] } },
                '#withWwids':: d.fn(help='"wwids Optional: FC volume world wide identifiers (wwids)\\nEither wwids or combination of targetWWNs and lun must be set, but not both simultaneously."', args=[d.arg(name='wwids', type=d.T.array)]),
                withWwids(wwids): { fc+: { wwids: if std.isArray(v=wwids) then wwids else [wwids] } },
                '#withWwidsMixin':: d.fn(help='"wwids Optional: FC volume world wide identifiers (wwids)\\nEither wwids or combination of targetWWNs and lun must be set, but not both simultaneously."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='wwids', type=d.T.array)]),
                withWwidsMixin(wwids): { fc+: { wwids+: if std.isArray(v=wwids) then wwids else [wwids] } },
              },
              '#flexVolume':: d.obj(help='"flexVolume represents a generic volume resource that is\\nprovisioned/attached using an exec based plugin.\\nDeprecated: FlexVolume is deprecated. Consider using a CSIDriver instead."'),
              flexVolume: {
                '#secretRef':: d.obj(help='"secretRef is Optional: secretRef is reference to the secret object containing\\nsensitive information to pass to the plugin scripts. This may be\\nempty if no secret object is specified. If the secret object\\ncontains more than one secret, all secrets are passed to the plugin\\nscripts."'),
                secretRef: {
                  '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
                  withName(name): { flexVolume+: { secretRef+: { name: name } } },
                },
                '#withDriver':: d.fn(help='"driver is the name of the driver to use for this volume."', args=[d.arg(name='driver', type=d.T.string)]),
                withDriver(driver): { flexVolume+: { driver: driver } },
                '#withFsType':: d.fn(help='"fsType is the filesystem type to mount.\\nMust be a filesystem type supported by the host operating system.\\nEx. \\"ext4\\", \\"xfs\\", \\"ntfs\\". The default filesystem depends on FlexVolume script."', args=[d.arg(name='fsType', type=d.T.string)]),
                withFsType(fsType): { flexVolume+: { fsType: fsType } },
                '#withOptions':: d.fn(help='"options is Optional: this field holds extra command options if any."', args=[d.arg(name='options', type=d.T.object)]),
                withOptions(options): { flexVolume+: { options: options } },
                '#withOptionsMixin':: d.fn(help='"options is Optional: this field holds extra command options if any."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='options', type=d.T.object)]),
                withOptionsMixin(options): { flexVolume+: { options+: options } },
                '#withReadOnly':: d.fn(help='"readOnly is Optional: defaults to false (read/write). ReadOnly here will force\\nthe ReadOnly setting in VolumeMounts."', args=[d.arg(name='readOnly', type=d.T.boolean)]),
                withReadOnly(readOnly): { flexVolume+: { readOnly: readOnly } },
              },
              '#flocker':: d.obj(help="\"flocker represents a Flocker volume attached to a kubelet's host machine. This depends on the Flocker control service being running.\\nDeprecated: Flocker is deprecated and the in-tree flocker type is no longer supported.\""),
              flocker: {
                '#withDatasetName':: d.fn(help='"datasetName is Name of the dataset stored as metadata -> name on the dataset for Flocker\\nshould be considered as deprecated"', args=[d.arg(name='datasetName', type=d.T.string)]),
                withDatasetName(datasetName): { flocker+: { datasetName: datasetName } },
                '#withDatasetUUID':: d.fn(help='"datasetUUID is the UUID of the dataset. This is unique identifier of a Flocker dataset"', args=[d.arg(name='datasetUUID', type=d.T.string)]),
                withDatasetUUID(datasetUUID): { flocker+: { datasetUUID: datasetUUID } },
              },
              '#gcePersistentDisk':: d.obj(help="\"gcePersistentDisk represents a GCE Disk resource that is attached to a\\nkubelet's host machine and then exposed to the pod.\\nDeprecated: GCEPersistentDisk is deprecated. All operations for the in-tree\\ngcePersistentDisk type are redirected to the pd.csi.storage.gke.io CSI driver.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk\""),
              gcePersistentDisk: {
                '#withFsType':: d.fn(help='"fsType is filesystem type of the volume that you want to mount.\\nTip: Ensure that the filesystem type is supported by the host operating system.\\nExamples: \\"ext4\\", \\"xfs\\", \\"ntfs\\". Implicitly inferred to be \\"ext4\\" if unspecified.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk"', args=[d.arg(name='fsType', type=d.T.string)]),
                withFsType(fsType): { gcePersistentDisk+: { fsType: fsType } },
                '#withPartition':: d.fn(help='"partition is the partition in the volume that you want to mount.\\nIf omitted, the default is to mount by volume name.\\nExamples: For volume /dev/sda1, you specify the partition as \\"1\\".\\nSimilarly, the volume partition for /dev/sda is \\"0\\" (or you can leave the property empty).\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk"', args=[d.arg(name='partition', type=d.T.integer)]),
                withPartition(partition): { gcePersistentDisk+: { partition: partition } },
                '#withPdName':: d.fn(help='"pdName is unique name of the PD resource in GCE. Used to identify the disk in GCE.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk"', args=[d.arg(name='pdName', type=d.T.string)]),
                withPdName(pdName): { gcePersistentDisk+: { pdName: pdName } },
                '#withReadOnly':: d.fn(help='"readOnly here will force the ReadOnly setting in VolumeMounts.\\nDefaults to false.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk"', args=[d.arg(name='readOnly', type=d.T.boolean)]),
                withReadOnly(readOnly): { gcePersistentDisk+: { readOnly: readOnly } },
              },
              '#gitRepo':: d.obj(help="\"gitRepo represents a git repository at a particular revision.\\nDeprecated: GitRepo is deprecated. To provision a container with a git repo, mount an\\nEmptyDir into an InitContainer that clones the repo using git, then mount the EmptyDir\\ninto the Pod's container.\""),
              gitRepo: {
                '#withDirectory':: d.fn(help="\"directory is the target directory name.\\nMust not contain or start with '..'.  If '.' is supplied, the volume directory will be the\\ngit repository.  Otherwise, if specified, the volume will contain the git repository in\\nthe subdirectory with the given name.\"", args=[d.arg(name='directory', type=d.T.string)]),
                withDirectory(directory): { gitRepo+: { directory: directory } },
                '#withRepository':: d.fn(help='"repository is the URL"', args=[d.arg(name='repository', type=d.T.string)]),
                withRepository(repository): { gitRepo+: { repository: repository } },
                '#withRevision':: d.fn(help='"revision is the commit hash for the specified revision."', args=[d.arg(name='revision', type=d.T.string)]),
                withRevision(revision): { gitRepo+: { revision: revision } },
              },
              '#glusterfs':: d.obj(help="\"glusterfs represents a Glusterfs mount on the host that shares a pod's lifetime.\\nDeprecated: Glusterfs is deprecated and the in-tree glusterfs type is no longer supported.\\nMore info: https://examples.k8s.io/volumes/glusterfs/README.md\""),
              glusterfs: {
                '#withEndpoints':: d.fn(help='"endpoints is the endpoint name that details Glusterfs topology.\\nMore info: https://examples.k8s.io/volumes/glusterfs/README.md#create-a-pod"', args=[d.arg(name='endpoints', type=d.T.string)]),
                withEndpoints(endpoints): { glusterfs+: { endpoints: endpoints } },
                '#withPath':: d.fn(help='"path is the Glusterfs volume path.\\nMore info: https://examples.k8s.io/volumes/glusterfs/README.md#create-a-pod"', args=[d.arg(name='path', type=d.T.string)]),
                withPath(path): { glusterfs+: { path: path } },
                '#withReadOnly':: d.fn(help='"readOnly here will force the Glusterfs volume to be mounted with read-only permissions.\\nDefaults to false.\\nMore info: https://examples.k8s.io/volumes/glusterfs/README.md#create-a-pod"', args=[d.arg(name='readOnly', type=d.T.boolean)]),
                withReadOnly(readOnly): { glusterfs+: { readOnly: readOnly } },
              },
              '#hostPath':: d.obj(help='"hostPath represents a pre-existing file or directory on the host\\nmachine that is directly exposed to the container. This is generally\\nused for system agents or other privileged things that are allowed\\nto see the host machine. Most containers will NOT need this.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#hostpath"'),
              hostPath: {
                '#withPath':: d.fn(help='"path of the directory on the host.\\nIf the path is a symlink, it will follow the link to the real path.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#hostpath"', args=[d.arg(name='path', type=d.T.string)]),
                withPath(path): { hostPath+: { path: path } },
                '#withType':: d.fn(help='"type for HostPath Volume\\nDefaults to \\"\\"\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#hostpath"', args=[d.arg(name='type', type=d.T.string)]),
                withType(type): { hostPath+: { type: type } },
              },
              '#image':: d.obj(help="\"image represents an OCI object (a container image or artifact) pulled and mounted on the kubelet's host machine.\\nThe volume is resolved at pod startup depending on which PullPolicy value is provided:\\n\\n- Always: the kubelet always attempts to pull the reference. Container creation will fail If the pull fails.\\n- Never: the kubelet never pulls the reference and only uses a local image or artifact. Container creation will fail if the reference isn't present.\\n- IfNotPresent: the kubelet pulls if the reference isn't already present on disk. Container creation will fail if the reference isn't present and the pull fails.\\n\\nThe volume gets re-resolved if the pod gets deleted and recreated, which means that new remote content will become available on pod recreation.\\nA failure to resolve or pull the image during pod startup will block containers from starting and may add significant latency. Failures will be retried using normal volume backoff and will be reported on the pod reason and message.\\nThe types of objects that may be mounted by this volume are defined by the container runtime implementation on a host machine and at minimum must include all valid types supported by the container image field.\\nThe OCI object gets mounted in a single directory (spec.containers[*].volumeMounts.mountPath) by merging the manifest layers in the same way as for container images.\\nThe volume will be mounted read-only (ro) and non-executable files (noexec).\\nSub path mounts for containers are not supported (spec.containers[*].volumeMounts.subpath) before 1.33.\\nThe field spec.securityContext.fsGroupChangePolicy has no effect on this volume type.\""),
              image: {
                '#withPullPolicy':: d.fn(help="\"Policy for pulling OCI objects. Possible values are:\\nAlways: the kubelet always attempts to pull the reference. Container creation will fail If the pull fails.\\nNever: the kubelet never pulls the reference and only uses a local image or artifact. Container creation will fail if the reference isn't present.\\nIfNotPresent: the kubelet pulls if the reference isn't already present on disk. Container creation will fail if the reference isn't present and the pull fails.\\nDefaults to Always if :latest tag is specified, or IfNotPresent otherwise.\"", args=[d.arg(name='pullPolicy', type=d.T.string)]),
                withPullPolicy(pullPolicy): { image+: { pullPolicy: pullPolicy } },
                '#withReference':: d.fn(help='"Required: Image or artifact reference to be used.\\nBehaves in the same way as pod.spec.containers[*].image.\\nPull secrets will be assembled in the same way as for the container image by looking up node credentials, SA image pull secrets, and pod spec image pull secrets.\\nMore info: https://kubernetes.io/docs/concepts/containers/images\\nThis field is optional to allow higher level config management to default or override\\ncontainer images in workload controllers like Deployments and StatefulSets."', args=[d.arg(name='reference', type=d.T.string)]),
                withReference(reference): { image+: { reference: reference } },
              },
              '#iscsi':: d.obj(help="\"iscsi represents an ISCSI Disk resource that is attached to a\\nkubelet's host machine and then exposed to the pod.\\nMore info: https://examples.k8s.io/volumes/iscsi/README.md\""),
              iscsi: {
                '#secretRef':: d.obj(help='"secretRef is the CHAP Secret for iSCSI target and initiator authentication"'),
                secretRef: {
                  '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
                  withName(name): { iscsi+: { secretRef+: { name: name } } },
                },
                '#withChapAuthDiscovery':: d.fn(help='"chapAuthDiscovery defines whether support iSCSI Discovery CHAP authentication"', args=[d.arg(name='chapAuthDiscovery', type=d.T.boolean)]),
                withChapAuthDiscovery(chapAuthDiscovery): { iscsi+: { chapAuthDiscovery: chapAuthDiscovery } },
                '#withChapAuthSession':: d.fn(help='"chapAuthSession defines whether support iSCSI Session CHAP authentication"', args=[d.arg(name='chapAuthSession', type=d.T.boolean)]),
                withChapAuthSession(chapAuthSession): { iscsi+: { chapAuthSession: chapAuthSession } },
                '#withFsType':: d.fn(help='"fsType is the filesystem type of the volume that you want to mount.\\nTip: Ensure that the filesystem type is supported by the host operating system.\\nExamples: \\"ext4\\", \\"xfs\\", \\"ntfs\\". Implicitly inferred to be \\"ext4\\" if unspecified.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#iscsi"', args=[d.arg(name='fsType', type=d.T.string)]),
                withFsType(fsType): { iscsi+: { fsType: fsType } },
                '#withInitiatorName':: d.fn(help='"initiatorName is the custom iSCSI Initiator Name.\\nIf initiatorName is specified with iscsiInterface simultaneously, new iSCSI interface\\n<target portal>:<volume name> will be created for the connection."', args=[d.arg(name='initiatorName', type=d.T.string)]),
                withInitiatorName(initiatorName): { iscsi+: { initiatorName: initiatorName } },
                '#withIqn':: d.fn(help='"iqn is the target iSCSI Qualified Name."', args=[d.arg(name='iqn', type=d.T.string)]),
                withIqn(iqn): { iscsi+: { iqn: iqn } },
                '#withIscsiInterface':: d.fn(help="\"iscsiInterface is the interface Name that uses an iSCSI transport.\\nDefaults to 'default' (tcp).\"", args=[d.arg(name='iscsiInterface', type=d.T.string)]),
                withIscsiInterface(iscsiInterface): { iscsi+: { iscsiInterface: iscsiInterface } },
                '#withLun':: d.fn(help='"lun represents iSCSI Target Lun number."', args=[d.arg(name='lun', type=d.T.integer)]),
                withLun(lun): { iscsi+: { lun: lun } },
                '#withPortals':: d.fn(help='"portals is the iSCSI Target Portal List. The portal is either an IP or ip_addr:port if the port\\nis other than default (typically TCP ports 860 and 3260)."', args=[d.arg(name='portals', type=d.T.array)]),
                withPortals(portals): { iscsi+: { portals: if std.isArray(v=portals) then portals else [portals] } },
                '#withPortalsMixin':: d.fn(help='"portals is the iSCSI Target Portal List. The portal is either an IP or ip_addr:port if the port\\nis other than default (typically TCP ports 860 and 3260)."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='portals', type=d.T.array)]),
                withPortalsMixin(portals): { iscsi+: { portals+: if std.isArray(v=portals) then portals else [portals] } },
                '#withReadOnly':: d.fn(help='"readOnly here will force the ReadOnly setting in VolumeMounts.\\nDefaults to false."', args=[d.arg(name='readOnly', type=d.T.boolean)]),
                withReadOnly(readOnly): { iscsi+: { readOnly: readOnly } },
                '#withTargetPortal':: d.fn(help='"targetPortal is iSCSI Target Portal. The Portal is either an IP or ip_addr:port if the port\\nis other than default (typically TCP ports 860 and 3260)."', args=[d.arg(name='targetPortal', type=d.T.string)]),
                withTargetPortal(targetPortal): { iscsi+: { targetPortal: targetPortal } },
              },
              '#nfs':: d.obj(help="\"nfs represents an NFS mount on the host that shares a pod's lifetime\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#nfs\""),
              nfs: {
                '#withPath':: d.fn(help='"path that is exported by the NFS server.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#nfs"', args=[d.arg(name='path', type=d.T.string)]),
                withPath(path): { nfs+: { path: path } },
                '#withReadOnly':: d.fn(help='"readOnly here will force the NFS export to be mounted with read-only permissions.\\nDefaults to false.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#nfs"', args=[d.arg(name='readOnly', type=d.T.boolean)]),
                withReadOnly(readOnly): { nfs+: { readOnly: readOnly } },
                '#withServer':: d.fn(help='"server is the hostname or IP address of the NFS server.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#nfs"', args=[d.arg(name='server', type=d.T.string)]),
                withServer(server): { nfs+: { server: server } },
              },
              '#persistentVolumeClaim':: d.obj(help='"persistentVolumeClaimVolumeSource represents a reference to a\\nPersistentVolumeClaim in the same namespace.\\nMore info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims"'),
              persistentVolumeClaim: {
                '#withClaimName':: d.fn(help='"claimName is the name of a PersistentVolumeClaim in the same namespace as the pod using this volume.\\nMore info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims"', args=[d.arg(name='claimName', type=d.T.string)]),
                withClaimName(claimName): { persistentVolumeClaim+: { claimName: claimName } },
                '#withReadOnly':: d.fn(help='"readOnly Will force the ReadOnly setting in VolumeMounts.\\nDefault false."', args=[d.arg(name='readOnly', type=d.T.boolean)]),
                withReadOnly(readOnly): { persistentVolumeClaim+: { readOnly: readOnly } },
              },
              '#photonPersistentDisk':: d.obj(help='"photonPersistentDisk represents a PhotonController persistent disk attached and mounted on kubelets host machine.\\nDeprecated: PhotonPersistentDisk is deprecated and the in-tree photonPersistentDisk type is no longer supported."'),
              photonPersistentDisk: {
                '#withFsType':: d.fn(help='"fsType is the filesystem type to mount.\\nMust be a filesystem type supported by the host operating system.\\nEx. \\"ext4\\", \\"xfs\\", \\"ntfs\\". Implicitly inferred to be \\"ext4\\" if unspecified."', args=[d.arg(name='fsType', type=d.T.string)]),
                withFsType(fsType): { photonPersistentDisk+: { fsType: fsType } },
                '#withPdID':: d.fn(help='"pdID is the ID that identifies Photon Controller persistent disk"', args=[d.arg(name='pdID', type=d.T.string)]),
                withPdID(pdID): { photonPersistentDisk+: { pdID: pdID } },
              },
              '#portworxVolume':: d.obj(help='"portworxVolume represents a portworx volume attached and mounted on kubelets host machine.\\nDeprecated: PortworxVolume is deprecated. All operations for the in-tree portworxVolume type\\nare redirected to the pxd.portworx.com CSI driver when the CSIMigrationPortworx feature-gate\\nis on."'),
              portworxVolume: {
                '#withFsType':: d.fn(help='"fSType represents the filesystem type to mount\\nMust be a filesystem type supported by the host operating system.\\nEx. \\"ext4\\", \\"xfs\\". Implicitly inferred to be \\"ext4\\" if unspecified."', args=[d.arg(name='fsType', type=d.T.string)]),
                withFsType(fsType): { portworxVolume+: { fsType: fsType } },
                '#withReadOnly':: d.fn(help='"readOnly defaults to false (read/write). ReadOnly here will force\\nthe ReadOnly setting in VolumeMounts."', args=[d.arg(name='readOnly', type=d.T.boolean)]),
                withReadOnly(readOnly): { portworxVolume+: { readOnly: readOnly } },
                '#withVolumeID':: d.fn(help='"volumeID uniquely identifies a Portworx volume"', args=[d.arg(name='volumeID', type=d.T.string)]),
                withVolumeID(volumeID): { portworxVolume+: { volumeID: volumeID } },
              },
              '#projected':: d.obj(help='"projected items for all in one resources secrets, configmaps, and downward API"'),
              projected: {
                '#sources':: d.obj(help='"sources is the list of volume projections. Each entry in this list\\nhandles one source."'),
                sources: {
                  '#clusterTrustBundle':: d.obj(help='"ClusterTrustBundle allows a pod to access the `.spec.trustBundle` field\\nof ClusterTrustBundle objects in an auto-updating file.\\n\\nAlpha, gated by the ClusterTrustBundleProjection feature gate.\\n\\nClusterTrustBundle objects can either be selected by name, or by the\\ncombination of signer name and a label selector.\\n\\nKubelet performs aggressive normalization of the PEM contents written\\ninto the pod filesystem.  Esoteric PEM features such as inter-block\\ncomments and block headers are stripped.  Certificates are deduplicated.\\nThe ordering of certificates within the file is arbitrary, and Kubelet\\nmay change the order over time."'),
                  clusterTrustBundle: {
                    '#labelSelector':: d.obj(help='"Select all ClusterTrustBundles that match this label selector.  Only has\\neffect if signerName is set.  Mutually-exclusive with name.  If unset,\\ninterpreted as \\"match nothing\\".  If set but empty, interpreted as \\"match\\neverything\\"."'),
                    labelSelector: {
                      '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                      matchExpressions: {
                        '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                        withKey(key): { key: key },
                        '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                        withOperator(operator): { operator: operator },
                        '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                        withValues(values): { values: if std.isArray(v=values) then values else [values] },
                        '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                        withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                      },
                      '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                      withMatchExpressions(matchExpressions): { clusterTrustBundle+: { labelSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                      '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                      withMatchExpressionsMixin(matchExpressions): { clusterTrustBundle+: { labelSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                      '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                      withMatchLabels(matchLabels): { clusterTrustBundle+: { labelSelector+: { matchLabels: matchLabels } } },
                      '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                      withMatchLabelsMixin(matchLabels): { clusterTrustBundle+: { labelSelector+: { matchLabels+: matchLabels } } },
                    },
                    '#withName':: d.fn(help='"Select a single ClusterTrustBundle by object name.  Mutually-exclusive\\nwith signerName and labelSelector."', args=[d.arg(name='name', type=d.T.string)]),
                    withName(name): { clusterTrustBundle+: { name: name } },
                    '#withOptional':: d.fn(help="\"If true, don't block pod startup if the referenced ClusterTrustBundle(s)\\naren't available.  If using name, then the named ClusterTrustBundle is\\nallowed not to exist.  If using signerName, then the combination of\\nsignerName and labelSelector is allowed to match zero\\nClusterTrustBundles.\"", args=[d.arg(name='optional', type=d.T.boolean)]),
                    withOptional(optional): { clusterTrustBundle+: { optional: optional } },
                    '#withPath':: d.fn(help='"Relative path from the volume root to write the bundle."', args=[d.arg(name='path', type=d.T.string)]),
                    withPath(path): { clusterTrustBundle+: { path: path } },
                    '#withSignerName':: d.fn(help='"Select all ClusterTrustBundles that match this signer name.\\nMutually-exclusive with name.  The contents of all selected\\nClusterTrustBundles will be unified and deduplicated."', args=[d.arg(name='signerName', type=d.T.string)]),
                    withSignerName(signerName): { clusterTrustBundle+: { signerName: signerName } },
                  },
                  '#configMap':: d.obj(help='"configMap information about the configMap data to project"'),
                  configMap: {
                    '#items':: d.obj(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nConfigMap will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the ConfigMap,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\""),
                    items: {
                      '#withKey':: d.fn(help='"key is the key to project."', args=[d.arg(name='key', type=d.T.string)]),
                      withKey(key): { key: key },
                      '#withMode':: d.fn(help='"mode is Optional: mode bits used to set permissions on this file.\\nMust be an octal value between 0000 and 0777 or a decimal value between 0 and 511.\\nYAML accepts both octal and decimal values, JSON requires decimal values for mode bits.\\nIf not specified, the volume defaultMode will be used.\\nThis might be in conflict with other options that affect the file\\nmode, like fsGroup, and the result can be other mode bits set."', args=[d.arg(name='mode', type=d.T.integer)]),
                      withMode(mode): { mode: mode },
                      '#withPath':: d.fn(help="\"path is the relative path of the file to map the key to.\\nMay not be an absolute path.\\nMay not contain the path element '..'.\\nMay not start with the string '..'.\"", args=[d.arg(name='path', type=d.T.string)]),
                      withPath(path): { path: path },
                    },
                    '#withItems':: d.fn(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nConfigMap will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the ConfigMap,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\"", args=[d.arg(name='items', type=d.T.array)]),
                    withItems(items): { configMap+: { items: if std.isArray(v=items) then items else [items] } },
                    '#withItemsMixin':: d.fn(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nConfigMap will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the ConfigMap,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='items', type=d.T.array)]),
                    withItemsMixin(items): { configMap+: { items+: if std.isArray(v=items) then items else [items] } },
                    '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
                    withName(name): { configMap+: { name: name } },
                    '#withOptional':: d.fn(help='"optional specify whether the ConfigMap or its keys must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
                    withOptional(optional): { configMap+: { optional: optional } },
                  },
                  '#downwardAPI':: d.obj(help='"downwardAPI information about the downwardAPI data to project"'),
                  downwardAPI: {
                    '#items':: d.obj(help='"Items is a list of DownwardAPIVolume file"'),
                    items: {
                      '#fieldRef':: d.obj(help='"Required: Selects a field of the pod: only annotations, labels, name, namespace and uid are supported."'),
                      fieldRef: {
                        '#withApiVersion':: d.fn(help='"Version of the schema the FieldPath is written in terms of, defaults to \\"v1\\"."', args=[d.arg(name='apiVersion', type=d.T.string)]),
                        withApiVersion(apiVersion): { fieldRef+: { apiVersion: apiVersion } },
                        '#withFieldPath':: d.fn(help='"Path of the field to select in the specified API version."', args=[d.arg(name='fieldPath', type=d.T.string)]),
                        withFieldPath(fieldPath): { fieldRef+: { fieldPath: fieldPath } },
                      },
                      '#resourceFieldRef':: d.obj(help='"Selects a resource of the container: only resources limits and requests\\n(limits.cpu, limits.memory, requests.cpu and requests.memory) are currently supported."'),
                      resourceFieldRef: {
                        '#withContainerName':: d.fn(help='"Container name: required for volumes, optional for env vars"', args=[d.arg(name='containerName', type=d.T.string)]),
                        withContainerName(containerName): { resourceFieldRef+: { containerName: containerName } },
                        '#withDivisor':: d.fn(help='"Specifies the output format of the exposed resources, defaults to \\"1\\', args=[d.arg(name='divisor', type=d.T.any)]),
                        withDivisor(divisor): { resourceFieldRef+: { divisor: divisor } },
                        '#withResource':: d.fn(help='"Required: resource to select"', args=[d.arg(name='resource', type=d.T.string)]),
                        withResource(resource): { resourceFieldRef+: { resource: resource } },
                      },
                      '#withMode':: d.fn(help='"Optional: mode bits used to set permissions on this file, must be an octal value\\nbetween 0000 and 0777 or a decimal value between 0 and 511.\\nYAML accepts both octal and decimal values, JSON requires decimal values for mode bits.\\nIf not specified, the volume defaultMode will be used.\\nThis might be in conflict with other options that affect the file\\nmode, like fsGroup, and the result can be other mode bits set."', args=[d.arg(name='mode', type=d.T.integer)]),
                      withMode(mode): { mode: mode },
                      '#withPath':: d.fn(help="\"Required: Path is  the relative path name of the file to be created. Must not be absolute or contain the '..' path. Must be utf-8 encoded. The first item of the relative path must not start with '..'\"", args=[d.arg(name='path', type=d.T.string)]),
                      withPath(path): { path: path },
                    },
                    '#withItems':: d.fn(help='"Items is a list of DownwardAPIVolume file"', args=[d.arg(name='items', type=d.T.array)]),
                    withItems(items): { downwardAPI+: { items: if std.isArray(v=items) then items else [items] } },
                    '#withItemsMixin':: d.fn(help='"Items is a list of DownwardAPIVolume file"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='items', type=d.T.array)]),
                    withItemsMixin(items): { downwardAPI+: { items+: if std.isArray(v=items) then items else [items] } },
                  },
                  '#secret':: d.obj(help='"secret information about the secret data to project"'),
                  secret: {
                    '#items':: d.obj(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nSecret will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the Secret,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\""),
                    items: {
                      '#withKey':: d.fn(help='"key is the key to project."', args=[d.arg(name='key', type=d.T.string)]),
                      withKey(key): { key: key },
                      '#withMode':: d.fn(help='"mode is Optional: mode bits used to set permissions on this file.\\nMust be an octal value between 0000 and 0777 or a decimal value between 0 and 511.\\nYAML accepts both octal and decimal values, JSON requires decimal values for mode bits.\\nIf not specified, the volume defaultMode will be used.\\nThis might be in conflict with other options that affect the file\\nmode, like fsGroup, and the result can be other mode bits set."', args=[d.arg(name='mode', type=d.T.integer)]),
                      withMode(mode): { mode: mode },
                      '#withPath':: d.fn(help="\"path is the relative path of the file to map the key to.\\nMay not be an absolute path.\\nMay not contain the path element '..'.\\nMay not start with the string '..'.\"", args=[d.arg(name='path', type=d.T.string)]),
                      withPath(path): { path: path },
                    },
                    '#withItems':: d.fn(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nSecret will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the Secret,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\"", args=[d.arg(name='items', type=d.T.array)]),
                    withItems(items): { secret+: { items: if std.isArray(v=items) then items else [items] } },
                    '#withItemsMixin':: d.fn(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nSecret will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the Secret,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='items', type=d.T.array)]),
                    withItemsMixin(items): { secret+: { items+: if std.isArray(v=items) then items else [items] } },
                    '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
                    withName(name): { secret+: { name: name } },
                    '#withOptional':: d.fn(help='"optional field specify whether the Secret or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
                    withOptional(optional): { secret+: { optional: optional } },
                  },
                  '#serviceAccountToken':: d.obj(help='"serviceAccountToken is information about the serviceAccountToken data to project"'),
                  serviceAccountToken: {
                    '#withAudience':: d.fn(help='"audience is the intended audience of the token. A recipient of a token\\nmust identify itself with an identifier specified in the audience of the\\ntoken, and otherwise should reject the token. The audience defaults to the\\nidentifier of the apiserver."', args=[d.arg(name='audience', type=d.T.string)]),
                    withAudience(audience): { serviceAccountToken+: { audience: audience } },
                    '#withExpirationSeconds':: d.fn(help='"expirationSeconds is the requested duration of validity of the service\\naccount token. As the token approaches expiration, the kubelet volume\\nplugin will proactively rotate the service account token. The kubelet will\\nstart trying to rotate the token if the token is older than 80 percent of\\nits time to live or if the token is older than 24 hours.Defaults to 1 hour\\nand must be at least 10 minutes."', args=[d.arg(name='expirationSeconds', type=d.T.integer)]),
                    withExpirationSeconds(expirationSeconds): { serviceAccountToken+: { expirationSeconds: expirationSeconds } },
                    '#withPath':: d.fn(help='"path is the path relative to the mount point of the file to project the\\ntoken into."', args=[d.arg(name='path', type=d.T.string)]),
                    withPath(path): { serviceAccountToken+: { path: path } },
                  },
                },
                '#withDefaultMode':: d.fn(help='"defaultMode are the mode bits used to set permissions on created files by default.\\nMust be an octal value between 0000 and 0777 or a decimal value between 0 and 511.\\nYAML accepts both octal and decimal values, JSON requires decimal values for mode bits.\\nDirectories within the path are not affected by this setting.\\nThis might be in conflict with other options that affect the file\\nmode, like fsGroup, and the result can be other mode bits set."', args=[d.arg(name='defaultMode', type=d.T.integer)]),
                withDefaultMode(defaultMode): { projected+: { defaultMode: defaultMode } },
                '#withSources':: d.fn(help='"sources is the list of volume projections. Each entry in this list\\nhandles one source."', args=[d.arg(name='sources', type=d.T.array)]),
                withSources(sources): { projected+: { sources: if std.isArray(v=sources) then sources else [sources] } },
                '#withSourcesMixin':: d.fn(help='"sources is the list of volume projections. Each entry in this list\\nhandles one source."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='sources', type=d.T.array)]),
                withSourcesMixin(sources): { projected+: { sources+: if std.isArray(v=sources) then sources else [sources] } },
              },
              '#quobyte':: d.obj(help="\"quobyte represents a Quobyte mount on the host that shares a pod's lifetime.\\nDeprecated: Quobyte is deprecated and the in-tree quobyte type is no longer supported.\""),
              quobyte: {
                '#withGroup':: d.fn(help='"group to map volume access to\\nDefault is no group"', args=[d.arg(name='group', type=d.T.string)]),
                withGroup(group): { quobyte+: { group: group } },
                '#withReadOnly':: d.fn(help='"readOnly here will force the Quobyte volume to be mounted with read-only permissions.\\nDefaults to false."', args=[d.arg(name='readOnly', type=d.T.boolean)]),
                withReadOnly(readOnly): { quobyte+: { readOnly: readOnly } },
                '#withRegistry':: d.fn(help='"registry represents a single or multiple Quobyte Registry services\\nspecified as a string as host:port pair (multiple entries are separated with commas)\\nwhich acts as the central registry for volumes"', args=[d.arg(name='registry', type=d.T.string)]),
                withRegistry(registry): { quobyte+: { registry: registry } },
                '#withTenant':: d.fn(help='"tenant owning the given Quobyte volume in the Backend\\nUsed with dynamically provisioned Quobyte volumes, value is set by the plugin"', args=[d.arg(name='tenant', type=d.T.string)]),
                withTenant(tenant): { quobyte+: { tenant: tenant } },
                '#withUser':: d.fn(help='"user to map volume access to\\nDefaults to serivceaccount user"', args=[d.arg(name='user', type=d.T.string)]),
                withUser(user): { quobyte+: { user: user } },
                '#withVolume':: d.fn(help='"volume is a string that references an already created Quobyte volume by name."', args=[d.arg(name='volume', type=d.T.string)]),
                withVolume(volume): { quobyte+: { volume: volume } },
              },
              '#rbd':: d.obj(help="\"rbd represents a Rados Block Device mount on the host that shares a pod's lifetime.\\nDeprecated: RBD is deprecated and the in-tree rbd type is no longer supported.\\nMore info: https://examples.k8s.io/volumes/rbd/README.md\""),
              rbd: {
                '#secretRef':: d.obj(help='"secretRef is name of the authentication secret for RBDUser. If provided\\noverrides keyring.\\nDefault is nil.\\nMore info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it"'),
                secretRef: {
                  '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
                  withName(name): { rbd+: { secretRef+: { name: name } } },
                },
                '#withFsType':: d.fn(help='"fsType is the filesystem type of the volume that you want to mount.\\nTip: Ensure that the filesystem type is supported by the host operating system.\\nExamples: \\"ext4\\", \\"xfs\\", \\"ntfs\\". Implicitly inferred to be \\"ext4\\" if unspecified.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#rbd"', args=[d.arg(name='fsType', type=d.T.string)]),
                withFsType(fsType): { rbd+: { fsType: fsType } },
                '#withImage':: d.fn(help='"image is the rados image name.\\nMore info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it"', args=[d.arg(name='image', type=d.T.string)]),
                withImage(image): { rbd+: { image: image } },
                '#withKeyring':: d.fn(help='"keyring is the path to key ring for RBDUser.\\nDefault is /etc/ceph/keyring.\\nMore info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it"', args=[d.arg(name='keyring', type=d.T.string)]),
                withKeyring(keyring): { rbd+: { keyring: keyring } },
                '#withMonitors':: d.fn(help='"monitors is a collection of Ceph monitors.\\nMore info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it"', args=[d.arg(name='monitors', type=d.T.array)]),
                withMonitors(monitors): { rbd+: { monitors: if std.isArray(v=monitors) then monitors else [monitors] } },
                '#withMonitorsMixin':: d.fn(help='"monitors is a collection of Ceph monitors.\\nMore info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='monitors', type=d.T.array)]),
                withMonitorsMixin(monitors): { rbd+: { monitors+: if std.isArray(v=monitors) then monitors else [monitors] } },
                '#withPool':: d.fn(help='"pool is the rados pool name.\\nDefault is rbd.\\nMore info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it"', args=[d.arg(name='pool', type=d.T.string)]),
                withPool(pool): { rbd+: { pool: pool } },
                '#withReadOnly':: d.fn(help='"readOnly here will force the ReadOnly setting in VolumeMounts.\\nDefaults to false.\\nMore info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it"', args=[d.arg(name='readOnly', type=d.T.boolean)]),
                withReadOnly(readOnly): { rbd+: { readOnly: readOnly } },
                '#withUser':: d.fn(help='"user is the rados user name.\\nDefault is admin.\\nMore info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it"', args=[d.arg(name='user', type=d.T.string)]),
                withUser(user): { rbd+: { user: user } },
              },
              '#scaleIO':: d.obj(help='"scaleIO represents a ScaleIO persistent volume attached and mounted on Kubernetes nodes.\\nDeprecated: ScaleIO is deprecated and the in-tree scaleIO type is no longer supported."'),
              scaleIO: {
                '#secretRef':: d.obj(help='"secretRef references to the secret for ScaleIO user and other\\nsensitive information. If this is not provided, Login operation will fail."'),
                secretRef: {
                  '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
                  withName(name): { scaleIO+: { secretRef+: { name: name } } },
                },
                '#withFsType':: d.fn(help='"fsType is the filesystem type to mount.\\nMust be a filesystem type supported by the host operating system.\\nEx. \\"ext4\\", \\"xfs\\", \\"ntfs\\".\\nDefault is \\"xfs\\"."', args=[d.arg(name='fsType', type=d.T.string)]),
                withFsType(fsType): { scaleIO+: { fsType: fsType } },
                '#withGateway':: d.fn(help='"gateway is the host address of the ScaleIO API Gateway."', args=[d.arg(name='gateway', type=d.T.string)]),
                withGateway(gateway): { scaleIO+: { gateway: gateway } },
                '#withProtectionDomain':: d.fn(help='"protectionDomain is the name of the ScaleIO Protection Domain for the configured storage."', args=[d.arg(name='protectionDomain', type=d.T.string)]),
                withProtectionDomain(protectionDomain): { scaleIO+: { protectionDomain: protectionDomain } },
                '#withReadOnly':: d.fn(help='"readOnly Defaults to false (read/write). ReadOnly here will force\\nthe ReadOnly setting in VolumeMounts."', args=[d.arg(name='readOnly', type=d.T.boolean)]),
                withReadOnly(readOnly): { scaleIO+: { readOnly: readOnly } },
                '#withSslEnabled':: d.fn(help='"sslEnabled Flag enable/disable SSL communication with Gateway, default false"', args=[d.arg(name='sslEnabled', type=d.T.boolean)]),
                withSslEnabled(sslEnabled): { scaleIO+: { sslEnabled: sslEnabled } },
                '#withStorageMode':: d.fn(help='"storageMode indicates whether the storage for a volume should be ThickProvisioned or ThinProvisioned.\\nDefault is ThinProvisioned."', args=[d.arg(name='storageMode', type=d.T.string)]),
                withStorageMode(storageMode): { scaleIO+: { storageMode: storageMode } },
                '#withStoragePool':: d.fn(help='"storagePool is the ScaleIO Storage Pool associated with the protection domain."', args=[d.arg(name='storagePool', type=d.T.string)]),
                withStoragePool(storagePool): { scaleIO+: { storagePool: storagePool } },
                '#withSystem':: d.fn(help='"system is the name of the storage system as configured in ScaleIO."', args=[d.arg(name='system', type=d.T.string)]),
                withSystem(system): { scaleIO+: { system: system } },
                '#withVolumeName':: d.fn(help='"volumeName is the name of a volume already created in the ScaleIO system\\nthat is associated with this volume source."', args=[d.arg(name='volumeName', type=d.T.string)]),
                withVolumeName(volumeName): { scaleIO+: { volumeName: volumeName } },
              },
              '#secret':: d.obj(help='"secret represents a secret that should populate this volume.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#secret"'),
              secret: {
                '#items':: d.obj(help="\"items If unspecified, each key-value pair in the Data field of the referenced\\nSecret will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the Secret,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\""),
                items: {
                  '#withKey':: d.fn(help='"key is the key to project."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { key: key },
                  '#withMode':: d.fn(help='"mode is Optional: mode bits used to set permissions on this file.\\nMust be an octal value between 0000 and 0777 or a decimal value between 0 and 511.\\nYAML accepts both octal and decimal values, JSON requires decimal values for mode bits.\\nIf not specified, the volume defaultMode will be used.\\nThis might be in conflict with other options that affect the file\\nmode, like fsGroup, and the result can be other mode bits set."', args=[d.arg(name='mode', type=d.T.integer)]),
                  withMode(mode): { mode: mode },
                  '#withPath':: d.fn(help="\"path is the relative path of the file to map the key to.\\nMay not be an absolute path.\\nMay not contain the path element '..'.\\nMay not start with the string '..'.\"", args=[d.arg(name='path', type=d.T.string)]),
                  withPath(path): { path: path },
                },
                '#withDefaultMode':: d.fn(help='"defaultMode is Optional: mode bits used to set permissions on created files by default.\\nMust be an octal value between 0000 and 0777 or a decimal value between 0 and 511.\\nYAML accepts both octal and decimal values, JSON requires decimal values\\nfor mode bits. Defaults to 0644.\\nDirectories within the path are not affected by this setting.\\nThis might be in conflict with other options that affect the file\\nmode, like fsGroup, and the result can be other mode bits set."', args=[d.arg(name='defaultMode', type=d.T.integer)]),
                withDefaultMode(defaultMode): { secret+: { defaultMode: defaultMode } },
                '#withItems':: d.fn(help="\"items If unspecified, each key-value pair in the Data field of the referenced\\nSecret will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the Secret,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\"", args=[d.arg(name='items', type=d.T.array)]),
                withItems(items): { secret+: { items: if std.isArray(v=items) then items else [items] } },
                '#withItemsMixin':: d.fn(help="\"items If unspecified, each key-value pair in the Data field of the referenced\\nSecret will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the Secret,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='items', type=d.T.array)]),
                withItemsMixin(items): { secret+: { items+: if std.isArray(v=items) then items else [items] } },
                '#withOptional':: d.fn(help='"optional field specify whether the Secret or its keys must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
                withOptional(optional): { secret+: { optional: optional } },
                '#withSecretName':: d.fn(help="\"secretName is the name of the secret in the pod's namespace to use.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#secret\"", args=[d.arg(name='secretName', type=d.T.string)]),
                withSecretName(secretName): { secret+: { secretName: secretName } },
              },
              '#storageos':: d.obj(help='"storageOS represents a StorageOS volume attached and mounted on Kubernetes nodes.\\nDeprecated: StorageOS is deprecated and the in-tree storageos type is no longer supported."'),
              storageos: {
                '#secretRef':: d.obj(help='"secretRef specifies the secret to use for obtaining the StorageOS API\\ncredentials.  If not specified, default values will be attempted."'),
                secretRef: {
                  '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
                  withName(name): { storageos+: { secretRef+: { name: name } } },
                },
                '#withFsType':: d.fn(help='"fsType is the filesystem type to mount.\\nMust be a filesystem type supported by the host operating system.\\nEx. \\"ext4\\", \\"xfs\\", \\"ntfs\\". Implicitly inferred to be \\"ext4\\" if unspecified."', args=[d.arg(name='fsType', type=d.T.string)]),
                withFsType(fsType): { storageos+: { fsType: fsType } },
                '#withReadOnly':: d.fn(help='"readOnly defaults to false (read/write). ReadOnly here will force\\nthe ReadOnly setting in VolumeMounts."', args=[d.arg(name='readOnly', type=d.T.boolean)]),
                withReadOnly(readOnly): { storageos+: { readOnly: readOnly } },
                '#withVolumeName':: d.fn(help='"volumeName is the human-readable name of the StorageOS volume.  Volume\\nnames are only unique within a namespace."', args=[d.arg(name='volumeName', type=d.T.string)]),
                withVolumeName(volumeName): { storageos+: { volumeName: volumeName } },
                '#withVolumeNamespace':: d.fn(help="\"volumeNamespace specifies the scope of the volume within StorageOS.  If no\\nnamespace is specified then the Pod's namespace will be used.  This allows the\\nKubernetes name scoping to be mirrored within StorageOS for tighter integration.\\nSet VolumeName to any name to override the default behaviour.\\nSet to \\\"default\\\" if you are not using namespaces within StorageOS.\\nNamespaces that do not pre-exist within StorageOS will be created.\"", args=[d.arg(name='volumeNamespace', type=d.T.string)]),
                withVolumeNamespace(volumeNamespace): { storageos+: { volumeNamespace: volumeNamespace } },
              },
              '#vsphereVolume':: d.obj(help='"vsphereVolume represents a vSphere volume attached and mounted on kubelets host machine.\\nDeprecated: VsphereVolume is deprecated. All operations for the in-tree vsphereVolume type\\nare redirected to the csi.vsphere.vmware.com CSI driver."'),
              vsphereVolume: {
                '#withFsType':: d.fn(help='"fsType is filesystem type to mount.\\nMust be a filesystem type supported by the host operating system.\\nEx. \\"ext4\\", \\"xfs\\", \\"ntfs\\". Implicitly inferred to be \\"ext4\\" if unspecified."', args=[d.arg(name='fsType', type=d.T.string)]),
                withFsType(fsType): { vsphereVolume+: { fsType: fsType } },
                '#withStoragePolicyID':: d.fn(help='"storagePolicyID is the storage Policy Based Management (SPBM) profile ID associated with the StoragePolicyName."', args=[d.arg(name='storagePolicyID', type=d.T.string)]),
                withStoragePolicyID(storagePolicyID): { vsphereVolume+: { storagePolicyID: storagePolicyID } },
                '#withStoragePolicyName':: d.fn(help='"storagePolicyName is the storage Policy Based Management (SPBM) profile name."', args=[d.arg(name='storagePolicyName', type=d.T.string)]),
                withStoragePolicyName(storagePolicyName): { vsphereVolume+: { storagePolicyName: storagePolicyName } },
                '#withVolumePath':: d.fn(help='"volumePath is the path that identifies vSphere volume vmdk"', args=[d.arg(name='volumePath', type=d.T.string)]),
                withVolumePath(volumePath): { vsphereVolume+: { volumePath: volumePath } },
              },
              '#withName':: d.fn(help='"name of the volume.\\nMust be a DNS_LABEL and unique within the pod.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { name: name },
            },
            '#withAnnotations':: d.fn(help='"Annotations are the annotations that should be appended to the pods.\\nBy default, no pod annotations are appended."', args=[d.arg(name='annotations', type=d.T.object)]),
            withAnnotations(annotations): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { pod+: { annotations: annotations } } } } } },
            '#withAnnotationsMixin':: d.fn(help='"Annotations are the annotations that should be appended to the pods.\\nBy default, no pod annotations are appended."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='annotations', type=d.T.object)]),
            withAnnotationsMixin(annotations): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { pod+: { annotations+: annotations } } } } } },
            '#withImagePullSecrets':: d.fn(help='"ImagePullSecrets is an optional list of references to secrets\\nin the same namespace to use for pulling any of the images used by this PodSpec.\\nIf specified, these secrets will be passed to individual puller implementations for them to use.\\nMore info: https://kubernetes.io/docs/concepts/containers/images#specifying-imagepullsecrets-on-a-pod"', args=[d.arg(name='imagePullSecrets', type=d.T.array)]),
            withImagePullSecrets(imagePullSecrets): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { pod+: { imagePullSecrets: if std.isArray(v=imagePullSecrets) then imagePullSecrets else [imagePullSecrets] } } } } } },
            '#withImagePullSecretsMixin':: d.fn(help='"ImagePullSecrets is an optional list of references to secrets\\nin the same namespace to use for pulling any of the images used by this PodSpec.\\nIf specified, these secrets will be passed to individual puller implementations for them to use.\\nMore info: https://kubernetes.io/docs/concepts/containers/images#specifying-imagepullsecrets-on-a-pod"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='imagePullSecrets', type=d.T.array)]),
            withImagePullSecretsMixin(imagePullSecrets): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { pod+: { imagePullSecrets+: if std.isArray(v=imagePullSecrets) then imagePullSecrets else [imagePullSecrets] } } } } } },
            '#withLabels':: d.fn(help='"Labels are the additional labels that should be tagged to the pods.\\nBy default, no additional pod labels are tagged."', args=[d.arg(name='labels', type=d.T.object)]),
            withLabels(labels): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { pod+: { labels: labels } } } } } },
            '#withLabelsMixin':: d.fn(help='"Labels are the additional labels that should be tagged to the pods.\\nBy default, no additional pod labels are tagged."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labels', type=d.T.object)]),
            withLabelsMixin(labels): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { pod+: { labels+: labels } } } } } },
            '#withNodeSelector':: d.fn(help="\"NodeSelector is a selector which must be true for the pod to fit on a node.\\nSelector which must match a node's labels for the pod to be scheduled on that node.\\nMore info: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\"", args=[d.arg(name='nodeSelector', type=d.T.object)]),
            withNodeSelector(nodeSelector): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { pod+: { nodeSelector: nodeSelector } } } } } },
            '#withNodeSelectorMixin':: d.fn(help="\"NodeSelector is a selector which must be true for the pod to fit on a node.\\nSelector which must match a node's labels for the pod to be scheduled on that node.\\nMore info: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='nodeSelector', type=d.T.object)]),
            withNodeSelectorMixin(nodeSelector): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { pod+: { nodeSelector+: nodeSelector } } } } } },
            '#withTolerations':: d.fn(help="\"If specified, the pod's tolerations.\"", args=[d.arg(name='tolerations', type=d.T.array)]),
            withTolerations(tolerations): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { pod+: { tolerations: if std.isArray(v=tolerations) then tolerations else [tolerations] } } } } } },
            '#withTolerationsMixin':: d.fn(help="\"If specified, the pod's tolerations.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='tolerations', type=d.T.array)]),
            withTolerationsMixin(tolerations): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { pod+: { tolerations+: if std.isArray(v=tolerations) then tolerations else [tolerations] } } } } } },
            '#withTopologySpreadConstraints':: d.fn(help='"TopologySpreadConstraints describes how a group of pods ought to spread across topology\\ndomains. Scheduler will schedule pods in a way which abides by the constraints.\\nAll topologySpreadConstraints are ANDed."', args=[d.arg(name='topologySpreadConstraints', type=d.T.array)]),
            withTopologySpreadConstraints(topologySpreadConstraints): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { pod+: { topologySpreadConstraints: if std.isArray(v=topologySpreadConstraints) then topologySpreadConstraints else [topologySpreadConstraints] } } } } } },
            '#withTopologySpreadConstraintsMixin':: d.fn(help='"TopologySpreadConstraints describes how a group of pods ought to spread across topology\\ndomains. Scheduler will schedule pods in a way which abides by the constraints.\\nAll topologySpreadConstraints are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='topologySpreadConstraints', type=d.T.array)]),
            withTopologySpreadConstraintsMixin(topologySpreadConstraints): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { pod+: { topologySpreadConstraints+: if std.isArray(v=topologySpreadConstraints) then topologySpreadConstraints else [topologySpreadConstraints] } } } } } },
            '#withVolumes':: d.fn(help='"Volumes that can be mounted by containers belonging to the pod.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes"', args=[d.arg(name='volumes', type=d.T.array)]),
            withVolumes(volumes): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { pod+: { volumes: if std.isArray(v=volumes) then volumes else [volumes] } } } } } },
            '#withVolumesMixin':: d.fn(help='"Volumes that can be mounted by containers belonging to the pod.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='volumes', type=d.T.array)]),
            withVolumesMixin(volumes): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { pod+: { volumes+: if std.isArray(v=volumes) then volumes else [volumes] } } } } } },
          },
          '#strategy':: d.obj(help='"The daemonset strategy to use to replace existing pods with new ones."'),
          strategy: {
            '#rollingUpdate':: d.obj(help='"Rolling update config params. Present only if type = \\"RollingUpdate\\"."'),
            rollingUpdate: {
              '#withMaxSurge':: d.fn(help='"The maximum number of nodes with an existing available DaemonSet pod that\\ncan have an updated DaemonSet pod during during an update.\\nValue can be an absolute number (ex: 5) or a percentage of desired pods (ex: 10%).\\nThis can not be 0 if MaxUnavailable is 0.\\nAbsolute number is calculated from percentage by rounding up to a minimum of 1.\\nDefault value is 0.\\nExample: when this is set to 30%, at most 30% of the total number of nodes\\nthat should be running the daemon pod (i.e. status.desiredNumberScheduled)\\ncan have their a new pod created before the old pod is marked as deleted.\\nThe update starts by launching new pods on 30% of nodes. Once an updated\\npod is available (Ready for at least minReadySeconds) the old DaemonSet pod\\non that node is marked deleted. If the old pod becomes unavailable for any\\nreason (Ready transitions to false, is evicted, or is drained) an updated\\npod is immediatedly created on that node without considering surge limits.\\nAllowing surge implies the possibility that the resources consumed by the\\ndaemonset on any given node can double if the readiness check fails, and\\nso resource intensive daemonsets should take into account that they may\\ncause evictions during disruption."', args=[d.arg(name='maxSurge', type=d.T.any)]),
              withMaxSurge(maxSurge): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { strategy+: { rollingUpdate+: { maxSurge: maxSurge } } } } } } },
              '#withMaxUnavailable':: d.fn(help='"The maximum number of DaemonSet pods that can be unavailable during the\\nupdate. Value can be an absolute number (ex: 5) or a percentage of total\\nnumber of DaemonSet pods at the start of the update (ex: 10%). Absolute\\nnumber is calculated from percentage by rounding up.\\nThis cannot be 0 if MaxSurge is 0\\nDefault value is 1.\\nExample: when this is set to 30%, at most 30% of the total number of nodes\\nthat should be running the daemon pod (i.e. status.desiredNumberScheduled)\\ncan have their pods stopped for an update at any given time. The update\\nstarts by stopping at most 30% of those DaemonSet pods and then brings\\nup new DaemonSet pods in their place. Once the new pods are available,\\nit then proceeds onto other DaemonSet pods, thus ensuring that at least\\n70% of original number of DaemonSet pods are available at all times during\\nthe update."', args=[d.arg(name='maxUnavailable', type=d.T.any)]),
              withMaxUnavailable(maxUnavailable): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { strategy+: { rollingUpdate+: { maxUnavailable: maxUnavailable } } } } } } },
            },
            '#withType':: d.fn(help='"Type of daemon set update. Can be \\"RollingUpdate\\" or \\"OnDelete\\". Default is RollingUpdate."', args=[d.arg(name='type', type=d.T.string)]),
            withType(type): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { strategy+: { type: type } } } } } },
          },
          '#withName':: d.fn(help='"Name of the daemonSet.\\nWhen unset, this defaults to an autogenerated name."', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { spec+: { provider+: { kubernetes+: { envoyDaemonSet+: { name: name } } } } },
        },
        '#envoyDeployment':: d.obj(help='"EnvoyDeployment defines the desired state of the Envoy deployment resource.\\nIf unspecified, default settings for the managed Envoy deployment resource\\nare applied."'),
        envoyDeployment: {
          '#container':: d.obj(help='"Container defines the desired specification of main container."'),
          container: {
            '#env':: d.obj(help='"List of environment variables to set in the container."'),
            env: {
              '#valueFrom':: d.obj(help="\"Source for the environment variable's value. Cannot be used if value is not empty.\""),
              valueFrom: {
                '#configMapKeyRef':: d.obj(help='"Selects a key of a ConfigMap."'),
                configMapKeyRef: {
                  '#withKey':: d.fn(help='"The key to select."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { valueFrom+: { configMapKeyRef+: { key: key } } },
                  '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
                  withName(name): { valueFrom+: { configMapKeyRef+: { name: name } } },
                  '#withOptional':: d.fn(help='"Specify whether the ConfigMap or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
                  withOptional(optional): { valueFrom+: { configMapKeyRef+: { optional: optional } } },
                },
                '#fieldRef':: d.obj(help="\"Selects a field of the pod: supports metadata.name, metadata.namespace, `metadata.labels['\u003cKEY\u003e']`, `metadata.annotations['\u003cKEY\u003e']`,\\nspec.nodeName, spec.serviceAccountName, status.hostIP, status.podIP, status.podIPs.\""),
                fieldRef: {
                  '#withApiVersion':: d.fn(help='"Version of the schema the FieldPath is written in terms of, defaults to \\"v1\\"."', args=[d.arg(name='apiVersion', type=d.T.string)]),
                  withApiVersion(apiVersion): { valueFrom+: { fieldRef+: { apiVersion: apiVersion } } },
                  '#withFieldPath':: d.fn(help='"Path of the field to select in the specified API version."', args=[d.arg(name='fieldPath', type=d.T.string)]),
                  withFieldPath(fieldPath): { valueFrom+: { fieldRef+: { fieldPath: fieldPath } } },
                },
                '#resourceFieldRef':: d.obj(help='"Selects a resource of the container: only resources limits and requests\\n(limits.cpu, limits.memory, limits.ephemeral-storage, requests.cpu, requests.memory and requests.ephemeral-storage) are currently supported."'),
                resourceFieldRef: {
                  '#withContainerName':: d.fn(help='"Container name: required for volumes, optional for env vars"', args=[d.arg(name='containerName', type=d.T.string)]),
                  withContainerName(containerName): { valueFrom+: { resourceFieldRef+: { containerName: containerName } } },
                  '#withDivisor':: d.fn(help='"Specifies the output format of the exposed resources, defaults to \\"1\\', args=[d.arg(name='divisor', type=d.T.any)]),
                  withDivisor(divisor): { valueFrom+: { resourceFieldRef+: { divisor: divisor } } },
                  '#withResource':: d.fn(help='"Required: resource to select"', args=[d.arg(name='resource', type=d.T.string)]),
                  withResource(resource): { valueFrom+: { resourceFieldRef+: { resource: resource } } },
                },
                '#secretKeyRef':: d.obj(help="\"Selects a key of a secret in the pod's namespace\""),
                secretKeyRef: {
                  '#withKey':: d.fn(help='"The key of the secret to select from.  Must be a valid secret key."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { valueFrom+: { secretKeyRef+: { key: key } } },
                  '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
                  withName(name): { valueFrom+: { secretKeyRef+: { name: name } } },
                  '#withOptional':: d.fn(help='"Specify whether the Secret or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
                  withOptional(optional): { valueFrom+: { secretKeyRef+: { optional: optional } } },
                },
              },
              '#withName':: d.fn(help='"Name of the environment variable. Must be a C_IDENTIFIER."', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { name: name },
              '#withValue':: d.fn(help='"Variable references $(VAR_NAME) are expanded\\nusing the previously defined environment variables in the container and\\nany service environment variables. If a variable cannot be resolved,\\nthe reference in the input string will be unchanged. Double $$ are reduced\\nto a single $, which allows for escaping the $(VAR_NAME) syntax: i.e.\\n\\"$$(VAR_NAME)\\" will produce the string literal \\"$(VAR_NAME)\\".\\nEscaped references will never be expanded, regardless of whether the variable\\nexists or not.\\nDefaults to \\"\\"."', args=[d.arg(name='value', type=d.T.string)]),
              withValue(value): { value: value },
            },
            '#resources':: d.obj(help='"Resources required by this container.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"'),
            resources: {
              '#claims':: d.obj(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis is an alpha field and requires enabling the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."'),
              claims: {
                '#withName':: d.fn(help='"Name must match the name of one entry in pod.spec.resourceClaims of\\nthe Pod where this field is used. It makes that resource available\\ninside a container."', args=[d.arg(name='name', type=d.T.string)]),
                withName(name): { name: name },
                '#withRequest':: d.fn(help='"Request is the name chosen for a request in the referenced claim.\\nIf empty, everything from the claim is made available, otherwise\\nonly the result of this request."', args=[d.arg(name='request', type=d.T.string)]),
                withRequest(request): { request: request },
              },
              '#withClaims':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis is an alpha field and requires enabling the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."', args=[d.arg(name='claims', type=d.T.array)]),
              withClaims(claims): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { container+: { resources+: { claims: if std.isArray(v=claims) then claims else [claims] } } } } } } },
              '#withClaimsMixin':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis is an alpha field and requires enabling the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='claims', type=d.T.array)]),
              withClaimsMixin(claims): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { container+: { resources+: { claims+: if std.isArray(v=claims) then claims else [claims] } } } } } } },
              '#withLimits':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='limits', type=d.T.object)]),
              withLimits(limits): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { container+: { resources+: { limits: limits } } } } } } },
              '#withLimitsMixin':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='limits', type=d.T.object)]),
              withLimitsMixin(limits): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { container+: { resources+: { limits+: limits } } } } } } },
              '#withRequests':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='requests', type=d.T.object)]),
              withRequests(requests): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { container+: { resources+: { requests: requests } } } } } } },
              '#withRequestsMixin':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requests', type=d.T.object)]),
              withRequestsMixin(requests): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { container+: { resources+: { requests+: requests } } } } } } },
            },
            '#securityContext':: d.obj(help='"SecurityContext defines the security options the container should be run with.\\nIf set, the fields of SecurityContext override the equivalent fields of PodSecurityContext.\\nMore info: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/"'),
            securityContext: {
              '#appArmorProfile':: d.obj(help="\"appArmorProfile is the AppArmor options to use by this container. If set, this profile\\noverrides the pod's appArmorProfile.\\nNote that this field cannot be set when spec.os.name is windows.\""),
              appArmorProfile: {
                '#withLocalhostProfile':: d.fn(help='"localhostProfile indicates a profile loaded on the node that should be used.\\nThe profile must be preconfigured on the node to work.\\nMust match the loaded name of the profile.\\nMust be set if and only if type is \\"Localhost\\"."', args=[d.arg(name='localhostProfile', type=d.T.string)]),
                withLocalhostProfile(localhostProfile): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { container+: { securityContext+: { appArmorProfile+: { localhostProfile: localhostProfile } } } } } } } },
                '#withType':: d.fn(help="\"type indicates which kind of AppArmor profile will be applied.\\nValid options are:\\n  Localhost - a profile pre-loaded on the node.\\n  RuntimeDefault - the container runtime's default profile.\\n  Unconfined - no AppArmor enforcement.\"", args=[d.arg(name='type', type=d.T.string)]),
                withType(type): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { container+: { securityContext+: { appArmorProfile+: { type: type } } } } } } } },
              },
              '#capabilities':: d.obj(help='"The capabilities to add/drop when running containers.\\nDefaults to the default set of capabilities granted by the container runtime.\\nNote that this field cannot be set when spec.os.name is windows."'),
              capabilities: {
                '#withAdd':: d.fn(help='"Added capabilities"', args=[d.arg(name='add', type=d.T.array)]),
                withAdd(add): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { container+: { securityContext+: { capabilities+: { add: if std.isArray(v=add) then add else [add] } } } } } } } },
                '#withAddMixin':: d.fn(help='"Added capabilities"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='add', type=d.T.array)]),
                withAddMixin(add): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { container+: { securityContext+: { capabilities+: { add+: if std.isArray(v=add) then add else [add] } } } } } } } },
                '#withDrop':: d.fn(help='"Removed capabilities"', args=[d.arg(name='drop', type=d.T.array)]),
                withDrop(drop): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { container+: { securityContext+: { capabilities+: { drop: if std.isArray(v=drop) then drop else [drop] } } } } } } } },
                '#withDropMixin':: d.fn(help='"Removed capabilities"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='drop', type=d.T.array)]),
                withDropMixin(drop): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { container+: { securityContext+: { capabilities+: { drop+: if std.isArray(v=drop) then drop else [drop] } } } } } } } },
              },
              '#seLinuxOptions':: d.obj(help='"The SELinux context to be applied to the container.\\nIf unspecified, the container runtime will allocate a random SELinux context for each\\ncontainer.  May also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is windows."'),
              seLinuxOptions: {
                '#withLevel':: d.fn(help='"Level is SELinux level label that applies to the container."', args=[d.arg(name='level', type=d.T.string)]),
                withLevel(level): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { container+: { securityContext+: { seLinuxOptions+: { level: level } } } } } } } },
                '#withRole':: d.fn(help='"Role is a SELinux role label that applies to the container."', args=[d.arg(name='role', type=d.T.string)]),
                withRole(role): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { container+: { securityContext+: { seLinuxOptions+: { role: role } } } } } } } },
                '#withType':: d.fn(help='"Type is a SELinux type label that applies to the container."', args=[d.arg(name='type', type=d.T.string)]),
                withType(type): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { container+: { securityContext+: { seLinuxOptions+: { type: type } } } } } } } },
                '#withUser':: d.fn(help='"User is a SELinux user label that applies to the container."', args=[d.arg(name='user', type=d.T.string)]),
                withUser(user): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { container+: { securityContext+: { seLinuxOptions+: { user: user } } } } } } } },
              },
              '#seccompProfile':: d.obj(help='"The seccomp options to use by this container. If seccomp options are\\nprovided at both the pod & container level, the container options\\noverride the pod options.\\nNote that this field cannot be set when spec.os.name is windows."'),
              seccompProfile: {
                '#withLocalhostProfile':: d.fn(help="\"localhostProfile indicates a profile defined in a file on the node should be used.\\nThe profile must be preconfigured on the node to work.\\nMust be a descending path, relative to the kubelet's configured seccomp profile location.\\nMust be set if type is \\\"Localhost\\\". Must NOT be set for any other type.\"", args=[d.arg(name='localhostProfile', type=d.T.string)]),
                withLocalhostProfile(localhostProfile): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { container+: { securityContext+: { seccompProfile+: { localhostProfile: localhostProfile } } } } } } } },
                '#withType':: d.fn(help='"type indicates which kind of seccomp profile will be applied.\\nValid options are:\\n\\nLocalhost - a profile defined in a file on the node should be used.\\nRuntimeDefault - the container runtime default profile should be used.\\nUnconfined - no profile should be applied."', args=[d.arg(name='type', type=d.T.string)]),
                withType(type): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { container+: { securityContext+: { seccompProfile+: { type: type } } } } } } } },
              },
              '#windowsOptions':: d.obj(help='"The Windows specific settings applied to all containers.\\nIf unspecified, the options from the PodSecurityContext will be used.\\nIf set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is linux."'),
              windowsOptions: {
                '#withGmsaCredentialSpec':: d.fn(help='"GMSACredentialSpec is where the GMSA admission webhook\\n(https://github.com/kubernetes-sigs/windows-gmsa) inlines the contents of the\\nGMSA credential spec named by the GMSACredentialSpecName field."', args=[d.arg(name='gmsaCredentialSpec', type=d.T.string)]),
                withGmsaCredentialSpec(gmsaCredentialSpec): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { container+: { securityContext+: { windowsOptions+: { gmsaCredentialSpec: gmsaCredentialSpec } } } } } } } },
                '#withGmsaCredentialSpecName':: d.fn(help='"GMSACredentialSpecName is the name of the GMSA credential spec to use."', args=[d.arg(name='gmsaCredentialSpecName', type=d.T.string)]),
                withGmsaCredentialSpecName(gmsaCredentialSpecName): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { container+: { securityContext+: { windowsOptions+: { gmsaCredentialSpecName: gmsaCredentialSpecName } } } } } } } },
                '#withHostProcess':: d.fn(help="\"HostProcess determines if a container should be run as a 'Host Process' container.\\nAll of a Pod's containers must have the same effective HostProcess value\\n(it is not allowed to have a mix of HostProcess containers and non-HostProcess containers).\\nIn addition, if HostProcess is true then HostNetwork must also be set to true.\"", args=[d.arg(name='hostProcess', type=d.T.boolean)]),
                withHostProcess(hostProcess): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { container+: { securityContext+: { windowsOptions+: { hostProcess: hostProcess } } } } } } } },
                '#withRunAsUserName':: d.fn(help='"The UserName in Windows to run the entrypoint of the container process.\\nDefaults to the user specified in image metadata if unspecified.\\nMay also be set in PodSecurityContext. If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence."', args=[d.arg(name='runAsUserName', type=d.T.string)]),
                withRunAsUserName(runAsUserName): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { container+: { securityContext+: { windowsOptions+: { runAsUserName: runAsUserName } } } } } } } },
              },
              '#withAllowPrivilegeEscalation':: d.fn(help='"AllowPrivilegeEscalation controls whether a process can gain more\\nprivileges than its parent process. This bool directly controls if\\nthe no_new_privs flag will be set on the container process.\\nAllowPrivilegeEscalation is true always when the container is:\\n1) run as Privileged\\n2) has CAP_SYS_ADMIN\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='allowPrivilegeEscalation', type=d.T.boolean)]),
              withAllowPrivilegeEscalation(allowPrivilegeEscalation): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { container+: { securityContext+: { allowPrivilegeEscalation: allowPrivilegeEscalation } } } } } } },
              '#withPrivileged':: d.fn(help='"Run container in privileged mode.\\nProcesses in privileged containers are essentially equivalent to root on the host.\\nDefaults to false.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='privileged', type=d.T.boolean)]),
              withPrivileged(privileged): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { container+: { securityContext+: { privileged: privileged } } } } } } },
              '#withProcMount':: d.fn(help='"procMount denotes the type of proc mount to use for the containers.\\nThe default value is Default which uses the container runtime defaults for\\nreadonly paths and masked paths.\\nThis requires the ProcMountType feature flag to be enabled.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='procMount', type=d.T.string)]),
              withProcMount(procMount): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { container+: { securityContext+: { procMount: procMount } } } } } } },
              '#withReadOnlyRootFilesystem':: d.fn(help='"Whether this container has a read-only root filesystem.\\nDefault is false.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='readOnlyRootFilesystem', type=d.T.boolean)]),
              withReadOnlyRootFilesystem(readOnlyRootFilesystem): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { container+: { securityContext+: { readOnlyRootFilesystem: readOnlyRootFilesystem } } } } } } },
              '#withRunAsGroup':: d.fn(help='"The GID to run the entrypoint of the container process.\\nUses runtime default if unset.\\nMay also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='runAsGroup', type=d.T.integer)]),
              withRunAsGroup(runAsGroup): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { container+: { securityContext+: { runAsGroup: runAsGroup } } } } } } },
              '#withRunAsNonRoot':: d.fn(help='"Indicates that the container must run as a non-root user.\\nIf true, the Kubelet will validate the image at runtime to ensure that it\\ndoes not run as UID 0 (root) and fail to start the container if it does.\\nIf unset or false, no such validation will be performed.\\nMay also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence."', args=[d.arg(name='runAsNonRoot', type=d.T.boolean)]),
              withRunAsNonRoot(runAsNonRoot): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { container+: { securityContext+: { runAsNonRoot: runAsNonRoot } } } } } } },
              '#withRunAsUser':: d.fn(help='"The UID to run the entrypoint of the container process.\\nDefaults to user specified in image metadata if unspecified.\\nMay also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='runAsUser', type=d.T.integer)]),
              withRunAsUser(runAsUser): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { container+: { securityContext+: { runAsUser: runAsUser } } } } } } },
            },
            '#volumeMounts':: d.obj(help="\"VolumeMounts are volumes to mount into the container's filesystem.\\nCannot be updated.\""),
            volumeMounts: {
              '#withMountPath':: d.fn(help="\"Path within the container at which the volume should be mounted.  Must\\nnot contain ':'.\"", args=[d.arg(name='mountPath', type=d.T.string)]),
              withMountPath(mountPath): { mountPath: mountPath },
              '#withMountPropagation':: d.fn(help='"mountPropagation determines how mounts are propagated from the host\\nto container and the other way around.\\nWhen not set, MountPropagationNone is used.\\nThis field is beta in 1.10.\\nWhen RecursiveReadOnly is set to IfPossible or to Enabled, MountPropagation must be None or unspecified\\n(which defaults to None)."', args=[d.arg(name='mountPropagation', type=d.T.string)]),
              withMountPropagation(mountPropagation): { mountPropagation: mountPropagation },
              '#withName':: d.fn(help='"This must match the Name of a Volume."', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { name: name },
              '#withReadOnly':: d.fn(help='"Mounted read-only if true, read-write otherwise (false or unspecified).\\nDefaults to false."', args=[d.arg(name='readOnly', type=d.T.boolean)]),
              withReadOnly(readOnly): { readOnly: readOnly },
              '#withRecursiveReadOnly':: d.fn(help='"RecursiveReadOnly specifies whether read-only mounts should be handled\\nrecursively.\\n\\nIf ReadOnly is false, this field has no meaning and must be unspecified.\\n\\nIf ReadOnly is true, and this field is set to Disabled, the mount is not made\\nrecursively read-only.  If this field is set to IfPossible, the mount is made\\nrecursively read-only, if it is supported by the container runtime.  If this\\nfield is set to Enabled, the mount is made recursively read-only if it is\\nsupported by the container runtime, otherwise the pod will not be started and\\nan error will be generated to indicate the reason.\\n\\nIf this field is set to IfPossible or Enabled, MountPropagation must be set to\\nNone (or be unspecified, which defaults to None).\\n\\nIf this field is not specified, it is treated as an equivalent of Disabled."', args=[d.arg(name='recursiveReadOnly', type=d.T.string)]),
              withRecursiveReadOnly(recursiveReadOnly): { recursiveReadOnly: recursiveReadOnly },
              '#withSubPath':: d.fn(help="\"Path within the volume from which the container's volume should be mounted.\\nDefaults to \\\"\\\" (volume's root).\"", args=[d.arg(name='subPath', type=d.T.string)]),
              withSubPath(subPath): { subPath: subPath },
              '#withSubPathExpr':: d.fn(help="\"Expanded path within the volume from which the container's volume should be mounted.\\nBehaves similarly to SubPath but environment variable references $(VAR_NAME) are expanded using the container's environment.\\nDefaults to \\\"\\\" (volume's root).\\nSubPathExpr and SubPath are mutually exclusive.\"", args=[d.arg(name='subPathExpr', type=d.T.string)]),
              withSubPathExpr(subPathExpr): { subPathExpr: subPathExpr },
            },
            '#withEnv':: d.fn(help='"List of environment variables to set in the container."', args=[d.arg(name='env', type=d.T.array)]),
            withEnv(env): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { container+: { env: if std.isArray(v=env) then env else [env] } } } } } },
            '#withEnvMixin':: d.fn(help='"List of environment variables to set in the container."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='env', type=d.T.array)]),
            withEnvMixin(env): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { container+: { env+: if std.isArray(v=env) then env else [env] } } } } } },
            '#withImage':: d.fn(help='"Image specifies the EnvoyProxy container image to be used, instead of the default image."', args=[d.arg(name='image', type=d.T.string)]),
            withImage(image): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { container+: { image: image } } } } } },
            '#withVolumeMounts':: d.fn(help="\"VolumeMounts are volumes to mount into the container's filesystem.\\nCannot be updated.\"", args=[d.arg(name='volumeMounts', type=d.T.array)]),
            withVolumeMounts(volumeMounts): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { container+: { volumeMounts: if std.isArray(v=volumeMounts) then volumeMounts else [volumeMounts] } } } } } },
            '#withVolumeMountsMixin':: d.fn(help="\"VolumeMounts are volumes to mount into the container's filesystem.\\nCannot be updated.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='volumeMounts', type=d.T.array)]),
            withVolumeMountsMixin(volumeMounts): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { container+: { volumeMounts+: if std.isArray(v=volumeMounts) then volumeMounts else [volumeMounts] } } } } } },
          },
          '#initContainers':: d.obj(help='"List of initialization containers belonging to the pod.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/init-containers/"'),
          initContainers: {
            '#env':: d.obj(help='"List of environment variables to set in the container.\\nCannot be updated."'),
            env: {
              '#valueFrom':: d.obj(help="\"Source for the environment variable's value. Cannot be used if value is not empty.\""),
              valueFrom: {
                '#configMapKeyRef':: d.obj(help='"Selects a key of a ConfigMap."'),
                configMapKeyRef: {
                  '#withKey':: d.fn(help='"The key to select."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { valueFrom+: { configMapKeyRef+: { key: key } } },
                  '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
                  withName(name): { valueFrom+: { configMapKeyRef+: { name: name } } },
                  '#withOptional':: d.fn(help='"Specify whether the ConfigMap or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
                  withOptional(optional): { valueFrom+: { configMapKeyRef+: { optional: optional } } },
                },
                '#fieldRef':: d.obj(help="\"Selects a field of the pod: supports metadata.name, metadata.namespace, `metadata.labels['\u003cKEY\u003e']`, `metadata.annotations['\u003cKEY\u003e']`,\\nspec.nodeName, spec.serviceAccountName, status.hostIP, status.podIP, status.podIPs.\""),
                fieldRef: {
                  '#withApiVersion':: d.fn(help='"Version of the schema the FieldPath is written in terms of, defaults to \\"v1\\"."', args=[d.arg(name='apiVersion', type=d.T.string)]),
                  withApiVersion(apiVersion): { valueFrom+: { fieldRef+: { apiVersion: apiVersion } } },
                  '#withFieldPath':: d.fn(help='"Path of the field to select in the specified API version."', args=[d.arg(name='fieldPath', type=d.T.string)]),
                  withFieldPath(fieldPath): { valueFrom+: { fieldRef+: { fieldPath: fieldPath } } },
                },
                '#resourceFieldRef':: d.obj(help='"Selects a resource of the container: only resources limits and requests\\n(limits.cpu, limits.memory, limits.ephemeral-storage, requests.cpu, requests.memory and requests.ephemeral-storage) are currently supported."'),
                resourceFieldRef: {
                  '#withContainerName':: d.fn(help='"Container name: required for volumes, optional for env vars"', args=[d.arg(name='containerName', type=d.T.string)]),
                  withContainerName(containerName): { valueFrom+: { resourceFieldRef+: { containerName: containerName } } },
                  '#withDivisor':: d.fn(help='"Specifies the output format of the exposed resources, defaults to \\"1\\', args=[d.arg(name='divisor', type=d.T.any)]),
                  withDivisor(divisor): { valueFrom+: { resourceFieldRef+: { divisor: divisor } } },
                  '#withResource':: d.fn(help='"Required: resource to select"', args=[d.arg(name='resource', type=d.T.string)]),
                  withResource(resource): { valueFrom+: { resourceFieldRef+: { resource: resource } } },
                },
                '#secretKeyRef':: d.obj(help="\"Selects a key of a secret in the pod's namespace\""),
                secretKeyRef: {
                  '#withKey':: d.fn(help='"The key of the secret to select from.  Must be a valid secret key."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { valueFrom+: { secretKeyRef+: { key: key } } },
                  '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
                  withName(name): { valueFrom+: { secretKeyRef+: { name: name } } },
                  '#withOptional':: d.fn(help='"Specify whether the Secret or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
                  withOptional(optional): { valueFrom+: { secretKeyRef+: { optional: optional } } },
                },
              },
              '#withName':: d.fn(help='"Name of the environment variable. Must be a C_IDENTIFIER."', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { name: name },
              '#withValue':: d.fn(help='"Variable references $(VAR_NAME) are expanded\\nusing the previously defined environment variables in the container and\\nany service environment variables. If a variable cannot be resolved,\\nthe reference in the input string will be unchanged. Double $$ are reduced\\nto a single $, which allows for escaping the $(VAR_NAME) syntax: i.e.\\n\\"$$(VAR_NAME)\\" will produce the string literal \\"$(VAR_NAME)\\".\\nEscaped references will never be expanded, regardless of whether the variable\\nexists or not.\\nDefaults to \\"\\"."', args=[d.arg(name='value', type=d.T.string)]),
              withValue(value): { value: value },
            },
            '#envFrom':: d.obj(help='"List of sources to populate environment variables in the container.\\nThe keys defined within a source must be a C_IDENTIFIER. All invalid keys\\nwill be reported as an event when the container is starting. When a key exists in multiple\\nsources, the value associated with the last source will take precedence.\\nValues defined by an Env with a duplicate key will take precedence.\\nCannot be updated."'),
            envFrom: {
              '#configMapRef':: d.obj(help='"The ConfigMap to select from"'),
              configMapRef: {
                '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
                withName(name): { configMapRef+: { name: name } },
                '#withOptional':: d.fn(help='"Specify whether the ConfigMap must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
                withOptional(optional): { configMapRef+: { optional: optional } },
              },
              '#secretRef':: d.obj(help='"The Secret to select from"'),
              secretRef: {
                '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
                withName(name): { secretRef+: { name: name } },
                '#withOptional':: d.fn(help='"Specify whether the Secret must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
                withOptional(optional): { secretRef+: { optional: optional } },
              },
              '#withPrefix':: d.fn(help='"Optional text to prepend to the name of each environment variable. Must be a C_IDENTIFIER."', args=[d.arg(name='prefix', type=d.T.string)]),
              withPrefix(prefix): { prefix: prefix },
            },
            '#lifecycle':: d.obj(help='"Actions that the management system should take in response to container lifecycle events.\\nCannot be updated."'),
            lifecycle: {
              '#postStart':: d.obj(help='"PostStart is called immediately after a container is created. If the handler fails,\\nthe container is terminated and restarted according to its restart policy.\\nOther management of the container blocks until the hook completes.\\nMore info: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks"'),
              postStart: {
                '#exec':: d.obj(help='"Exec specifies a command to execute in the container."'),
                exec: {
                  '#withCommand':: d.fn(help="\"Command is the command line to execute inside the container, the working directory for the\\ncommand  is root ('/') in the container's filesystem. The command is simply exec'd, it is\\nnot run inside a shell, so traditional shell instructions ('|', etc) won't work. To use\\na shell, you need to explicitly call out to that shell.\\nExit status of 0 is treated as live/healthy and non-zero is unhealthy.\"", args=[d.arg(name='command', type=d.T.array)]),
                  withCommand(command): { lifecycle+: { postStart+: { exec+: { command: if std.isArray(v=command) then command else [command] } } } },
                  '#withCommandMixin':: d.fn(help="\"Command is the command line to execute inside the container, the working directory for the\\ncommand  is root ('/') in the container's filesystem. The command is simply exec'd, it is\\nnot run inside a shell, so traditional shell instructions ('|', etc) won't work. To use\\na shell, you need to explicitly call out to that shell.\\nExit status of 0 is treated as live/healthy and non-zero is unhealthy.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='command', type=d.T.array)]),
                  withCommandMixin(command): { lifecycle+: { postStart+: { exec+: { command+: if std.isArray(v=command) then command else [command] } } } },
                },
                '#httpGet':: d.obj(help='"HTTPGet specifies an HTTP GET request to perform."'),
                httpGet: {
                  '#httpHeaders':: d.obj(help='"Custom headers to set in the request. HTTP allows repeated headers."'),
                  httpHeaders: {
                    '#withName':: d.fn(help='"The header field name.\\nThis will be canonicalized upon output, so case-variant names will be understood as the same header."', args=[d.arg(name='name', type=d.T.string)]),
                    withName(name): { name: name },
                    '#withValue':: d.fn(help='"The header field value"', args=[d.arg(name='value', type=d.T.string)]),
                    withValue(value): { value: value },
                  },
                  '#withHost':: d.fn(help='"Host name to connect to, defaults to the pod IP. You probably want to set\\n\\"Host\\" in httpHeaders instead."', args=[d.arg(name='host', type=d.T.string)]),
                  withHost(host): { lifecycle+: { postStart+: { httpGet+: { host: host } } } },
                  '#withHttpHeaders':: d.fn(help='"Custom headers to set in the request. HTTP allows repeated headers."', args=[d.arg(name='httpHeaders', type=d.T.array)]),
                  withHttpHeaders(httpHeaders): { lifecycle+: { postStart+: { httpGet+: { httpHeaders: if std.isArray(v=httpHeaders) then httpHeaders else [httpHeaders] } } } },
                  '#withHttpHeadersMixin':: d.fn(help='"Custom headers to set in the request. HTTP allows repeated headers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='httpHeaders', type=d.T.array)]),
                  withHttpHeadersMixin(httpHeaders): { lifecycle+: { postStart+: { httpGet+: { httpHeaders+: if std.isArray(v=httpHeaders) then httpHeaders else [httpHeaders] } } } },
                  '#withPath':: d.fn(help='"Path to access on the HTTP server."', args=[d.arg(name='path', type=d.T.string)]),
                  withPath(path): { lifecycle+: { postStart+: { httpGet+: { path: path } } } },
                  '#withPort':: d.fn(help='"Name or number of the port to access on the container.\\nNumber must be in the range 1 to 65535.\\nName must be an IANA_SVC_NAME."', args=[d.arg(name='port', type=d.T.any)]),
                  withPort(port): { lifecycle+: { postStart+: { httpGet+: { port: port } } } },
                  '#withScheme':: d.fn(help='"Scheme to use for connecting to the host.\\nDefaults to HTTP."', args=[d.arg(name='scheme', type=d.T.string)]),
                  withScheme(scheme): { lifecycle+: { postStart+: { httpGet+: { scheme: scheme } } } },
                },
                '#sleep':: d.obj(help='"Sleep represents a duration that the container should sleep."'),
                sleep: {
                  '#withSeconds':: d.fn(help='"Seconds is the number of seconds to sleep."', args=[d.arg(name='seconds', type=d.T.integer)]),
                  withSeconds(seconds): { lifecycle+: { postStart+: { sleep+: { seconds: seconds } } } },
                },
                '#tcpSocket':: d.obj(help='"Deprecated. TCPSocket is NOT supported as a LifecycleHandler and kept\\nfor backward compatibility. There is no validation of this field and\\nlifecycle hooks will fail at runtime when it is specified."'),
                tcpSocket: {
                  '#withHost':: d.fn(help='"Optional: Host name to connect to, defaults to the pod IP."', args=[d.arg(name='host', type=d.T.string)]),
                  withHost(host): { lifecycle+: { postStart+: { tcpSocket+: { host: host } } } },
                  '#withPort':: d.fn(help='"Number or name of the port to access on the container.\\nNumber must be in the range 1 to 65535.\\nName must be an IANA_SVC_NAME."', args=[d.arg(name='port', type=d.T.any)]),
                  withPort(port): { lifecycle+: { postStart+: { tcpSocket+: { port: port } } } },
                },
              },
              '#preStop':: d.obj(help="\"PreStop is called immediately before a container is terminated due to an\\nAPI request or management event such as liveness/startup probe failure,\\npreemption, resource contention, etc. The handler is not called if the\\ncontainer crashes or exits. The Pod's termination grace period countdown begins before the\\nPreStop hook is executed. Regardless of the outcome of the handler, the\\ncontainer will eventually terminate within the Pod's termination grace\\nperiod (unless delayed by finalizers). Other management of the container blocks until the hook completes\\nor until the termination grace period is reached.\\nMore info: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks\""),
              preStop: {
                '#exec':: d.obj(help='"Exec specifies a command to execute in the container."'),
                exec: {
                  '#withCommand':: d.fn(help="\"Command is the command line to execute inside the container, the working directory for the\\ncommand  is root ('/') in the container's filesystem. The command is simply exec'd, it is\\nnot run inside a shell, so traditional shell instructions ('|', etc) won't work. To use\\na shell, you need to explicitly call out to that shell.\\nExit status of 0 is treated as live/healthy and non-zero is unhealthy.\"", args=[d.arg(name='command', type=d.T.array)]),
                  withCommand(command): { lifecycle+: { preStop+: { exec+: { command: if std.isArray(v=command) then command else [command] } } } },
                  '#withCommandMixin':: d.fn(help="\"Command is the command line to execute inside the container, the working directory for the\\ncommand  is root ('/') in the container's filesystem. The command is simply exec'd, it is\\nnot run inside a shell, so traditional shell instructions ('|', etc) won't work. To use\\na shell, you need to explicitly call out to that shell.\\nExit status of 0 is treated as live/healthy and non-zero is unhealthy.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='command', type=d.T.array)]),
                  withCommandMixin(command): { lifecycle+: { preStop+: { exec+: { command+: if std.isArray(v=command) then command else [command] } } } },
                },
                '#httpGet':: d.obj(help='"HTTPGet specifies an HTTP GET request to perform."'),
                httpGet: {
                  '#httpHeaders':: d.obj(help='"Custom headers to set in the request. HTTP allows repeated headers."'),
                  httpHeaders: {
                    '#withName':: d.fn(help='"The header field name.\\nThis will be canonicalized upon output, so case-variant names will be understood as the same header."', args=[d.arg(name='name', type=d.T.string)]),
                    withName(name): { name: name },
                    '#withValue':: d.fn(help='"The header field value"', args=[d.arg(name='value', type=d.T.string)]),
                    withValue(value): { value: value },
                  },
                  '#withHost':: d.fn(help='"Host name to connect to, defaults to the pod IP. You probably want to set\\n\\"Host\\" in httpHeaders instead."', args=[d.arg(name='host', type=d.T.string)]),
                  withHost(host): { lifecycle+: { preStop+: { httpGet+: { host: host } } } },
                  '#withHttpHeaders':: d.fn(help='"Custom headers to set in the request. HTTP allows repeated headers."', args=[d.arg(name='httpHeaders', type=d.T.array)]),
                  withHttpHeaders(httpHeaders): { lifecycle+: { preStop+: { httpGet+: { httpHeaders: if std.isArray(v=httpHeaders) then httpHeaders else [httpHeaders] } } } },
                  '#withHttpHeadersMixin':: d.fn(help='"Custom headers to set in the request. HTTP allows repeated headers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='httpHeaders', type=d.T.array)]),
                  withHttpHeadersMixin(httpHeaders): { lifecycle+: { preStop+: { httpGet+: { httpHeaders+: if std.isArray(v=httpHeaders) then httpHeaders else [httpHeaders] } } } },
                  '#withPath':: d.fn(help='"Path to access on the HTTP server."', args=[d.arg(name='path', type=d.T.string)]),
                  withPath(path): { lifecycle+: { preStop+: { httpGet+: { path: path } } } },
                  '#withPort':: d.fn(help='"Name or number of the port to access on the container.\\nNumber must be in the range 1 to 65535.\\nName must be an IANA_SVC_NAME."', args=[d.arg(name='port', type=d.T.any)]),
                  withPort(port): { lifecycle+: { preStop+: { httpGet+: { port: port } } } },
                  '#withScheme':: d.fn(help='"Scheme to use for connecting to the host.\\nDefaults to HTTP."', args=[d.arg(name='scheme', type=d.T.string)]),
                  withScheme(scheme): { lifecycle+: { preStop+: { httpGet+: { scheme: scheme } } } },
                },
                '#sleep':: d.obj(help='"Sleep represents a duration that the container should sleep."'),
                sleep: {
                  '#withSeconds':: d.fn(help='"Seconds is the number of seconds to sleep."', args=[d.arg(name='seconds', type=d.T.integer)]),
                  withSeconds(seconds): { lifecycle+: { preStop+: { sleep+: { seconds: seconds } } } },
                },
                '#tcpSocket':: d.obj(help='"Deprecated. TCPSocket is NOT supported as a LifecycleHandler and kept\\nfor backward compatibility. There is no validation of this field and\\nlifecycle hooks will fail at runtime when it is specified."'),
                tcpSocket: {
                  '#withHost':: d.fn(help='"Optional: Host name to connect to, defaults to the pod IP."', args=[d.arg(name='host', type=d.T.string)]),
                  withHost(host): { lifecycle+: { preStop+: { tcpSocket+: { host: host } } } },
                  '#withPort':: d.fn(help='"Number or name of the port to access on the container.\\nNumber must be in the range 1 to 65535.\\nName must be an IANA_SVC_NAME."', args=[d.arg(name='port', type=d.T.any)]),
                  withPort(port): { lifecycle+: { preStop+: { tcpSocket+: { port: port } } } },
                },
              },
              '#withStopSignal':: d.fn(help='"StopSignal defines which signal will be sent to a container when it is being stopped.\\nIf not specified, the default is defined by the container runtime in use.\\nStopSignal can only be set for Pods with a non-empty .spec.os.name"', args=[d.arg(name='stopSignal', type=d.T.string)]),
              withStopSignal(stopSignal): { lifecycle+: { stopSignal: stopSignal } },
            },
            '#livenessProbe':: d.obj(help='"Periodic probe of container liveness.\\nContainer will be restarted if the probe fails.\\nCannot be updated.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes"'),
            livenessProbe: {
              '#exec':: d.obj(help='"Exec specifies a command to execute in the container."'),
              exec: {
                '#withCommand':: d.fn(help="\"Command is the command line to execute inside the container, the working directory for the\\ncommand  is root ('/') in the container's filesystem. The command is simply exec'd, it is\\nnot run inside a shell, so traditional shell instructions ('|', etc) won't work. To use\\na shell, you need to explicitly call out to that shell.\\nExit status of 0 is treated as live/healthy and non-zero is unhealthy.\"", args=[d.arg(name='command', type=d.T.array)]),
                withCommand(command): { livenessProbe+: { exec+: { command: if std.isArray(v=command) then command else [command] } } },
                '#withCommandMixin':: d.fn(help="\"Command is the command line to execute inside the container, the working directory for the\\ncommand  is root ('/') in the container's filesystem. The command is simply exec'd, it is\\nnot run inside a shell, so traditional shell instructions ('|', etc) won't work. To use\\na shell, you need to explicitly call out to that shell.\\nExit status of 0 is treated as live/healthy and non-zero is unhealthy.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='command', type=d.T.array)]),
                withCommandMixin(command): { livenessProbe+: { exec+: { command+: if std.isArray(v=command) then command else [command] } } },
              },
              '#grpc':: d.obj(help='"GRPC specifies a GRPC HealthCheckRequest."'),
              grpc: {
                '#withPort':: d.fn(help='"Port number of the gRPC service. Number must be in the range 1 to 65535."', args=[d.arg(name='port', type=d.T.integer)]),
                withPort(port): { livenessProbe+: { grpc+: { port: port } } },
                '#withService':: d.fn(help='"Service is the name of the service to place in the gRPC HealthCheckRequest\\n(see https://github.com/grpc/grpc/blob/master/doc/health-checking.md).\\n\\nIf this is not specified, the default behavior is defined by gRPC."', args=[d.arg(name='service', type=d.T.string)]),
                withService(service): { livenessProbe+: { grpc+: { service: service } } },
              },
              '#httpGet':: d.obj(help='"HTTPGet specifies an HTTP GET request to perform."'),
              httpGet: {
                '#httpHeaders':: d.obj(help='"Custom headers to set in the request. HTTP allows repeated headers."'),
                httpHeaders: {
                  '#withName':: d.fn(help='"The header field name.\\nThis will be canonicalized upon output, so case-variant names will be understood as the same header."', args=[d.arg(name='name', type=d.T.string)]),
                  withName(name): { name: name },
                  '#withValue':: d.fn(help='"The header field value"', args=[d.arg(name='value', type=d.T.string)]),
                  withValue(value): { value: value },
                },
                '#withHost':: d.fn(help='"Host name to connect to, defaults to the pod IP. You probably want to set\\n\\"Host\\" in httpHeaders instead."', args=[d.arg(name='host', type=d.T.string)]),
                withHost(host): { livenessProbe+: { httpGet+: { host: host } } },
                '#withHttpHeaders':: d.fn(help='"Custom headers to set in the request. HTTP allows repeated headers."', args=[d.arg(name='httpHeaders', type=d.T.array)]),
                withHttpHeaders(httpHeaders): { livenessProbe+: { httpGet+: { httpHeaders: if std.isArray(v=httpHeaders) then httpHeaders else [httpHeaders] } } },
                '#withHttpHeadersMixin':: d.fn(help='"Custom headers to set in the request. HTTP allows repeated headers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='httpHeaders', type=d.T.array)]),
                withHttpHeadersMixin(httpHeaders): { livenessProbe+: { httpGet+: { httpHeaders+: if std.isArray(v=httpHeaders) then httpHeaders else [httpHeaders] } } },
                '#withPath':: d.fn(help='"Path to access on the HTTP server."', args=[d.arg(name='path', type=d.T.string)]),
                withPath(path): { livenessProbe+: { httpGet+: { path: path } } },
                '#withPort':: d.fn(help='"Name or number of the port to access on the container.\\nNumber must be in the range 1 to 65535.\\nName must be an IANA_SVC_NAME."', args=[d.arg(name='port', type=d.T.any)]),
                withPort(port): { livenessProbe+: { httpGet+: { port: port } } },
                '#withScheme':: d.fn(help='"Scheme to use for connecting to the host.\\nDefaults to HTTP."', args=[d.arg(name='scheme', type=d.T.string)]),
                withScheme(scheme): { livenessProbe+: { httpGet+: { scheme: scheme } } },
              },
              '#tcpSocket':: d.obj(help='"TCPSocket specifies a connection to a TCP port."'),
              tcpSocket: {
                '#withHost':: d.fn(help='"Optional: Host name to connect to, defaults to the pod IP."', args=[d.arg(name='host', type=d.T.string)]),
                withHost(host): { livenessProbe+: { tcpSocket+: { host: host } } },
                '#withPort':: d.fn(help='"Number or name of the port to access on the container.\\nNumber must be in the range 1 to 65535.\\nName must be an IANA_SVC_NAME."', args=[d.arg(name='port', type=d.T.any)]),
                withPort(port): { livenessProbe+: { tcpSocket+: { port: port } } },
              },
              '#withFailureThreshold':: d.fn(help='"Minimum consecutive failures for the probe to be considered failed after having succeeded.\\nDefaults to 3. Minimum value is 1."', args=[d.arg(name='failureThreshold', type=d.T.integer)]),
              withFailureThreshold(failureThreshold): { livenessProbe+: { failureThreshold: failureThreshold } },
              '#withInitialDelaySeconds':: d.fn(help='"Number of seconds after the container has started before liveness probes are initiated.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes"', args=[d.arg(name='initialDelaySeconds', type=d.T.integer)]),
              withInitialDelaySeconds(initialDelaySeconds): { livenessProbe+: { initialDelaySeconds: initialDelaySeconds } },
              '#withPeriodSeconds':: d.fn(help='"How often (in seconds) to perform the probe.\\nDefault to 10 seconds. Minimum value is 1."', args=[d.arg(name='periodSeconds', type=d.T.integer)]),
              withPeriodSeconds(periodSeconds): { livenessProbe+: { periodSeconds: periodSeconds } },
              '#withSuccessThreshold':: d.fn(help='"Minimum consecutive successes for the probe to be considered successful after having failed.\\nDefaults to 1. Must be 1 for liveness and startup. Minimum value is 1."', args=[d.arg(name='successThreshold', type=d.T.integer)]),
              withSuccessThreshold(successThreshold): { livenessProbe+: { successThreshold: successThreshold } },
              '#withTerminationGracePeriodSeconds':: d.fn(help="\"Optional duration in seconds the pod needs to terminate gracefully upon probe failure.\\nThe grace period is the duration in seconds after the processes running in the pod are sent\\na termination signal and the time when the processes are forcibly halted with a kill signal.\\nSet this value longer than the expected cleanup time for your process.\\nIf this value is nil, the pod's terminationGracePeriodSeconds will be used. Otherwise, this\\nvalue overrides the value provided by the pod spec.\\nValue must be non-negative integer. The value zero indicates stop immediately via\\nthe kill signal (no opportunity to shut down).\\nThis is a beta field and requires enabling ProbeTerminationGracePeriod feature gate.\\nMinimum value is 1. spec.terminationGracePeriodSeconds is used if unset.\"", args=[d.arg(name='terminationGracePeriodSeconds', type=d.T.integer)]),
              withTerminationGracePeriodSeconds(terminationGracePeriodSeconds): { livenessProbe+: { terminationGracePeriodSeconds: terminationGracePeriodSeconds } },
              '#withTimeoutSeconds':: d.fn(help='"Number of seconds after which the probe times out.\\nDefaults to 1 second. Minimum value is 1.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes"', args=[d.arg(name='timeoutSeconds', type=d.T.integer)]),
              withTimeoutSeconds(timeoutSeconds): { livenessProbe+: { timeoutSeconds: timeoutSeconds } },
            },
            '#ports':: d.obj(help='"List of ports to expose from the container. Not specifying a port here\\nDOES NOT prevent that port from being exposed. Any port which is\\nlistening on the default \\"0.0.0.0\\" address inside a container will be\\naccessible from the network.\\nModifying this array with strategic merge patch may corrupt the data.\\nFor more information See https://github.com/kubernetes/kubernetes/issues/108255.\\nCannot be updated."'),
            ports: {
              '#withContainerPort':: d.fn(help="\"Number of port to expose on the pod's IP address.\\nThis must be a valid port number, 0 \u003c x \u003c 65536.\"", args=[d.arg(name='containerPort', type=d.T.integer)]),
              withContainerPort(containerPort): { containerPort: containerPort },
              '#withHostIP':: d.fn(help='"What host IP to bind the external port to."', args=[d.arg(name='hostIP', type=d.T.string)]),
              withHostIP(hostIP): { hostIP: hostIP },
              '#withHostPort':: d.fn(help='"Number of port to expose on the host.\\nIf specified, this must be a valid port number, 0 < x < 65536.\\nIf HostNetwork is specified, this must match ContainerPort.\\nMost containers do not need this."', args=[d.arg(name='hostPort', type=d.T.integer)]),
              withHostPort(hostPort): { hostPort: hostPort },
              '#withName':: d.fn(help='"If specified, this must be an IANA_SVC_NAME and unique within the pod. Each\\nnamed port in a pod must have a unique name. Name for the port that can be\\nreferred to by services."', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { name: name },
              '#withProtocol':: d.fn(help='"Protocol for port. Must be UDP, TCP, or SCTP.\\nDefaults to \\"TCP\\"."', args=[d.arg(name='protocol', type=d.T.string)]),
              withProtocol(protocol): { protocol: protocol },
            },
            '#readinessProbe':: d.obj(help='"Periodic probe of container service readiness.\\nContainer will be removed from service endpoints if the probe fails.\\nCannot be updated.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes"'),
            readinessProbe: {
              '#exec':: d.obj(help='"Exec specifies a command to execute in the container."'),
              exec: {
                '#withCommand':: d.fn(help="\"Command is the command line to execute inside the container, the working directory for the\\ncommand  is root ('/') in the container's filesystem. The command is simply exec'd, it is\\nnot run inside a shell, so traditional shell instructions ('|', etc) won't work. To use\\na shell, you need to explicitly call out to that shell.\\nExit status of 0 is treated as live/healthy and non-zero is unhealthy.\"", args=[d.arg(name='command', type=d.T.array)]),
                withCommand(command): { readinessProbe+: { exec+: { command: if std.isArray(v=command) then command else [command] } } },
                '#withCommandMixin':: d.fn(help="\"Command is the command line to execute inside the container, the working directory for the\\ncommand  is root ('/') in the container's filesystem. The command is simply exec'd, it is\\nnot run inside a shell, so traditional shell instructions ('|', etc) won't work. To use\\na shell, you need to explicitly call out to that shell.\\nExit status of 0 is treated as live/healthy and non-zero is unhealthy.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='command', type=d.T.array)]),
                withCommandMixin(command): { readinessProbe+: { exec+: { command+: if std.isArray(v=command) then command else [command] } } },
              },
              '#grpc':: d.obj(help='"GRPC specifies a GRPC HealthCheckRequest."'),
              grpc: {
                '#withPort':: d.fn(help='"Port number of the gRPC service. Number must be in the range 1 to 65535."', args=[d.arg(name='port', type=d.T.integer)]),
                withPort(port): { readinessProbe+: { grpc+: { port: port } } },
                '#withService':: d.fn(help='"Service is the name of the service to place in the gRPC HealthCheckRequest\\n(see https://github.com/grpc/grpc/blob/master/doc/health-checking.md).\\n\\nIf this is not specified, the default behavior is defined by gRPC."', args=[d.arg(name='service', type=d.T.string)]),
                withService(service): { readinessProbe+: { grpc+: { service: service } } },
              },
              '#httpGet':: d.obj(help='"HTTPGet specifies an HTTP GET request to perform."'),
              httpGet: {
                '#httpHeaders':: d.obj(help='"Custom headers to set in the request. HTTP allows repeated headers."'),
                httpHeaders: {
                  '#withName':: d.fn(help='"The header field name.\\nThis will be canonicalized upon output, so case-variant names will be understood as the same header."', args=[d.arg(name='name', type=d.T.string)]),
                  withName(name): { name: name },
                  '#withValue':: d.fn(help='"The header field value"', args=[d.arg(name='value', type=d.T.string)]),
                  withValue(value): { value: value },
                },
                '#withHost':: d.fn(help='"Host name to connect to, defaults to the pod IP. You probably want to set\\n\\"Host\\" in httpHeaders instead."', args=[d.arg(name='host', type=d.T.string)]),
                withHost(host): { readinessProbe+: { httpGet+: { host: host } } },
                '#withHttpHeaders':: d.fn(help='"Custom headers to set in the request. HTTP allows repeated headers."', args=[d.arg(name='httpHeaders', type=d.T.array)]),
                withHttpHeaders(httpHeaders): { readinessProbe+: { httpGet+: { httpHeaders: if std.isArray(v=httpHeaders) then httpHeaders else [httpHeaders] } } },
                '#withHttpHeadersMixin':: d.fn(help='"Custom headers to set in the request. HTTP allows repeated headers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='httpHeaders', type=d.T.array)]),
                withHttpHeadersMixin(httpHeaders): { readinessProbe+: { httpGet+: { httpHeaders+: if std.isArray(v=httpHeaders) then httpHeaders else [httpHeaders] } } },
                '#withPath':: d.fn(help='"Path to access on the HTTP server."', args=[d.arg(name='path', type=d.T.string)]),
                withPath(path): { readinessProbe+: { httpGet+: { path: path } } },
                '#withPort':: d.fn(help='"Name or number of the port to access on the container.\\nNumber must be in the range 1 to 65535.\\nName must be an IANA_SVC_NAME."', args=[d.arg(name='port', type=d.T.any)]),
                withPort(port): { readinessProbe+: { httpGet+: { port: port } } },
                '#withScheme':: d.fn(help='"Scheme to use for connecting to the host.\\nDefaults to HTTP."', args=[d.arg(name='scheme', type=d.T.string)]),
                withScheme(scheme): { readinessProbe+: { httpGet+: { scheme: scheme } } },
              },
              '#tcpSocket':: d.obj(help='"TCPSocket specifies a connection to a TCP port."'),
              tcpSocket: {
                '#withHost':: d.fn(help='"Optional: Host name to connect to, defaults to the pod IP."', args=[d.arg(name='host', type=d.T.string)]),
                withHost(host): { readinessProbe+: { tcpSocket+: { host: host } } },
                '#withPort':: d.fn(help='"Number or name of the port to access on the container.\\nNumber must be in the range 1 to 65535.\\nName must be an IANA_SVC_NAME."', args=[d.arg(name='port', type=d.T.any)]),
                withPort(port): { readinessProbe+: { tcpSocket+: { port: port } } },
              },
              '#withFailureThreshold':: d.fn(help='"Minimum consecutive failures for the probe to be considered failed after having succeeded.\\nDefaults to 3. Minimum value is 1."', args=[d.arg(name='failureThreshold', type=d.T.integer)]),
              withFailureThreshold(failureThreshold): { readinessProbe+: { failureThreshold: failureThreshold } },
              '#withInitialDelaySeconds':: d.fn(help='"Number of seconds after the container has started before liveness probes are initiated.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes"', args=[d.arg(name='initialDelaySeconds', type=d.T.integer)]),
              withInitialDelaySeconds(initialDelaySeconds): { readinessProbe+: { initialDelaySeconds: initialDelaySeconds } },
              '#withPeriodSeconds':: d.fn(help='"How often (in seconds) to perform the probe.\\nDefault to 10 seconds. Minimum value is 1."', args=[d.arg(name='periodSeconds', type=d.T.integer)]),
              withPeriodSeconds(periodSeconds): { readinessProbe+: { periodSeconds: periodSeconds } },
              '#withSuccessThreshold':: d.fn(help='"Minimum consecutive successes for the probe to be considered successful after having failed.\\nDefaults to 1. Must be 1 for liveness and startup. Minimum value is 1."', args=[d.arg(name='successThreshold', type=d.T.integer)]),
              withSuccessThreshold(successThreshold): { readinessProbe+: { successThreshold: successThreshold } },
              '#withTerminationGracePeriodSeconds':: d.fn(help="\"Optional duration in seconds the pod needs to terminate gracefully upon probe failure.\\nThe grace period is the duration in seconds after the processes running in the pod are sent\\na termination signal and the time when the processes are forcibly halted with a kill signal.\\nSet this value longer than the expected cleanup time for your process.\\nIf this value is nil, the pod's terminationGracePeriodSeconds will be used. Otherwise, this\\nvalue overrides the value provided by the pod spec.\\nValue must be non-negative integer. The value zero indicates stop immediately via\\nthe kill signal (no opportunity to shut down).\\nThis is a beta field and requires enabling ProbeTerminationGracePeriod feature gate.\\nMinimum value is 1. spec.terminationGracePeriodSeconds is used if unset.\"", args=[d.arg(name='terminationGracePeriodSeconds', type=d.T.integer)]),
              withTerminationGracePeriodSeconds(terminationGracePeriodSeconds): { readinessProbe+: { terminationGracePeriodSeconds: terminationGracePeriodSeconds } },
              '#withTimeoutSeconds':: d.fn(help='"Number of seconds after which the probe times out.\\nDefaults to 1 second. Minimum value is 1.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes"', args=[d.arg(name='timeoutSeconds', type=d.T.integer)]),
              withTimeoutSeconds(timeoutSeconds): { readinessProbe+: { timeoutSeconds: timeoutSeconds } },
            },
            '#resizePolicy':: d.obj(help='"Resources resize policy for the container."'),
            resizePolicy: {
              '#withResourceName':: d.fn(help='"Name of the resource to which this resource resize policy applies.\\nSupported values: cpu, memory."', args=[d.arg(name='resourceName', type=d.T.string)]),
              withResourceName(resourceName): { resourceName: resourceName },
              '#withRestartPolicy':: d.fn(help='"Restart policy to apply when specified resource is resized.\\nIf not specified, it defaults to NotRequired."', args=[d.arg(name='restartPolicy', type=d.T.string)]),
              withRestartPolicy(restartPolicy): { restartPolicy: restartPolicy },
            },
            '#resources':: d.obj(help='"Compute Resources required by this container.\\nCannot be updated.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"'),
            resources: {
              '#claims':: d.obj(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis is an alpha field and requires enabling the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."'),
              claims: {
                '#withName':: d.fn(help='"Name must match the name of one entry in pod.spec.resourceClaims of\\nthe Pod where this field is used. It makes that resource available\\ninside a container."', args=[d.arg(name='name', type=d.T.string)]),
                withName(name): { name: name },
                '#withRequest':: d.fn(help='"Request is the name chosen for a request in the referenced claim.\\nIf empty, everything from the claim is made available, otherwise\\nonly the result of this request."', args=[d.arg(name='request', type=d.T.string)]),
                withRequest(request): { request: request },
              },
              '#withClaims':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis is an alpha field and requires enabling the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."', args=[d.arg(name='claims', type=d.T.array)]),
              withClaims(claims): { resources+: { claims: if std.isArray(v=claims) then claims else [claims] } },
              '#withClaimsMixin':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis is an alpha field and requires enabling the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='claims', type=d.T.array)]),
              withClaimsMixin(claims): { resources+: { claims+: if std.isArray(v=claims) then claims else [claims] } },
              '#withLimits':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='limits', type=d.T.object)]),
              withLimits(limits): { resources+: { limits: limits } },
              '#withLimitsMixin':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='limits', type=d.T.object)]),
              withLimitsMixin(limits): { resources+: { limits+: limits } },
              '#withRequests':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='requests', type=d.T.object)]),
              withRequests(requests): { resources+: { requests: requests } },
              '#withRequestsMixin':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requests', type=d.T.object)]),
              withRequestsMixin(requests): { resources+: { requests+: requests } },
            },
            '#securityContext':: d.obj(help='"SecurityContext defines the security options the container should be run with.\\nIf set, the fields of SecurityContext override the equivalent fields of PodSecurityContext.\\nMore info: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/"'),
            securityContext: {
              '#appArmorProfile':: d.obj(help="\"appArmorProfile is the AppArmor options to use by this container. If set, this profile\\noverrides the pod's appArmorProfile.\\nNote that this field cannot be set when spec.os.name is windows.\""),
              appArmorProfile: {
                '#withLocalhostProfile':: d.fn(help='"localhostProfile indicates a profile loaded on the node that should be used.\\nThe profile must be preconfigured on the node to work.\\nMust match the loaded name of the profile.\\nMust be set if and only if type is \\"Localhost\\"."', args=[d.arg(name='localhostProfile', type=d.T.string)]),
                withLocalhostProfile(localhostProfile): { securityContext+: { appArmorProfile+: { localhostProfile: localhostProfile } } },
                '#withType':: d.fn(help="\"type indicates which kind of AppArmor profile will be applied.\\nValid options are:\\n  Localhost - a profile pre-loaded on the node.\\n  RuntimeDefault - the container runtime's default profile.\\n  Unconfined - no AppArmor enforcement.\"", args=[d.arg(name='type', type=d.T.string)]),
                withType(type): { securityContext+: { appArmorProfile+: { type: type } } },
              },
              '#capabilities':: d.obj(help='"The capabilities to add/drop when running containers.\\nDefaults to the default set of capabilities granted by the container runtime.\\nNote that this field cannot be set when spec.os.name is windows."'),
              capabilities: {
                '#withAdd':: d.fn(help='"Added capabilities"', args=[d.arg(name='add', type=d.T.array)]),
                withAdd(add): { securityContext+: { capabilities+: { add: if std.isArray(v=add) then add else [add] } } },
                '#withAddMixin':: d.fn(help='"Added capabilities"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='add', type=d.T.array)]),
                withAddMixin(add): { securityContext+: { capabilities+: { add+: if std.isArray(v=add) then add else [add] } } },
                '#withDrop':: d.fn(help='"Removed capabilities"', args=[d.arg(name='drop', type=d.T.array)]),
                withDrop(drop): { securityContext+: { capabilities+: { drop: if std.isArray(v=drop) then drop else [drop] } } },
                '#withDropMixin':: d.fn(help='"Removed capabilities"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='drop', type=d.T.array)]),
                withDropMixin(drop): { securityContext+: { capabilities+: { drop+: if std.isArray(v=drop) then drop else [drop] } } },
              },
              '#seLinuxOptions':: d.obj(help='"The SELinux context to be applied to the container.\\nIf unspecified, the container runtime will allocate a random SELinux context for each\\ncontainer.  May also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is windows."'),
              seLinuxOptions: {
                '#withLevel':: d.fn(help='"Level is SELinux level label that applies to the container."', args=[d.arg(name='level', type=d.T.string)]),
                withLevel(level): { securityContext+: { seLinuxOptions+: { level: level } } },
                '#withRole':: d.fn(help='"Role is a SELinux role label that applies to the container."', args=[d.arg(name='role', type=d.T.string)]),
                withRole(role): { securityContext+: { seLinuxOptions+: { role: role } } },
                '#withType':: d.fn(help='"Type is a SELinux type label that applies to the container."', args=[d.arg(name='type', type=d.T.string)]),
                withType(type): { securityContext+: { seLinuxOptions+: { type: type } } },
                '#withUser':: d.fn(help='"User is a SELinux user label that applies to the container."', args=[d.arg(name='user', type=d.T.string)]),
                withUser(user): { securityContext+: { seLinuxOptions+: { user: user } } },
              },
              '#seccompProfile':: d.obj(help='"The seccomp options to use by this container. If seccomp options are\\nprovided at both the pod & container level, the container options\\noverride the pod options.\\nNote that this field cannot be set when spec.os.name is windows."'),
              seccompProfile: {
                '#withLocalhostProfile':: d.fn(help="\"localhostProfile indicates a profile defined in a file on the node should be used.\\nThe profile must be preconfigured on the node to work.\\nMust be a descending path, relative to the kubelet's configured seccomp profile location.\\nMust be set if type is \\\"Localhost\\\". Must NOT be set for any other type.\"", args=[d.arg(name='localhostProfile', type=d.T.string)]),
                withLocalhostProfile(localhostProfile): { securityContext+: { seccompProfile+: { localhostProfile: localhostProfile } } },
                '#withType':: d.fn(help='"type indicates which kind of seccomp profile will be applied.\\nValid options are:\\n\\nLocalhost - a profile defined in a file on the node should be used.\\nRuntimeDefault - the container runtime default profile should be used.\\nUnconfined - no profile should be applied."', args=[d.arg(name='type', type=d.T.string)]),
                withType(type): { securityContext+: { seccompProfile+: { type: type } } },
              },
              '#windowsOptions':: d.obj(help='"The Windows specific settings applied to all containers.\\nIf unspecified, the options from the PodSecurityContext will be used.\\nIf set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is linux."'),
              windowsOptions: {
                '#withGmsaCredentialSpec':: d.fn(help='"GMSACredentialSpec is where the GMSA admission webhook\\n(https://github.com/kubernetes-sigs/windows-gmsa) inlines the contents of the\\nGMSA credential spec named by the GMSACredentialSpecName field."', args=[d.arg(name='gmsaCredentialSpec', type=d.T.string)]),
                withGmsaCredentialSpec(gmsaCredentialSpec): { securityContext+: { windowsOptions+: { gmsaCredentialSpec: gmsaCredentialSpec } } },
                '#withGmsaCredentialSpecName':: d.fn(help='"GMSACredentialSpecName is the name of the GMSA credential spec to use."', args=[d.arg(name='gmsaCredentialSpecName', type=d.T.string)]),
                withGmsaCredentialSpecName(gmsaCredentialSpecName): { securityContext+: { windowsOptions+: { gmsaCredentialSpecName: gmsaCredentialSpecName } } },
                '#withHostProcess':: d.fn(help="\"HostProcess determines if a container should be run as a 'Host Process' container.\\nAll of a Pod's containers must have the same effective HostProcess value\\n(it is not allowed to have a mix of HostProcess containers and non-HostProcess containers).\\nIn addition, if HostProcess is true then HostNetwork must also be set to true.\"", args=[d.arg(name='hostProcess', type=d.T.boolean)]),
                withHostProcess(hostProcess): { securityContext+: { windowsOptions+: { hostProcess: hostProcess } } },
                '#withRunAsUserName':: d.fn(help='"The UserName in Windows to run the entrypoint of the container process.\\nDefaults to the user specified in image metadata if unspecified.\\nMay also be set in PodSecurityContext. If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence."', args=[d.arg(name='runAsUserName', type=d.T.string)]),
                withRunAsUserName(runAsUserName): { securityContext+: { windowsOptions+: { runAsUserName: runAsUserName } } },
              },
              '#withAllowPrivilegeEscalation':: d.fn(help='"AllowPrivilegeEscalation controls whether a process can gain more\\nprivileges than its parent process. This bool directly controls if\\nthe no_new_privs flag will be set on the container process.\\nAllowPrivilegeEscalation is true always when the container is:\\n1) run as Privileged\\n2) has CAP_SYS_ADMIN\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='allowPrivilegeEscalation', type=d.T.boolean)]),
              withAllowPrivilegeEscalation(allowPrivilegeEscalation): { securityContext+: { allowPrivilegeEscalation: allowPrivilegeEscalation } },
              '#withPrivileged':: d.fn(help='"Run container in privileged mode.\\nProcesses in privileged containers are essentially equivalent to root on the host.\\nDefaults to false.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='privileged', type=d.T.boolean)]),
              withPrivileged(privileged): { securityContext+: { privileged: privileged } },
              '#withProcMount':: d.fn(help='"procMount denotes the type of proc mount to use for the containers.\\nThe default value is Default which uses the container runtime defaults for\\nreadonly paths and masked paths.\\nThis requires the ProcMountType feature flag to be enabled.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='procMount', type=d.T.string)]),
              withProcMount(procMount): { securityContext+: { procMount: procMount } },
              '#withReadOnlyRootFilesystem':: d.fn(help='"Whether this container has a read-only root filesystem.\\nDefault is false.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='readOnlyRootFilesystem', type=d.T.boolean)]),
              withReadOnlyRootFilesystem(readOnlyRootFilesystem): { securityContext+: { readOnlyRootFilesystem: readOnlyRootFilesystem } },
              '#withRunAsGroup':: d.fn(help='"The GID to run the entrypoint of the container process.\\nUses runtime default if unset.\\nMay also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='runAsGroup', type=d.T.integer)]),
              withRunAsGroup(runAsGroup): { securityContext+: { runAsGroup: runAsGroup } },
              '#withRunAsNonRoot':: d.fn(help='"Indicates that the container must run as a non-root user.\\nIf true, the Kubelet will validate the image at runtime to ensure that it\\ndoes not run as UID 0 (root) and fail to start the container if it does.\\nIf unset or false, no such validation will be performed.\\nMay also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence."', args=[d.arg(name='runAsNonRoot', type=d.T.boolean)]),
              withRunAsNonRoot(runAsNonRoot): { securityContext+: { runAsNonRoot: runAsNonRoot } },
              '#withRunAsUser':: d.fn(help='"The UID to run the entrypoint of the container process.\\nDefaults to user specified in image metadata if unspecified.\\nMay also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='runAsUser', type=d.T.integer)]),
              withRunAsUser(runAsUser): { securityContext+: { runAsUser: runAsUser } },
            },
            '#startupProbe':: d.obj(help="\"StartupProbe indicates that the Pod has successfully initialized.\\nIf specified, no other probes are executed until this completes successfully.\\nIf this probe fails, the Pod will be restarted, just as if the livenessProbe failed.\\nThis can be used to provide different probe parameters at the beginning of a Pod's lifecycle,\\nwhen it might take a long time to load data or warm a cache, than during steady-state operation.\\nThis cannot be updated.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes\""),
            startupProbe: {
              '#exec':: d.obj(help='"Exec specifies a command to execute in the container."'),
              exec: {
                '#withCommand':: d.fn(help="\"Command is the command line to execute inside the container, the working directory for the\\ncommand  is root ('/') in the container's filesystem. The command is simply exec'd, it is\\nnot run inside a shell, so traditional shell instructions ('|', etc) won't work. To use\\na shell, you need to explicitly call out to that shell.\\nExit status of 0 is treated as live/healthy and non-zero is unhealthy.\"", args=[d.arg(name='command', type=d.T.array)]),
                withCommand(command): { startupProbe+: { exec+: { command: if std.isArray(v=command) then command else [command] } } },
                '#withCommandMixin':: d.fn(help="\"Command is the command line to execute inside the container, the working directory for the\\ncommand  is root ('/') in the container's filesystem. The command is simply exec'd, it is\\nnot run inside a shell, so traditional shell instructions ('|', etc) won't work. To use\\na shell, you need to explicitly call out to that shell.\\nExit status of 0 is treated as live/healthy and non-zero is unhealthy.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='command', type=d.T.array)]),
                withCommandMixin(command): { startupProbe+: { exec+: { command+: if std.isArray(v=command) then command else [command] } } },
              },
              '#grpc':: d.obj(help='"GRPC specifies a GRPC HealthCheckRequest."'),
              grpc: {
                '#withPort':: d.fn(help='"Port number of the gRPC service. Number must be in the range 1 to 65535."', args=[d.arg(name='port', type=d.T.integer)]),
                withPort(port): { startupProbe+: { grpc+: { port: port } } },
                '#withService':: d.fn(help='"Service is the name of the service to place in the gRPC HealthCheckRequest\\n(see https://github.com/grpc/grpc/blob/master/doc/health-checking.md).\\n\\nIf this is not specified, the default behavior is defined by gRPC."', args=[d.arg(name='service', type=d.T.string)]),
                withService(service): { startupProbe+: { grpc+: { service: service } } },
              },
              '#httpGet':: d.obj(help='"HTTPGet specifies an HTTP GET request to perform."'),
              httpGet: {
                '#httpHeaders':: d.obj(help='"Custom headers to set in the request. HTTP allows repeated headers."'),
                httpHeaders: {
                  '#withName':: d.fn(help='"The header field name.\\nThis will be canonicalized upon output, so case-variant names will be understood as the same header."', args=[d.arg(name='name', type=d.T.string)]),
                  withName(name): { name: name },
                  '#withValue':: d.fn(help='"The header field value"', args=[d.arg(name='value', type=d.T.string)]),
                  withValue(value): { value: value },
                },
                '#withHost':: d.fn(help='"Host name to connect to, defaults to the pod IP. You probably want to set\\n\\"Host\\" in httpHeaders instead."', args=[d.arg(name='host', type=d.T.string)]),
                withHost(host): { startupProbe+: { httpGet+: { host: host } } },
                '#withHttpHeaders':: d.fn(help='"Custom headers to set in the request. HTTP allows repeated headers."', args=[d.arg(name='httpHeaders', type=d.T.array)]),
                withHttpHeaders(httpHeaders): { startupProbe+: { httpGet+: { httpHeaders: if std.isArray(v=httpHeaders) then httpHeaders else [httpHeaders] } } },
                '#withHttpHeadersMixin':: d.fn(help='"Custom headers to set in the request. HTTP allows repeated headers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='httpHeaders', type=d.T.array)]),
                withHttpHeadersMixin(httpHeaders): { startupProbe+: { httpGet+: { httpHeaders+: if std.isArray(v=httpHeaders) then httpHeaders else [httpHeaders] } } },
                '#withPath':: d.fn(help='"Path to access on the HTTP server."', args=[d.arg(name='path', type=d.T.string)]),
                withPath(path): { startupProbe+: { httpGet+: { path: path } } },
                '#withPort':: d.fn(help='"Name or number of the port to access on the container.\\nNumber must be in the range 1 to 65535.\\nName must be an IANA_SVC_NAME."', args=[d.arg(name='port', type=d.T.any)]),
                withPort(port): { startupProbe+: { httpGet+: { port: port } } },
                '#withScheme':: d.fn(help='"Scheme to use for connecting to the host.\\nDefaults to HTTP."', args=[d.arg(name='scheme', type=d.T.string)]),
                withScheme(scheme): { startupProbe+: { httpGet+: { scheme: scheme } } },
              },
              '#tcpSocket':: d.obj(help='"TCPSocket specifies a connection to a TCP port."'),
              tcpSocket: {
                '#withHost':: d.fn(help='"Optional: Host name to connect to, defaults to the pod IP."', args=[d.arg(name='host', type=d.T.string)]),
                withHost(host): { startupProbe+: { tcpSocket+: { host: host } } },
                '#withPort':: d.fn(help='"Number or name of the port to access on the container.\\nNumber must be in the range 1 to 65535.\\nName must be an IANA_SVC_NAME."', args=[d.arg(name='port', type=d.T.any)]),
                withPort(port): { startupProbe+: { tcpSocket+: { port: port } } },
              },
              '#withFailureThreshold':: d.fn(help='"Minimum consecutive failures for the probe to be considered failed after having succeeded.\\nDefaults to 3. Minimum value is 1."', args=[d.arg(name='failureThreshold', type=d.T.integer)]),
              withFailureThreshold(failureThreshold): { startupProbe+: { failureThreshold: failureThreshold } },
              '#withInitialDelaySeconds':: d.fn(help='"Number of seconds after the container has started before liveness probes are initiated.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes"', args=[d.arg(name='initialDelaySeconds', type=d.T.integer)]),
              withInitialDelaySeconds(initialDelaySeconds): { startupProbe+: { initialDelaySeconds: initialDelaySeconds } },
              '#withPeriodSeconds':: d.fn(help='"How often (in seconds) to perform the probe.\\nDefault to 10 seconds. Minimum value is 1."', args=[d.arg(name='periodSeconds', type=d.T.integer)]),
              withPeriodSeconds(periodSeconds): { startupProbe+: { periodSeconds: periodSeconds } },
              '#withSuccessThreshold':: d.fn(help='"Minimum consecutive successes for the probe to be considered successful after having failed.\\nDefaults to 1. Must be 1 for liveness and startup. Minimum value is 1."', args=[d.arg(name='successThreshold', type=d.T.integer)]),
              withSuccessThreshold(successThreshold): { startupProbe+: { successThreshold: successThreshold } },
              '#withTerminationGracePeriodSeconds':: d.fn(help="\"Optional duration in seconds the pod needs to terminate gracefully upon probe failure.\\nThe grace period is the duration in seconds after the processes running in the pod are sent\\na termination signal and the time when the processes are forcibly halted with a kill signal.\\nSet this value longer than the expected cleanup time for your process.\\nIf this value is nil, the pod's terminationGracePeriodSeconds will be used. Otherwise, this\\nvalue overrides the value provided by the pod spec.\\nValue must be non-negative integer. The value zero indicates stop immediately via\\nthe kill signal (no opportunity to shut down).\\nThis is a beta field and requires enabling ProbeTerminationGracePeriod feature gate.\\nMinimum value is 1. spec.terminationGracePeriodSeconds is used if unset.\"", args=[d.arg(name='terminationGracePeriodSeconds', type=d.T.integer)]),
              withTerminationGracePeriodSeconds(terminationGracePeriodSeconds): { startupProbe+: { terminationGracePeriodSeconds: terminationGracePeriodSeconds } },
              '#withTimeoutSeconds':: d.fn(help='"Number of seconds after which the probe times out.\\nDefaults to 1 second. Minimum value is 1.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes"', args=[d.arg(name='timeoutSeconds', type=d.T.integer)]),
              withTimeoutSeconds(timeoutSeconds): { startupProbe+: { timeoutSeconds: timeoutSeconds } },
            },
            '#volumeDevices':: d.obj(help='"volumeDevices is the list of block devices to be used by the container."'),
            volumeDevices: {
              '#withDevicePath':: d.fn(help='"devicePath is the path inside of the container that the device will be mapped to."', args=[d.arg(name='devicePath', type=d.T.string)]),
              withDevicePath(devicePath): { devicePath: devicePath },
              '#withName':: d.fn(help='"name must match the name of a persistentVolumeClaim in the pod"', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { name: name },
            },
            '#volumeMounts':: d.obj(help="\"Pod volumes to mount into the container's filesystem.\\nCannot be updated.\""),
            volumeMounts: {
              '#withMountPath':: d.fn(help="\"Path within the container at which the volume should be mounted.  Must\\nnot contain ':'.\"", args=[d.arg(name='mountPath', type=d.T.string)]),
              withMountPath(mountPath): { mountPath: mountPath },
              '#withMountPropagation':: d.fn(help='"mountPropagation determines how mounts are propagated from the host\\nto container and the other way around.\\nWhen not set, MountPropagationNone is used.\\nThis field is beta in 1.10.\\nWhen RecursiveReadOnly is set to IfPossible or to Enabled, MountPropagation must be None or unspecified\\n(which defaults to None)."', args=[d.arg(name='mountPropagation', type=d.T.string)]),
              withMountPropagation(mountPropagation): { mountPropagation: mountPropagation },
              '#withName':: d.fn(help='"This must match the Name of a Volume."', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { name: name },
              '#withReadOnly':: d.fn(help='"Mounted read-only if true, read-write otherwise (false or unspecified).\\nDefaults to false."', args=[d.arg(name='readOnly', type=d.T.boolean)]),
              withReadOnly(readOnly): { readOnly: readOnly },
              '#withRecursiveReadOnly':: d.fn(help='"RecursiveReadOnly specifies whether read-only mounts should be handled\\nrecursively.\\n\\nIf ReadOnly is false, this field has no meaning and must be unspecified.\\n\\nIf ReadOnly is true, and this field is set to Disabled, the mount is not made\\nrecursively read-only.  If this field is set to IfPossible, the mount is made\\nrecursively read-only, if it is supported by the container runtime.  If this\\nfield is set to Enabled, the mount is made recursively read-only if it is\\nsupported by the container runtime, otherwise the pod will not be started and\\nan error will be generated to indicate the reason.\\n\\nIf this field is set to IfPossible or Enabled, MountPropagation must be set to\\nNone (or be unspecified, which defaults to None).\\n\\nIf this field is not specified, it is treated as an equivalent of Disabled."', args=[d.arg(name='recursiveReadOnly', type=d.T.string)]),
              withRecursiveReadOnly(recursiveReadOnly): { recursiveReadOnly: recursiveReadOnly },
              '#withSubPath':: d.fn(help="\"Path within the volume from which the container's volume should be mounted.\\nDefaults to \\\"\\\" (volume's root).\"", args=[d.arg(name='subPath', type=d.T.string)]),
              withSubPath(subPath): { subPath: subPath },
              '#withSubPathExpr':: d.fn(help="\"Expanded path within the volume from which the container's volume should be mounted.\\nBehaves similarly to SubPath but environment variable references $(VAR_NAME) are expanded using the container's environment.\\nDefaults to \\\"\\\" (volume's root).\\nSubPathExpr and SubPath are mutually exclusive.\"", args=[d.arg(name='subPathExpr', type=d.T.string)]),
              withSubPathExpr(subPathExpr): { subPathExpr: subPathExpr },
            },
            '#withArgs':: d.fn(help="\"Arguments to the entrypoint.\\nThe container image's CMD is used if this is not provided.\\nVariable references $(VAR_NAME) are expanded using the container's environment. If a variable\\ncannot be resolved, the reference in the input string will be unchanged. Double $$ are reduced\\nto a single $, which allows for escaping the $(VAR_NAME) syntax: i.e. \\\"$$(VAR_NAME)\\\" will\\nproduce the string literal \\\"$(VAR_NAME)\\\". Escaped references will never be expanded, regardless\\nof whether the variable exists or not. Cannot be updated.\\nMore info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell\"", args=[d.arg(name='args', type=d.T.array)]),
            withArgs(args): { args: if std.isArray(v=args) then args else [args] },
            '#withArgsMixin':: d.fn(help="\"Arguments to the entrypoint.\\nThe container image's CMD is used if this is not provided.\\nVariable references $(VAR_NAME) are expanded using the container's environment. If a variable\\ncannot be resolved, the reference in the input string will be unchanged. Double $$ are reduced\\nto a single $, which allows for escaping the $(VAR_NAME) syntax: i.e. \\\"$$(VAR_NAME)\\\" will\\nproduce the string literal \\\"$(VAR_NAME)\\\". Escaped references will never be expanded, regardless\\nof whether the variable exists or not. Cannot be updated.\\nMore info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='args', type=d.T.array)]),
            withArgsMixin(args): { args+: if std.isArray(v=args) then args else [args] },
            '#withCommand':: d.fn(help="\"Entrypoint array. Not executed within a shell.\\nThe container image's ENTRYPOINT is used if this is not provided.\\nVariable references $(VAR_NAME) are expanded using the container's environment. If a variable\\ncannot be resolved, the reference in the input string will be unchanged. Double $$ are reduced\\nto a single $, which allows for escaping the $(VAR_NAME) syntax: i.e. \\\"$$(VAR_NAME)\\\" will\\nproduce the string literal \\\"$(VAR_NAME)\\\". Escaped references will never be expanded, regardless\\nof whether the variable exists or not. Cannot be updated.\\nMore info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell\"", args=[d.arg(name='command', type=d.T.array)]),
            withCommand(command): { command: if std.isArray(v=command) then command else [command] },
            '#withCommandMixin':: d.fn(help="\"Entrypoint array. Not executed within a shell.\\nThe container image's ENTRYPOINT is used if this is not provided.\\nVariable references $(VAR_NAME) are expanded using the container's environment. If a variable\\ncannot be resolved, the reference in the input string will be unchanged. Double $$ are reduced\\nto a single $, which allows for escaping the $(VAR_NAME) syntax: i.e. \\\"$$(VAR_NAME)\\\" will\\nproduce the string literal \\\"$(VAR_NAME)\\\". Escaped references will never be expanded, regardless\\nof whether the variable exists or not. Cannot be updated.\\nMore info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='command', type=d.T.array)]),
            withCommandMixin(command): { command+: if std.isArray(v=command) then command else [command] },
            '#withEnv':: d.fn(help='"List of environment variables to set in the container.\\nCannot be updated."', args=[d.arg(name='env', type=d.T.array)]),
            withEnv(env): { env: if std.isArray(v=env) then env else [env] },
            '#withEnvFrom':: d.fn(help='"List of sources to populate environment variables in the container.\\nThe keys defined within a source must be a C_IDENTIFIER. All invalid keys\\nwill be reported as an event when the container is starting. When a key exists in multiple\\nsources, the value associated with the last source will take precedence.\\nValues defined by an Env with a duplicate key will take precedence.\\nCannot be updated."', args=[d.arg(name='envFrom', type=d.T.array)]),
            withEnvFrom(envFrom): { envFrom: if std.isArray(v=envFrom) then envFrom else [envFrom] },
            '#withEnvFromMixin':: d.fn(help='"List of sources to populate environment variables in the container.\\nThe keys defined within a source must be a C_IDENTIFIER. All invalid keys\\nwill be reported as an event when the container is starting. When a key exists in multiple\\nsources, the value associated with the last source will take precedence.\\nValues defined by an Env with a duplicate key will take precedence.\\nCannot be updated."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='envFrom', type=d.T.array)]),
            withEnvFromMixin(envFrom): { envFrom+: if std.isArray(v=envFrom) then envFrom else [envFrom] },
            '#withEnvMixin':: d.fn(help='"List of environment variables to set in the container.\\nCannot be updated."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='env', type=d.T.array)]),
            withEnvMixin(env): { env+: if std.isArray(v=env) then env else [env] },
            '#withImage':: d.fn(help='"Container image name.\\nMore info: https://kubernetes.io/docs/concepts/containers/images\\nThis field is optional to allow higher level config management to default or override\\ncontainer images in workload controllers like Deployments and StatefulSets."', args=[d.arg(name='image', type=d.T.string)]),
            withImage(image): { image: image },
            '#withImagePullPolicy':: d.fn(help='"Image pull policy.\\nOne of Always, Never, IfNotPresent.\\nDefaults to Always if :latest tag is specified, or IfNotPresent otherwise.\\nCannot be updated.\\nMore info: https://kubernetes.io/docs/concepts/containers/images#updating-images"', args=[d.arg(name='imagePullPolicy', type=d.T.string)]),
            withImagePullPolicy(imagePullPolicy): { imagePullPolicy: imagePullPolicy },
            '#withName':: d.fn(help='"Name of the container specified as a DNS_LABEL.\\nEach container in a pod must have a unique name (DNS_LABEL).\\nCannot be updated."', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { name: name },
            '#withPorts':: d.fn(help='"List of ports to expose from the container. Not specifying a port here\\nDOES NOT prevent that port from being exposed. Any port which is\\nlistening on the default \\"0.0.0.0\\" address inside a container will be\\naccessible from the network.\\nModifying this array with strategic merge patch may corrupt the data.\\nFor more information See https://github.com/kubernetes/kubernetes/issues/108255.\\nCannot be updated."', args=[d.arg(name='ports', type=d.T.array)]),
            withPorts(ports): { ports: if std.isArray(v=ports) then ports else [ports] },
            '#withPortsMixin':: d.fn(help='"List of ports to expose from the container. Not specifying a port here\\nDOES NOT prevent that port from being exposed. Any port which is\\nlistening on the default \\"0.0.0.0\\" address inside a container will be\\naccessible from the network.\\nModifying this array with strategic merge patch may corrupt the data.\\nFor more information See https://github.com/kubernetes/kubernetes/issues/108255.\\nCannot be updated."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='ports', type=d.T.array)]),
            withPortsMixin(ports): { ports+: if std.isArray(v=ports) then ports else [ports] },
            '#withResizePolicy':: d.fn(help='"Resources resize policy for the container."', args=[d.arg(name='resizePolicy', type=d.T.array)]),
            withResizePolicy(resizePolicy): { resizePolicy: if std.isArray(v=resizePolicy) then resizePolicy else [resizePolicy] },
            '#withResizePolicyMixin':: d.fn(help='"Resources resize policy for the container."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='resizePolicy', type=d.T.array)]),
            withResizePolicyMixin(resizePolicy): { resizePolicy+: if std.isArray(v=resizePolicy) then resizePolicy else [resizePolicy] },
            '#withRestartPolicy':: d.fn(help="\"RestartPolicy defines the restart behavior of individual containers in a pod.\\nThis field may only be set for init containers, and the only allowed value is \\\"Always\\\".\\nFor non-init containers or when this field is not specified,\\nthe restart behavior is defined by the Pod's restart policy and the container type.\\nSetting the RestartPolicy as \\\"Always\\\" for the init container will have the following effect:\\nthis init container will be continually restarted on\\nexit until all regular containers have terminated. Once all regular\\ncontainers have completed, all init containers with restartPolicy \\\"Always\\\"\\nwill be shut down. This lifecycle differs from normal init containers and\\nis often referred to as a \\\"sidecar\\\" container. Although this init\\ncontainer still starts in the init container sequence, it does not wait\\nfor the container to complete before proceeding to the next init\\ncontainer. Instead, the next init container starts immediately after this\\ninit container is started, or after any startupProbe has successfully\\ncompleted.\"", args=[d.arg(name='restartPolicy', type=d.T.string)]),
            withRestartPolicy(restartPolicy): { restartPolicy: restartPolicy },
            '#withStdin':: d.fn(help='"Whether this container should allocate a buffer for stdin in the container runtime. If this\\nis not set, reads from stdin in the container will always result in EOF.\\nDefault is false."', args=[d.arg(name='stdin', type=d.T.boolean)]),
            withStdin(stdin): { stdin: stdin },
            '#withStdinOnce':: d.fn(help='"Whether the container runtime should close the stdin channel after it has been opened by\\na single attach. When stdin is true the stdin stream will remain open across multiple attach\\nsessions. If stdinOnce is set to true, stdin is opened on container start, is empty until the\\nfirst client attaches to stdin, and then remains open and accepts data until the client disconnects,\\nat which time stdin is closed and remains closed until the container is restarted. If this\\nflag is false, a container processes that reads from stdin will never receive an EOF.\\nDefault is false"', args=[d.arg(name='stdinOnce', type=d.T.boolean)]),
            withStdinOnce(stdinOnce): { stdinOnce: stdinOnce },
            '#withTerminationMessagePath':: d.fn(help="\"Optional: Path at which the file to which the container's termination message\\nwill be written is mounted into the container's filesystem.\\nMessage written is intended to be brief final status, such as an assertion failure message.\\nWill be truncated by the node if greater than 4096 bytes. The total message length across\\nall containers will be limited to 12kb.\\nDefaults to /dev/termination-log.\\nCannot be updated.\"", args=[d.arg(name='terminationMessagePath', type=d.T.string)]),
            withTerminationMessagePath(terminationMessagePath): { terminationMessagePath: terminationMessagePath },
            '#withTerminationMessagePolicy':: d.fn(help='"Indicate how the termination message should be populated. File will use the contents of\\nterminationMessagePath to populate the container status message on both success and failure.\\nFallbackToLogsOnError will use the last chunk of container log output if the termination\\nmessage file is empty and the container exited with an error.\\nThe log output is limited to 2048 bytes or 80 lines, whichever is smaller.\\nDefaults to File.\\nCannot be updated."', args=[d.arg(name='terminationMessagePolicy', type=d.T.string)]),
            withTerminationMessagePolicy(terminationMessagePolicy): { terminationMessagePolicy: terminationMessagePolicy },
            '#withTty':: d.fn(help="\"Whether this container should allocate a TTY for itself, also requires 'stdin' to be true.\\nDefault is false.\"", args=[d.arg(name='tty', type=d.T.boolean)]),
            withTty(tty): { tty: tty },
            '#withVolumeDevices':: d.fn(help='"volumeDevices is the list of block devices to be used by the container."', args=[d.arg(name='volumeDevices', type=d.T.array)]),
            withVolumeDevices(volumeDevices): { volumeDevices: if std.isArray(v=volumeDevices) then volumeDevices else [volumeDevices] },
            '#withVolumeDevicesMixin':: d.fn(help='"volumeDevices is the list of block devices to be used by the container."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='volumeDevices', type=d.T.array)]),
            withVolumeDevicesMixin(volumeDevices): { volumeDevices+: if std.isArray(v=volumeDevices) then volumeDevices else [volumeDevices] },
            '#withVolumeMounts':: d.fn(help="\"Pod volumes to mount into the container's filesystem.\\nCannot be updated.\"", args=[d.arg(name='volumeMounts', type=d.T.array)]),
            withVolumeMounts(volumeMounts): { volumeMounts: if std.isArray(v=volumeMounts) then volumeMounts else [volumeMounts] },
            '#withVolumeMountsMixin':: d.fn(help="\"Pod volumes to mount into the container's filesystem.\\nCannot be updated.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='volumeMounts', type=d.T.array)]),
            withVolumeMountsMixin(volumeMounts): { volumeMounts+: if std.isArray(v=volumeMounts) then volumeMounts else [volumeMounts] },
            '#withWorkingDir':: d.fn(help="\"Container's working directory.\\nIf not specified, the container runtime's default will be used, which\\nmight be configured in the container image.\\nCannot be updated.\"", args=[d.arg(name='workingDir', type=d.T.string)]),
            withWorkingDir(workingDir): { workingDir: workingDir },
          },
          '#patch':: d.obj(help='"Patch defines how to perform the patch operation to deployment"'),
          patch: {
            '#withType':: d.fn(help='"Type is the type of merge operation to perform\\n\\nBy default, StrategicMerge is used as the patch type."', args=[d.arg(name='type', type=d.T.string)]),
            withType(type): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { patch+: { type: type } } } } } },
            '#withValue':: d.fn(help='"Object contains the raw configuration for merged object"', args=[d.arg(name='value', type=d.T.any)]),
            withValue(value): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { patch+: { value: value } } } } } },
          },
          '#pod':: d.obj(help='"Pod defines the desired specification of pod."'),
          pod: {
            '#affinity':: d.obj(help="\"If specified, the pod's scheduling constraints.\""),
            affinity: {
              '#nodeAffinity':: d.obj(help='"Describes node affinity scheduling rules for the pod."'),
              nodeAffinity: {
                '#preferredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node matches the corresponding matchExpressions; the\\nnode(s) with the highest sum are the most preferred."'),
                preferredDuringSchedulingIgnoredDuringExecution: {
                  '#preference':: d.obj(help='"A node selector term, associated with the corresponding weight."'),
                  preference: {
                    '#matchExpressions':: d.obj(help="\"A list of node selector requirements by node's labels.\""),
                    matchExpressions: {
                      '#withKey':: d.fn(help='"The label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                      withKey(key): { key: key },
                      '#withOperator':: d.fn(help="\"Represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.\"", args=[d.arg(name='operator', type=d.T.string)]),
                      withOperator(operator): { operator: operator },
                      '#withValues':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."', args=[d.arg(name='values', type=d.T.array)]),
                      withValues(values): { values: if std.isArray(v=values) then values else [values] },
                      '#withValuesMixin':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                      withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                    },
                    '#matchFields':: d.obj(help="\"A list of node selector requirements by node's fields.\""),
                    matchFields: {
                      '#withKey':: d.fn(help='"The label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                      withKey(key): { key: key },
                      '#withOperator':: d.fn(help="\"Represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.\"", args=[d.arg(name='operator', type=d.T.string)]),
                      withOperator(operator): { operator: operator },
                      '#withValues':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."', args=[d.arg(name='values', type=d.T.array)]),
                      withValues(values): { values: if std.isArray(v=values) then values else [values] },
                      '#withValuesMixin':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                      withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                    },
                    '#withMatchExpressions':: d.fn(help="\"A list of node selector requirements by node's labels.\"", args=[d.arg(name='matchExpressions', type=d.T.array)]),
                    withMatchExpressions(matchExpressions): { preference+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                    '#withMatchExpressionsMixin':: d.fn(help="\"A list of node selector requirements by node's labels.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchExpressions', type=d.T.array)]),
                    withMatchExpressionsMixin(matchExpressions): { preference+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                    '#withMatchFields':: d.fn(help="\"A list of node selector requirements by node's fields.\"", args=[d.arg(name='matchFields', type=d.T.array)]),
                    withMatchFields(matchFields): { preference+: { matchFields: if std.isArray(v=matchFields) then matchFields else [matchFields] } },
                    '#withMatchFieldsMixin':: d.fn(help="\"A list of node selector requirements by node's fields.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchFields', type=d.T.array)]),
                    withMatchFieldsMixin(matchFields): { preference+: { matchFields+: if std.isArray(v=matchFields) then matchFields else [matchFields] } },
                  },
                  '#withWeight':: d.fn(help='"Weight associated with matching the corresponding nodeSelectorTerm, in the range 1-100."', args=[d.arg(name='weight', type=d.T.integer)]),
                  withWeight(weight): { weight: weight },
                },
                '#requiredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"If the affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to an update), the system\\nmay or may not try to eventually evict the pod from its node."'),
                requiredDuringSchedulingIgnoredDuringExecution: {
                  '#nodeSelectorTerms':: d.obj(help='"Required. A list of node selector terms. The terms are ORed."'),
                  nodeSelectorTerms: {
                    '#matchExpressions':: d.obj(help="\"A list of node selector requirements by node's labels.\""),
                    matchExpressions: {
                      '#withKey':: d.fn(help='"The label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                      withKey(key): { key: key },
                      '#withOperator':: d.fn(help="\"Represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.\"", args=[d.arg(name='operator', type=d.T.string)]),
                      withOperator(operator): { operator: operator },
                      '#withValues':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."', args=[d.arg(name='values', type=d.T.array)]),
                      withValues(values): { values: if std.isArray(v=values) then values else [values] },
                      '#withValuesMixin':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                      withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                    },
                    '#matchFields':: d.obj(help="\"A list of node selector requirements by node's fields.\""),
                    matchFields: {
                      '#withKey':: d.fn(help='"The label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                      withKey(key): { key: key },
                      '#withOperator':: d.fn(help="\"Represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.\"", args=[d.arg(name='operator', type=d.T.string)]),
                      withOperator(operator): { operator: operator },
                      '#withValues':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."', args=[d.arg(name='values', type=d.T.array)]),
                      withValues(values): { values: if std.isArray(v=values) then values else [values] },
                      '#withValuesMixin':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                      withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                    },
                    '#withMatchExpressions':: d.fn(help="\"A list of node selector requirements by node's labels.\"", args=[d.arg(name='matchExpressions', type=d.T.array)]),
                    withMatchExpressions(matchExpressions): { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] },
                    '#withMatchExpressionsMixin':: d.fn(help="\"A list of node selector requirements by node's labels.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchExpressions', type=d.T.array)]),
                    withMatchExpressionsMixin(matchExpressions): { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] },
                    '#withMatchFields':: d.fn(help="\"A list of node selector requirements by node's fields.\"", args=[d.arg(name='matchFields', type=d.T.array)]),
                    withMatchFields(matchFields): { matchFields: if std.isArray(v=matchFields) then matchFields else [matchFields] },
                    '#withMatchFieldsMixin':: d.fn(help="\"A list of node selector requirements by node's fields.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchFields', type=d.T.array)]),
                    withMatchFieldsMixin(matchFields): { matchFields+: if std.isArray(v=matchFields) then matchFields else [matchFields] },
                  },
                  '#withNodeSelectorTerms':: d.fn(help='"Required. A list of node selector terms. The terms are ORed."', args=[d.arg(name='nodeSelectorTerms', type=d.T.array)]),
                  withNodeSelectorTerms(nodeSelectorTerms): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { pod+: { affinity+: { nodeAffinity+: { requiredDuringSchedulingIgnoredDuringExecution+: { nodeSelectorTerms: if std.isArray(v=nodeSelectorTerms) then nodeSelectorTerms else [nodeSelectorTerms] } } } } } } } } },
                  '#withNodeSelectorTermsMixin':: d.fn(help='"Required. A list of node selector terms. The terms are ORed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='nodeSelectorTerms', type=d.T.array)]),
                  withNodeSelectorTermsMixin(nodeSelectorTerms): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { pod+: { affinity+: { nodeAffinity+: { requiredDuringSchedulingIgnoredDuringExecution+: { nodeSelectorTerms+: if std.isArray(v=nodeSelectorTerms) then nodeSelectorTerms else [nodeSelectorTerms] } } } } } } } } },
                },
                '#withPreferredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node matches the corresponding matchExpressions; the\\nnode(s) with the highest sum are the most preferred."', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
                withPreferredDuringSchedulingIgnoredDuringExecution(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { pod+: { affinity+: { nodeAffinity+: { preferredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } } } },
                '#withPreferredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node matches the corresponding matchExpressions; the\\nnode(s) with the highest sum are the most preferred."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
                withPreferredDuringSchedulingIgnoredDuringExecutionMixin(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { pod+: { affinity+: { nodeAffinity+: { preferredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } } } },
              },
              '#podAffinity':: d.obj(help='"Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s))."'),
              podAffinity: {
                '#preferredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."'),
                preferredDuringSchedulingIgnoredDuringExecution: {
                  '#podAffinityTerm':: d.obj(help='"Required. A pod affinity term, associated with the corresponding weight."'),
                  podAffinityTerm: {
                    '#labelSelector':: d.obj(help="\"A label query over a set of resources, in this case pods.\\nIf it's null, this PodAffinityTerm matches with no Pods.\""),
                    labelSelector: {
                      '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                      matchExpressions: {
                        '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                        withKey(key): { key: key },
                        '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                        withOperator(operator): { operator: operator },
                        '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                        withValues(values): { values: if std.isArray(v=values) then values else [values] },
                        '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                        withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                      },
                      '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                      withMatchExpressions(matchExpressions): { podAffinityTerm+: { labelSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                      '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                      withMatchExpressionsMixin(matchExpressions): { podAffinityTerm+: { labelSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                      '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                      withMatchLabels(matchLabels): { podAffinityTerm+: { labelSelector+: { matchLabels: matchLabels } } },
                      '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                      withMatchLabelsMixin(matchLabels): { podAffinityTerm+: { labelSelector+: { matchLabels+: matchLabels } } },
                    },
                    '#namespaceSelector':: d.obj(help="\"A label query over the set of namespaces that the term applies to.\\nThe term is applied to the union of the namespaces selected by this field\\nand the ones listed in the namespaces field.\\nnull selector and null or empty namespaces list means \\\"this pod's namespace\\\".\\nAn empty selector ({}) matches all namespaces.\""),
                    namespaceSelector: {
                      '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                      matchExpressions: {
                        '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                        withKey(key): { key: key },
                        '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                        withOperator(operator): { operator: operator },
                        '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                        withValues(values): { values: if std.isArray(v=values) then values else [values] },
                        '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                        withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                      },
                      '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                      withMatchExpressions(matchExpressions): { podAffinityTerm+: { namespaceSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                      '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                      withMatchExpressionsMixin(matchExpressions): { podAffinityTerm+: { namespaceSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                      '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                      withMatchLabels(matchLabels): { podAffinityTerm+: { namespaceSelector+: { matchLabels: matchLabels } } },
                      '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                      withMatchLabelsMixin(matchLabels): { podAffinityTerm+: { namespaceSelector+: { matchLabels+: matchLabels } } },
                    },
                    '#withMatchLabelKeys':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                    withMatchLabelKeys(matchLabelKeys): { podAffinityTerm+: { matchLabelKeys: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] } },
                    '#withMatchLabelKeysMixin':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                    withMatchLabelKeysMixin(matchLabelKeys): { podAffinityTerm+: { matchLabelKeys+: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] } },
                    '#withMismatchLabelKeys':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                    withMismatchLabelKeys(mismatchLabelKeys): { podAffinityTerm+: { mismatchLabelKeys: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] } },
                    '#withMismatchLabelKeysMixin':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                    withMismatchLabelKeysMixin(mismatchLabelKeys): { podAffinityTerm+: { mismatchLabelKeys+: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] } },
                    '#withNamespaces':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"", args=[d.arg(name='namespaces', type=d.T.array)]),
                    withNamespaces(namespaces): { podAffinityTerm+: { namespaces: if std.isArray(v=namespaces) then namespaces else [namespaces] } },
                    '#withNamespacesMixin':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='namespaces', type=d.T.array)]),
                    withNamespacesMixin(namespaces): { podAffinityTerm+: { namespaces+: if std.isArray(v=namespaces) then namespaces else [namespaces] } },
                    '#withTopologyKey':: d.fn(help='"This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching\\nthe labelSelector in the specified namespaces, where co-located is defined as running on a node\\nwhose value of the label with key topologyKey matches that of any node on which any of the\\nselected pods is running.\\nEmpty topologyKey is not allowed."', args=[d.arg(name='topologyKey', type=d.T.string)]),
                    withTopologyKey(topologyKey): { podAffinityTerm+: { topologyKey: topologyKey } },
                  },
                  '#withWeight':: d.fn(help='"weight associated with matching the corresponding podAffinityTerm,\\nin the range 1-100."', args=[d.arg(name='weight', type=d.T.integer)]),
                  withWeight(weight): { weight: weight },
                },
                '#requiredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"If the affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."'),
                requiredDuringSchedulingIgnoredDuringExecution: {
                  '#labelSelector':: d.obj(help="\"A label query over a set of resources, in this case pods.\\nIf it's null, this PodAffinityTerm matches with no Pods.\""),
                  labelSelector: {
                    '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                    matchExpressions: {
                      '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                      withKey(key): { key: key },
                      '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                      withOperator(operator): { operator: operator },
                      '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                      withValues(values): { values: if std.isArray(v=values) then values else [values] },
                      '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                      withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                    },
                    '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                    withMatchExpressions(matchExpressions): { labelSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                    '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                    withMatchExpressionsMixin(matchExpressions): { labelSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                    '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                    withMatchLabels(matchLabels): { labelSelector+: { matchLabels: matchLabels } },
                    '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                    withMatchLabelsMixin(matchLabels): { labelSelector+: { matchLabels+: matchLabels } },
                  },
                  '#namespaceSelector':: d.obj(help="\"A label query over the set of namespaces that the term applies to.\\nThe term is applied to the union of the namespaces selected by this field\\nand the ones listed in the namespaces field.\\nnull selector and null or empty namespaces list means \\\"this pod's namespace\\\".\\nAn empty selector ({}) matches all namespaces.\""),
                  namespaceSelector: {
                    '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                    matchExpressions: {
                      '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                      withKey(key): { key: key },
                      '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                      withOperator(operator): { operator: operator },
                      '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                      withValues(values): { values: if std.isArray(v=values) then values else [values] },
                      '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                      withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                    },
                    '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                    withMatchExpressions(matchExpressions): { namespaceSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                    '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                    withMatchExpressionsMixin(matchExpressions): { namespaceSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                    '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                    withMatchLabels(matchLabels): { namespaceSelector+: { matchLabels: matchLabels } },
                    '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                    withMatchLabelsMixin(matchLabels): { namespaceSelector+: { matchLabels+: matchLabels } },
                  },
                  '#withMatchLabelKeys':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                  withMatchLabelKeys(matchLabelKeys): { matchLabelKeys: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] },
                  '#withMatchLabelKeysMixin':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                  withMatchLabelKeysMixin(matchLabelKeys): { matchLabelKeys+: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] },
                  '#withMismatchLabelKeys':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                  withMismatchLabelKeys(mismatchLabelKeys): { mismatchLabelKeys: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] },
                  '#withMismatchLabelKeysMixin':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                  withMismatchLabelKeysMixin(mismatchLabelKeys): { mismatchLabelKeys+: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] },
                  '#withNamespaces':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"", args=[d.arg(name='namespaces', type=d.T.array)]),
                  withNamespaces(namespaces): { namespaces: if std.isArray(v=namespaces) then namespaces else [namespaces] },
                  '#withNamespacesMixin':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='namespaces', type=d.T.array)]),
                  withNamespacesMixin(namespaces): { namespaces+: if std.isArray(v=namespaces) then namespaces else [namespaces] },
                  '#withTopologyKey':: d.fn(help='"This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching\\nthe labelSelector in the specified namespaces, where co-located is defined as running on a node\\nwhose value of the label with key topologyKey matches that of any node on which any of the\\nselected pods is running.\\nEmpty topologyKey is not allowed."', args=[d.arg(name='topologyKey', type=d.T.string)]),
                  withTopologyKey(topologyKey): { topologyKey: topologyKey },
                },
                '#withPreferredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
                withPreferredDuringSchedulingIgnoredDuringExecution(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { pod+: { affinity+: { podAffinity+: { preferredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } } } },
                '#withPreferredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
                withPreferredDuringSchedulingIgnoredDuringExecutionMixin(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { pod+: { affinity+: { podAffinity+: { preferredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } } } },
                '#withRequiredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"If the affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."', args=[d.arg(name='requiredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
                withRequiredDuringSchedulingIgnoredDuringExecution(requiredDuringSchedulingIgnoredDuringExecution): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { pod+: { affinity+: { podAffinity+: { requiredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=requiredDuringSchedulingIgnoredDuringExecution) then requiredDuringSchedulingIgnoredDuringExecution else [requiredDuringSchedulingIgnoredDuringExecution] } } } } } } } },
                '#withRequiredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"If the affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requiredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
                withRequiredDuringSchedulingIgnoredDuringExecutionMixin(requiredDuringSchedulingIgnoredDuringExecution): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { pod+: { affinity+: { podAffinity+: { requiredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=requiredDuringSchedulingIgnoredDuringExecution) then requiredDuringSchedulingIgnoredDuringExecution else [requiredDuringSchedulingIgnoredDuringExecution] } } } } } } } },
              },
              '#podAntiAffinity':: d.obj(help='"Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s))."'),
              podAntiAffinity: {
                '#preferredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe anti-affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling anti-affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."'),
                preferredDuringSchedulingIgnoredDuringExecution: {
                  '#podAffinityTerm':: d.obj(help='"Required. A pod affinity term, associated with the corresponding weight."'),
                  podAffinityTerm: {
                    '#labelSelector':: d.obj(help="\"A label query over a set of resources, in this case pods.\\nIf it's null, this PodAffinityTerm matches with no Pods.\""),
                    labelSelector: {
                      '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                      matchExpressions: {
                        '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                        withKey(key): { key: key },
                        '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                        withOperator(operator): { operator: operator },
                        '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                        withValues(values): { values: if std.isArray(v=values) then values else [values] },
                        '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                        withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                      },
                      '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                      withMatchExpressions(matchExpressions): { podAffinityTerm+: { labelSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                      '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                      withMatchExpressionsMixin(matchExpressions): { podAffinityTerm+: { labelSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                      '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                      withMatchLabels(matchLabels): { podAffinityTerm+: { labelSelector+: { matchLabels: matchLabels } } },
                      '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                      withMatchLabelsMixin(matchLabels): { podAffinityTerm+: { labelSelector+: { matchLabels+: matchLabels } } },
                    },
                    '#namespaceSelector':: d.obj(help="\"A label query over the set of namespaces that the term applies to.\\nThe term is applied to the union of the namespaces selected by this field\\nand the ones listed in the namespaces field.\\nnull selector and null or empty namespaces list means \\\"this pod's namespace\\\".\\nAn empty selector ({}) matches all namespaces.\""),
                    namespaceSelector: {
                      '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                      matchExpressions: {
                        '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                        withKey(key): { key: key },
                        '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                        withOperator(operator): { operator: operator },
                        '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                        withValues(values): { values: if std.isArray(v=values) then values else [values] },
                        '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                        withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                      },
                      '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                      withMatchExpressions(matchExpressions): { podAffinityTerm+: { namespaceSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                      '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                      withMatchExpressionsMixin(matchExpressions): { podAffinityTerm+: { namespaceSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                      '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                      withMatchLabels(matchLabels): { podAffinityTerm+: { namespaceSelector+: { matchLabels: matchLabels } } },
                      '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                      withMatchLabelsMixin(matchLabels): { podAffinityTerm+: { namespaceSelector+: { matchLabels+: matchLabels } } },
                    },
                    '#withMatchLabelKeys':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                    withMatchLabelKeys(matchLabelKeys): { podAffinityTerm+: { matchLabelKeys: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] } },
                    '#withMatchLabelKeysMixin':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                    withMatchLabelKeysMixin(matchLabelKeys): { podAffinityTerm+: { matchLabelKeys+: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] } },
                    '#withMismatchLabelKeys':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                    withMismatchLabelKeys(mismatchLabelKeys): { podAffinityTerm+: { mismatchLabelKeys: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] } },
                    '#withMismatchLabelKeysMixin':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                    withMismatchLabelKeysMixin(mismatchLabelKeys): { podAffinityTerm+: { mismatchLabelKeys+: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] } },
                    '#withNamespaces':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"", args=[d.arg(name='namespaces', type=d.T.array)]),
                    withNamespaces(namespaces): { podAffinityTerm+: { namespaces: if std.isArray(v=namespaces) then namespaces else [namespaces] } },
                    '#withNamespacesMixin':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='namespaces', type=d.T.array)]),
                    withNamespacesMixin(namespaces): { podAffinityTerm+: { namespaces+: if std.isArray(v=namespaces) then namespaces else [namespaces] } },
                    '#withTopologyKey':: d.fn(help='"This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching\\nthe labelSelector in the specified namespaces, where co-located is defined as running on a node\\nwhose value of the label with key topologyKey matches that of any node on which any of the\\nselected pods is running.\\nEmpty topologyKey is not allowed."', args=[d.arg(name='topologyKey', type=d.T.string)]),
                    withTopologyKey(topologyKey): { podAffinityTerm+: { topologyKey: topologyKey } },
                  },
                  '#withWeight':: d.fn(help='"weight associated with matching the corresponding podAffinityTerm,\\nin the range 1-100."', args=[d.arg(name='weight', type=d.T.integer)]),
                  withWeight(weight): { weight: weight },
                },
                '#requiredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"If the anti-affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the anti-affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."'),
                requiredDuringSchedulingIgnoredDuringExecution: {
                  '#labelSelector':: d.obj(help="\"A label query over a set of resources, in this case pods.\\nIf it's null, this PodAffinityTerm matches with no Pods.\""),
                  labelSelector: {
                    '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                    matchExpressions: {
                      '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                      withKey(key): { key: key },
                      '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                      withOperator(operator): { operator: operator },
                      '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                      withValues(values): { values: if std.isArray(v=values) then values else [values] },
                      '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                      withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                    },
                    '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                    withMatchExpressions(matchExpressions): { labelSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                    '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                    withMatchExpressionsMixin(matchExpressions): { labelSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                    '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                    withMatchLabels(matchLabels): { labelSelector+: { matchLabels: matchLabels } },
                    '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                    withMatchLabelsMixin(matchLabels): { labelSelector+: { matchLabels+: matchLabels } },
                  },
                  '#namespaceSelector':: d.obj(help="\"A label query over the set of namespaces that the term applies to.\\nThe term is applied to the union of the namespaces selected by this field\\nand the ones listed in the namespaces field.\\nnull selector and null or empty namespaces list means \\\"this pod's namespace\\\".\\nAn empty selector ({}) matches all namespaces.\""),
                  namespaceSelector: {
                    '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                    matchExpressions: {
                      '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                      withKey(key): { key: key },
                      '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                      withOperator(operator): { operator: operator },
                      '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                      withValues(values): { values: if std.isArray(v=values) then values else [values] },
                      '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                      withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                    },
                    '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                    withMatchExpressions(matchExpressions): { namespaceSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                    '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                    withMatchExpressionsMixin(matchExpressions): { namespaceSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                    '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                    withMatchLabels(matchLabels): { namespaceSelector+: { matchLabels: matchLabels } },
                    '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                    withMatchLabelsMixin(matchLabels): { namespaceSelector+: { matchLabels+: matchLabels } },
                  },
                  '#withMatchLabelKeys':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                  withMatchLabelKeys(matchLabelKeys): { matchLabelKeys: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] },
                  '#withMatchLabelKeysMixin':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                  withMatchLabelKeysMixin(matchLabelKeys): { matchLabelKeys+: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] },
                  '#withMismatchLabelKeys':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                  withMismatchLabelKeys(mismatchLabelKeys): { mismatchLabelKeys: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] },
                  '#withMismatchLabelKeysMixin':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                  withMismatchLabelKeysMixin(mismatchLabelKeys): { mismatchLabelKeys+: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] },
                  '#withNamespaces':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"", args=[d.arg(name='namespaces', type=d.T.array)]),
                  withNamespaces(namespaces): { namespaces: if std.isArray(v=namespaces) then namespaces else [namespaces] },
                  '#withNamespacesMixin':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='namespaces', type=d.T.array)]),
                  withNamespacesMixin(namespaces): { namespaces+: if std.isArray(v=namespaces) then namespaces else [namespaces] },
                  '#withTopologyKey':: d.fn(help='"This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching\\nthe labelSelector in the specified namespaces, where co-located is defined as running on a node\\nwhose value of the label with key topologyKey matches that of any node on which any of the\\nselected pods is running.\\nEmpty topologyKey is not allowed."', args=[d.arg(name='topologyKey', type=d.T.string)]),
                  withTopologyKey(topologyKey): { topologyKey: topologyKey },
                },
                '#withPreferredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe anti-affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling anti-affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
                withPreferredDuringSchedulingIgnoredDuringExecution(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { pod+: { affinity+: { podAntiAffinity+: { preferredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } } } },
                '#withPreferredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe anti-affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling anti-affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
                withPreferredDuringSchedulingIgnoredDuringExecutionMixin(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { pod+: { affinity+: { podAntiAffinity+: { preferredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } } } },
                '#withRequiredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"If the anti-affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the anti-affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."', args=[d.arg(name='requiredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
                withRequiredDuringSchedulingIgnoredDuringExecution(requiredDuringSchedulingIgnoredDuringExecution): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { pod+: { affinity+: { podAntiAffinity+: { requiredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=requiredDuringSchedulingIgnoredDuringExecution) then requiredDuringSchedulingIgnoredDuringExecution else [requiredDuringSchedulingIgnoredDuringExecution] } } } } } } } },
                '#withRequiredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"If the anti-affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the anti-affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requiredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
                withRequiredDuringSchedulingIgnoredDuringExecutionMixin(requiredDuringSchedulingIgnoredDuringExecution): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { pod+: { affinity+: { podAntiAffinity+: { requiredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=requiredDuringSchedulingIgnoredDuringExecution) then requiredDuringSchedulingIgnoredDuringExecution else [requiredDuringSchedulingIgnoredDuringExecution] } } } } } } } },
              },
            },
            '#imagePullSecrets':: d.obj(help='"ImagePullSecrets is an optional list of references to secrets\\nin the same namespace to use for pulling any of the images used by this PodSpec.\\nIf specified, these secrets will be passed to individual puller implementations for them to use.\\nMore info: https://kubernetes.io/docs/concepts/containers/images#specifying-imagepullsecrets-on-a-pod"'),
            imagePullSecrets: {
              '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { name: name },
            },
            '#securityContext':: d.obj(help='"SecurityContext holds pod-level security attributes and common container settings.\\nOptional: Defaults to empty.  See type description for default values of each field."'),
            securityContext: {
              '#appArmorProfile':: d.obj(help='"appArmorProfile is the AppArmor options to use by the containers in this pod.\\nNote that this field cannot be set when spec.os.name is windows."'),
              appArmorProfile: {
                '#withLocalhostProfile':: d.fn(help='"localhostProfile indicates a profile loaded on the node that should be used.\\nThe profile must be preconfigured on the node to work.\\nMust match the loaded name of the profile.\\nMust be set if and only if type is \\"Localhost\\"."', args=[d.arg(name='localhostProfile', type=d.T.string)]),
                withLocalhostProfile(localhostProfile): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { pod+: { securityContext+: { appArmorProfile+: { localhostProfile: localhostProfile } } } } } } } },
                '#withType':: d.fn(help="\"type indicates which kind of AppArmor profile will be applied.\\nValid options are:\\n  Localhost - a profile pre-loaded on the node.\\n  RuntimeDefault - the container runtime's default profile.\\n  Unconfined - no AppArmor enforcement.\"", args=[d.arg(name='type', type=d.T.string)]),
                withType(type): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { pod+: { securityContext+: { appArmorProfile+: { type: type } } } } } } } },
              },
              '#seLinuxOptions':: d.obj(help='"The SELinux context to be applied to all containers.\\nIf unspecified, the container runtime will allocate a random SELinux context for each\\ncontainer.  May also be set in SecurityContext.  If set in\\nboth SecurityContext and PodSecurityContext, the value specified in SecurityContext\\ntakes precedence for that container.\\nNote that this field cannot be set when spec.os.name is windows."'),
              seLinuxOptions: {
                '#withLevel':: d.fn(help='"Level is SELinux level label that applies to the container."', args=[d.arg(name='level', type=d.T.string)]),
                withLevel(level): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { pod+: { securityContext+: { seLinuxOptions+: { level: level } } } } } } } },
                '#withRole':: d.fn(help='"Role is a SELinux role label that applies to the container."', args=[d.arg(name='role', type=d.T.string)]),
                withRole(role): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { pod+: { securityContext+: { seLinuxOptions+: { role: role } } } } } } } },
                '#withType':: d.fn(help='"Type is a SELinux type label that applies to the container."', args=[d.arg(name='type', type=d.T.string)]),
                withType(type): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { pod+: { securityContext+: { seLinuxOptions+: { type: type } } } } } } } },
                '#withUser':: d.fn(help='"User is a SELinux user label that applies to the container."', args=[d.arg(name='user', type=d.T.string)]),
                withUser(user): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { pod+: { securityContext+: { seLinuxOptions+: { user: user } } } } } } } },
              },
              '#seccompProfile':: d.obj(help='"The seccomp options to use by the containers in this pod.\\nNote that this field cannot be set when spec.os.name is windows."'),
              seccompProfile: {
                '#withLocalhostProfile':: d.fn(help="\"localhostProfile indicates a profile defined in a file on the node should be used.\\nThe profile must be preconfigured on the node to work.\\nMust be a descending path, relative to the kubelet's configured seccomp profile location.\\nMust be set if type is \\\"Localhost\\\". Must NOT be set for any other type.\"", args=[d.arg(name='localhostProfile', type=d.T.string)]),
                withLocalhostProfile(localhostProfile): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { pod+: { securityContext+: { seccompProfile+: { localhostProfile: localhostProfile } } } } } } } },
                '#withType':: d.fn(help='"type indicates which kind of seccomp profile will be applied.\\nValid options are:\\n\\nLocalhost - a profile defined in a file on the node should be used.\\nRuntimeDefault - the container runtime default profile should be used.\\nUnconfined - no profile should be applied."', args=[d.arg(name='type', type=d.T.string)]),
                withType(type): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { pod+: { securityContext+: { seccompProfile+: { type: type } } } } } } } },
              },
              '#sysctls':: d.obj(help='"Sysctls hold a list of namespaced sysctls used for the pod. Pods with unsupported\\nsysctls (by the container runtime) might fail to launch.\\nNote that this field cannot be set when spec.os.name is windows."'),
              sysctls: {
                '#withName':: d.fn(help='"Name of a property to set"', args=[d.arg(name='name', type=d.T.string)]),
                withName(name): { name: name },
                '#withValue':: d.fn(help='"Value of a property to set"', args=[d.arg(name='value', type=d.T.string)]),
                withValue(value): { value: value },
              },
              '#windowsOptions':: d.obj(help="\"The Windows specific settings applied to all containers.\\nIf unspecified, the options within a container's SecurityContext will be used.\\nIf set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is linux.\""),
              windowsOptions: {
                '#withGmsaCredentialSpec':: d.fn(help='"GMSACredentialSpec is where the GMSA admission webhook\\n(https://github.com/kubernetes-sigs/windows-gmsa) inlines the contents of the\\nGMSA credential spec named by the GMSACredentialSpecName field."', args=[d.arg(name='gmsaCredentialSpec', type=d.T.string)]),
                withGmsaCredentialSpec(gmsaCredentialSpec): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { pod+: { securityContext+: { windowsOptions+: { gmsaCredentialSpec: gmsaCredentialSpec } } } } } } } },
                '#withGmsaCredentialSpecName':: d.fn(help='"GMSACredentialSpecName is the name of the GMSA credential spec to use."', args=[d.arg(name='gmsaCredentialSpecName', type=d.T.string)]),
                withGmsaCredentialSpecName(gmsaCredentialSpecName): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { pod+: { securityContext+: { windowsOptions+: { gmsaCredentialSpecName: gmsaCredentialSpecName } } } } } } } },
                '#withHostProcess':: d.fn(help="\"HostProcess determines if a container should be run as a 'Host Process' container.\\nAll of a Pod's containers must have the same effective HostProcess value\\n(it is not allowed to have a mix of HostProcess containers and non-HostProcess containers).\\nIn addition, if HostProcess is true then HostNetwork must also be set to true.\"", args=[d.arg(name='hostProcess', type=d.T.boolean)]),
                withHostProcess(hostProcess): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { pod+: { securityContext+: { windowsOptions+: { hostProcess: hostProcess } } } } } } } },
                '#withRunAsUserName':: d.fn(help='"The UserName in Windows to run the entrypoint of the container process.\\nDefaults to the user specified in image metadata if unspecified.\\nMay also be set in PodSecurityContext. If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence."', args=[d.arg(name='runAsUserName', type=d.T.string)]),
                withRunAsUserName(runAsUserName): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { pod+: { securityContext+: { windowsOptions+: { runAsUserName: runAsUserName } } } } } } } },
              },
              '#withFsGroup':: d.fn(help="\"A special supplemental group that applies to all containers in a pod.\\nSome volume types allow the Kubelet to change the ownership of that volume\\nto be owned by the pod:\\n\\n1. The owning GID will be the FSGroup\\n2. The setgid bit is set (new files created in the volume will be owned by FSGroup)\\n3. The permission bits are OR'd with rw-rw----\\n\\nIf unset, the Kubelet will not modify the ownership and permissions of any volume.\\nNote that this field cannot be set when spec.os.name is windows.\"", args=[d.arg(name='fsGroup', type=d.T.integer)]),
              withFsGroup(fsGroup): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { pod+: { securityContext+: { fsGroup: fsGroup } } } } } } },
              '#withFsGroupChangePolicy':: d.fn(help='"fsGroupChangePolicy defines behavior of changing ownership and permission of the volume\\nbefore being exposed inside Pod. This field will only apply to\\nvolume types which support fsGroup based ownership(and permissions).\\nIt will have no effect on ephemeral volume types such as: secret, configmaps\\nand emptydir.\\nValid values are \\"OnRootMismatch\\" and \\"Always\\". If not specified, \\"Always\\" is used.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='fsGroupChangePolicy', type=d.T.string)]),
              withFsGroupChangePolicy(fsGroupChangePolicy): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { pod+: { securityContext+: { fsGroupChangePolicy: fsGroupChangePolicy } } } } } } },
              '#withRunAsGroup':: d.fn(help='"The GID to run the entrypoint of the container process.\\nUses runtime default if unset.\\nMay also be set in SecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence\\nfor that container.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='runAsGroup', type=d.T.integer)]),
              withRunAsGroup(runAsGroup): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { pod+: { securityContext+: { runAsGroup: runAsGroup } } } } } } },
              '#withRunAsNonRoot':: d.fn(help='"Indicates that the container must run as a non-root user.\\nIf true, the Kubelet will validate the image at runtime to ensure that it\\ndoes not run as UID 0 (root) and fail to start the container if it does.\\nIf unset or false, no such validation will be performed.\\nMay also be set in SecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence."', args=[d.arg(name='runAsNonRoot', type=d.T.boolean)]),
              withRunAsNonRoot(runAsNonRoot): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { pod+: { securityContext+: { runAsNonRoot: runAsNonRoot } } } } } } },
              '#withRunAsUser':: d.fn(help='"The UID to run the entrypoint of the container process.\\nDefaults to user specified in image metadata if unspecified.\\nMay also be set in SecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence\\nfor that container.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='runAsUser', type=d.T.integer)]),
              withRunAsUser(runAsUser): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { pod+: { securityContext+: { runAsUser: runAsUser } } } } } } },
              '#withSeLinuxChangePolicy':: d.fn(help="\"seLinuxChangePolicy defines how the container's SELinux label is applied to all volumes used by the Pod.\\nIt has no effect on nodes that do not support SELinux or to volumes does not support SELinux.\\nValid values are \\\"MountOption\\\" and \\\"Recursive\\\".\\n\\n\\\"Recursive\\\" means relabeling of all files on all Pod volumes by the container runtime.\\nThis may be slow for large volumes, but allows mixing privileged and unprivileged Pods sharing the same volume on the same node.\\n\\n\\\"MountOption\\\" mounts all eligible Pod volumes with `-o context` mount option.\\nThis requires all Pods that share the same volume to use the same SELinux label.\\nIt is not possible to share the same volume among privileged and unprivileged Pods.\\nEligible volumes are in-tree FibreChannel and iSCSI volumes, and all CSI volumes\\nwhose CSI driver announces SELinux support by setting spec.seLinuxMount: true in their\\nCSIDriver instance. Other volumes are always re-labelled recursively.\\n\\\"MountOption\\\" value is allowed only when SELinuxMount feature gate is enabled.\\n\\nIf not specified and SELinuxMount feature gate is enabled, \\\"MountOption\\\" is used.\\nIf not specified and SELinuxMount feature gate is disabled, \\\"MountOption\\\" is used for ReadWriteOncePod volumes\\nand \\\"Recursive\\\" for all other volumes.\\n\\nThis field affects only Pods that have SELinux label set, either in PodSecurityContext or in SecurityContext of all containers.\\n\\nAll Pods that use the same volume should use the same seLinuxChangePolicy, otherwise some pods can get stuck in ContainerCreating state.\\nNote that this field cannot be set when spec.os.name is windows.\"", args=[d.arg(name='seLinuxChangePolicy', type=d.T.string)]),
              withSeLinuxChangePolicy(seLinuxChangePolicy): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { pod+: { securityContext+: { seLinuxChangePolicy: seLinuxChangePolicy } } } } } } },
              '#withSupplementalGroups':: d.fn(help="\"A list of groups applied to the first process run in each container, in\\naddition to the container's primary GID and fsGroup (if specified).  If\\nthe SupplementalGroupsPolicy feature is enabled, the\\nsupplementalGroupsPolicy field determines whether these are in addition\\nto or instead of any group memberships defined in the container image.\\nIf unspecified, no additional groups are added, though group memberships\\ndefined in the container image may still be used, depending on the\\nsupplementalGroupsPolicy field.\\nNote that this field cannot be set when spec.os.name is windows.\"", args=[d.arg(name='supplementalGroups', type=d.T.array)]),
              withSupplementalGroups(supplementalGroups): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { pod+: { securityContext+: { supplementalGroups: if std.isArray(v=supplementalGroups) then supplementalGroups else [supplementalGroups] } } } } } } },
              '#withSupplementalGroupsMixin':: d.fn(help="\"A list of groups applied to the first process run in each container, in\\naddition to the container's primary GID and fsGroup (if specified).  If\\nthe SupplementalGroupsPolicy feature is enabled, the\\nsupplementalGroupsPolicy field determines whether these are in addition\\nto or instead of any group memberships defined in the container image.\\nIf unspecified, no additional groups are added, though group memberships\\ndefined in the container image may still be used, depending on the\\nsupplementalGroupsPolicy field.\\nNote that this field cannot be set when spec.os.name is windows.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='supplementalGroups', type=d.T.array)]),
              withSupplementalGroupsMixin(supplementalGroups): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { pod+: { securityContext+: { supplementalGroups+: if std.isArray(v=supplementalGroups) then supplementalGroups else [supplementalGroups] } } } } } } },
              '#withSupplementalGroupsPolicy':: d.fn(help='"Defines how supplemental groups of the first container processes are calculated.\\nValid values are \\"Merge\\" and \\"Strict\\". If not specified, \\"Merge\\" is used.\\n(Alpha) Using the field requires the SupplementalGroupsPolicy feature gate to be enabled\\nand the container runtime must implement support for this feature.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='supplementalGroupsPolicy', type=d.T.string)]),
              withSupplementalGroupsPolicy(supplementalGroupsPolicy): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { pod+: { securityContext+: { supplementalGroupsPolicy: supplementalGroupsPolicy } } } } } } },
              '#withSysctls':: d.fn(help='"Sysctls hold a list of namespaced sysctls used for the pod. Pods with unsupported\\nsysctls (by the container runtime) might fail to launch.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='sysctls', type=d.T.array)]),
              withSysctls(sysctls): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { pod+: { securityContext+: { sysctls: if std.isArray(v=sysctls) then sysctls else [sysctls] } } } } } } },
              '#withSysctlsMixin':: d.fn(help='"Sysctls hold a list of namespaced sysctls used for the pod. Pods with unsupported\\nsysctls (by the container runtime) might fail to launch.\\nNote that this field cannot be set when spec.os.name is windows."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='sysctls', type=d.T.array)]),
              withSysctlsMixin(sysctls): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { pod+: { securityContext+: { sysctls+: if std.isArray(v=sysctls) then sysctls else [sysctls] } } } } } } },
            },
            '#tolerations':: d.obj(help="\"If specified, the pod's tolerations.\""),
            tolerations: {
              '#withEffect':: d.fn(help='"Effect indicates the taint effect to match. Empty means match all taint effects.\\nWhen specified, allowed values are NoSchedule, PreferNoSchedule and NoExecute."', args=[d.arg(name='effect', type=d.T.string)]),
              withEffect(effect): { effect: effect },
              '#withKey':: d.fn(help='"Key is the taint key that the toleration applies to. Empty means match all taint keys.\\nIf the key is empty, operator must be Exists; this combination means to match all values and all keys."', args=[d.arg(name='key', type=d.T.string)]),
              withKey(key): { key: key },
              '#withOperator':: d.fn(help="\"Operator represents a key's relationship to the value.\\nValid operators are Exists and Equal. Defaults to Equal.\\nExists is equivalent to wildcard for value, so that a pod can\\ntolerate all taints of a particular category.\"", args=[d.arg(name='operator', type=d.T.string)]),
              withOperator(operator): { operator: operator },
              '#withTolerationSeconds':: d.fn(help='"TolerationSeconds represents the period of time the toleration (which must be\\nof effect NoExecute, otherwise this field is ignored) tolerates the taint. By default,\\nit is not set, which means tolerate the taint forever (do not evict). Zero and\\nnegative values will be treated as 0 (evict immediately) by the system."', args=[d.arg(name='tolerationSeconds', type=d.T.integer)]),
              withTolerationSeconds(tolerationSeconds): { tolerationSeconds: tolerationSeconds },
              '#withValue':: d.fn(help='"Value is the taint value the toleration matches to.\\nIf the operator is Exists, the value should be empty, otherwise just a regular string."', args=[d.arg(name='value', type=d.T.string)]),
              withValue(value): { value: value },
            },
            '#topologySpreadConstraints':: d.obj(help='"TopologySpreadConstraints describes how a group of pods ought to spread across topology\\ndomains. Scheduler will schedule pods in a way which abides by the constraints.\\nAll topologySpreadConstraints are ANDed."'),
            topologySpreadConstraints: {
              '#labelSelector':: d.obj(help='"LabelSelector is used to find matching pods.\\nPods that match this label selector are counted to determine the number of pods\\nin their corresponding topology domain."'),
              labelSelector: {
                '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                matchExpressions: {
                  '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { key: key },
                  '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                  withOperator(operator): { operator: operator },
                  '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                  withValues(values): { values: if std.isArray(v=values) then values else [values] },
                  '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                  withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                },
                '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressions(matchExpressions): { labelSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressionsMixin(matchExpressions): { labelSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabels(matchLabels): { labelSelector+: { matchLabels: matchLabels } },
                '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabelsMixin(matchLabels): { labelSelector+: { matchLabels+: matchLabels } },
              },
              '#withMatchLabelKeys':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select the pods over which\\nspreading will be calculated. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are ANDed with labelSelector\\nto select the group of existing pods over which spreading will be calculated\\nfor the incoming pod. The same key is forbidden to exist in both MatchLabelKeys and LabelSelector.\\nMatchLabelKeys cannot be set when LabelSelector isn't set.\\nKeys that don't exist in the incoming pod labels will\\nbe ignored. A null or empty list means only match against labelSelector.\\n\\nThis is a beta field and requires the MatchLabelKeysInPodTopologySpread feature gate to be enabled (enabled by default).\"", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
              withMatchLabelKeys(matchLabelKeys): { matchLabelKeys: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] },
              '#withMatchLabelKeysMixin':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select the pods over which\\nspreading will be calculated. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are ANDed with labelSelector\\nto select the group of existing pods over which spreading will be calculated\\nfor the incoming pod. The same key is forbidden to exist in both MatchLabelKeys and LabelSelector.\\nMatchLabelKeys cannot be set when LabelSelector isn't set.\\nKeys that don't exist in the incoming pod labels will\\nbe ignored. A null or empty list means only match against labelSelector.\\n\\nThis is a beta field and requires the MatchLabelKeysInPodTopologySpread feature gate to be enabled (enabled by default).\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
              withMatchLabelKeysMixin(matchLabelKeys): { matchLabelKeys+: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] },
              '#withMaxSkew':: d.fn(help="\"MaxSkew describes the degree to which pods may be unevenly distributed.\\nWhen `whenUnsatisfiable=DoNotSchedule`, it is the maximum permitted difference\\nbetween the number of matching pods in the target topology and the global minimum.\\nThe global minimum is the minimum number of matching pods in an eligible domain\\nor zero if the number of eligible domains is less than MinDomains.\\nFor example, in a 3-zone cluster, MaxSkew is set to 1, and pods with the same\\nlabelSelector spread as 2/2/1:\\nIn this case, the global minimum is 1.\\n| zone1 | zone2 | zone3 |\\n|  P P  |  P P  |   P   |\\n- if MaxSkew is 1, incoming pod can only be scheduled to zone3 to become 2/2/2;\\nscheduling it onto zone1(zone2) would make the ActualSkew(3-1) on zone1(zone2)\\nviolate MaxSkew(1).\\n- if MaxSkew is 2, incoming pod can be scheduled onto any zone.\\nWhen `whenUnsatisfiable=ScheduleAnyway`, it is used to give higher precedence\\nto topologies that satisfy it.\\nIt's a required field. Default value is 1 and 0 is not allowed.\"", args=[d.arg(name='maxSkew', type=d.T.integer)]),
              withMaxSkew(maxSkew): { maxSkew: maxSkew },
              '#withMinDomains':: d.fn(help="\"MinDomains indicates a minimum number of eligible domains.\\nWhen the number of eligible domains with matching topology keys is less than minDomains,\\nPod Topology Spread treats \\\"global minimum\\\" as 0, and then the calculation of Skew is performed.\\nAnd when the number of eligible domains with matching topology keys equals or greater than minDomains,\\nthis value has no effect on scheduling.\\nAs a result, when the number of eligible domains is less than minDomains,\\nscheduler won't schedule more than maxSkew Pods to those domains.\\nIf value is nil, the constraint behaves as if MinDomains is equal to 1.\\nValid values are integers greater than 0.\\nWhen value is not nil, WhenUnsatisfiable must be DoNotSchedule.\\n\\nFor example, in a 3-zone cluster, MaxSkew is set to 2, MinDomains is set to 5 and pods with the same\\nlabelSelector spread as 2/2/2:\\n| zone1 | zone2 | zone3 |\\n|  P P  |  P P  |  P P  |\\nThe number of domains is less than 5(MinDomains), so \\\"global minimum\\\" is treated as 0.\\nIn this situation, new pod with the same labelSelector cannot be scheduled,\\nbecause computed skew will be 3(3 - 0) if new Pod is scheduled to any of the three zones,\\nit will violate MaxSkew.\"", args=[d.arg(name='minDomains', type=d.T.integer)]),
              withMinDomains(minDomains): { minDomains: minDomains },
              '#withNodeAffinityPolicy':: d.fn(help="\"NodeAffinityPolicy indicates how we will treat Pod's nodeAffinity/nodeSelector\\nwhen calculating pod topology spread skew. Options are:\\n- Honor: only nodes matching nodeAffinity/nodeSelector are included in the calculations.\\n- Ignore: nodeAffinity/nodeSelector are ignored. All nodes are included in the calculations.\\n\\nIf this value is nil, the behavior is equivalent to the Honor policy.\"", args=[d.arg(name='nodeAffinityPolicy', type=d.T.string)]),
              withNodeAffinityPolicy(nodeAffinityPolicy): { nodeAffinityPolicy: nodeAffinityPolicy },
              '#withNodeTaintsPolicy':: d.fn(help='"NodeTaintsPolicy indicates how we will treat node taints when calculating\\npod topology spread skew. Options are:\\n- Honor: nodes without taints, along with tainted nodes for which the incoming pod\\nhas a toleration, are included.\\n- Ignore: node taints are ignored. All nodes are included.\\n\\nIf this value is nil, the behavior is equivalent to the Ignore policy."', args=[d.arg(name='nodeTaintsPolicy', type=d.T.string)]),
              withNodeTaintsPolicy(nodeTaintsPolicy): { nodeTaintsPolicy: nodeTaintsPolicy },
              '#withTopologyKey':: d.fn(help="\"TopologyKey is the key of node labels. Nodes that have a label with this key\\nand identical values are considered to be in the same topology.\\nWe consider each \u003ckey, value\u003e as a \\\"bucket\\\", and try to put balanced number\\nof pods into each bucket.\\nWe define a domain as a particular instance of a topology.\\nAlso, we define an eligible domain as a domain whose nodes meet the requirements of\\nnodeAffinityPolicy and nodeTaintsPolicy.\\ne.g. If TopologyKey is \\\"kubernetes.io/hostname\\\", each Node is a domain of that topology.\\nAnd, if TopologyKey is \\\"topology.kubernetes.io/zone\\\", each zone is a domain of that topology.\\nIt's a required field.\"", args=[d.arg(name='topologyKey', type=d.T.string)]),
              withTopologyKey(topologyKey): { topologyKey: topologyKey },
              '#withWhenUnsatisfiable':: d.fn(help="\"WhenUnsatisfiable indicates how to deal with a pod if it doesn't satisfy\\nthe spread constraint.\\n- DoNotSchedule (default) tells the scheduler not to schedule it.\\n- ScheduleAnyway tells the scheduler to schedule the pod in any location,\\n  but giving higher precedence to topologies that would help reduce the\\n  skew.\\nA constraint is considered \\\"Unsatisfiable\\\" for an incoming pod\\nif and only if every possible node assignment for that pod would violate\\n\\\"MaxSkew\\\" on some topology.\\nFor example, in a 3-zone cluster, MaxSkew is set to 1, and pods with the same\\nlabelSelector spread as 3/1/1:\\n| zone1 | zone2 | zone3 |\\n| P P P |   P   |   P   |\\nIf WhenUnsatisfiable is set to DoNotSchedule, incoming pod can only be scheduled\\nto zone2(zone3) to become 3/2/1(3/1/2) as ActualSkew(2-1) on zone2(zone3) satisfies\\nMaxSkew(1). In other words, the cluster can still be imbalanced, but scheduler\\nwon't make it *more* imbalanced.\\nIt's a required field.\"", args=[d.arg(name='whenUnsatisfiable', type=d.T.string)]),
              withWhenUnsatisfiable(whenUnsatisfiable): { whenUnsatisfiable: whenUnsatisfiable },
            },
            '#volumes':: d.obj(help='"Volumes that can be mounted by containers belonging to the pod.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes"'),
            volumes: {
              '#awsElasticBlockStore':: d.obj(help="\"awsElasticBlockStore represents an AWS Disk resource that is attached to a\\nkubelet's host machine and then exposed to the pod.\\nDeprecated: AWSElasticBlockStore is deprecated. All operations for the in-tree\\nawsElasticBlockStore type are redirected to the ebs.csi.aws.com CSI driver.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore\""),
              awsElasticBlockStore: {
                '#withFsType':: d.fn(help='"fsType is the filesystem type of the volume that you want to mount.\\nTip: Ensure that the filesystem type is supported by the host operating system.\\nExamples: \\"ext4\\", \\"xfs\\", \\"ntfs\\". Implicitly inferred to be \\"ext4\\" if unspecified.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore"', args=[d.arg(name='fsType', type=d.T.string)]),
                withFsType(fsType): { awsElasticBlockStore+: { fsType: fsType } },
                '#withPartition':: d.fn(help='"partition is the partition in the volume that you want to mount.\\nIf omitted, the default is to mount by volume name.\\nExamples: For volume /dev/sda1, you specify the partition as \\"1\\".\\nSimilarly, the volume partition for /dev/sda is \\"0\\" (or you can leave the property empty)."', args=[d.arg(name='partition', type=d.T.integer)]),
                withPartition(partition): { awsElasticBlockStore+: { partition: partition } },
                '#withReadOnly':: d.fn(help='"readOnly value true will force the readOnly setting in VolumeMounts.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore"', args=[d.arg(name='readOnly', type=d.T.boolean)]),
                withReadOnly(readOnly): { awsElasticBlockStore+: { readOnly: readOnly } },
                '#withVolumeID':: d.fn(help='"volumeID is unique ID of the persistent disk resource in AWS (Amazon EBS volume).\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore"', args=[d.arg(name='volumeID', type=d.T.string)]),
                withVolumeID(volumeID): { awsElasticBlockStore+: { volumeID: volumeID } },
              },
              '#azureDisk':: d.obj(help='"azureDisk represents an Azure Data Disk mount on the host and bind mount to the pod.\\nDeprecated: AzureDisk is deprecated. All operations for the in-tree azureDisk type\\nare redirected to the disk.csi.azure.com CSI driver."'),
              azureDisk: {
                '#withCachingMode':: d.fn(help='"cachingMode is the Host Caching mode: None, Read Only, Read Write."', args=[d.arg(name='cachingMode', type=d.T.string)]),
                withCachingMode(cachingMode): { azureDisk+: { cachingMode: cachingMode } },
                '#withDiskName':: d.fn(help='"diskName is the Name of the data disk in the blob storage"', args=[d.arg(name='diskName', type=d.T.string)]),
                withDiskName(diskName): { azureDisk+: { diskName: diskName } },
                '#withDiskURI':: d.fn(help='"diskURI is the URI of data disk in the blob storage"', args=[d.arg(name='diskURI', type=d.T.string)]),
                withDiskURI(diskURI): { azureDisk+: { diskURI: diskURI } },
                '#withFsType':: d.fn(help='"fsType is Filesystem type to mount.\\nMust be a filesystem type supported by the host operating system.\\nEx. \\"ext4\\", \\"xfs\\", \\"ntfs\\". Implicitly inferred to be \\"ext4\\" if unspecified."', args=[d.arg(name='fsType', type=d.T.string)]),
                withFsType(fsType): { azureDisk+: { fsType: fsType } },
                '#withKind':: d.fn(help='"kind expected values are Shared: multiple blob disks per storage account  Dedicated: single blob disk per storage account  Managed: azure managed data disk (only in managed availability set). defaults to shared"', args=[d.arg(name='kind', type=d.T.string)]),
                withKind(kind): { azureDisk+: { kind: kind } },
                '#withReadOnly':: d.fn(help='"readOnly Defaults to false (read/write). ReadOnly here will force\\nthe ReadOnly setting in VolumeMounts."', args=[d.arg(name='readOnly', type=d.T.boolean)]),
                withReadOnly(readOnly): { azureDisk+: { readOnly: readOnly } },
              },
              '#azureFile':: d.obj(help='"azureFile represents an Azure File Service mount on the host and bind mount to the pod.\\nDeprecated: AzureFile is deprecated. All operations for the in-tree azureFile type\\nare redirected to the file.csi.azure.com CSI driver."'),
              azureFile: {
                '#withReadOnly':: d.fn(help='"readOnly defaults to false (read/write). ReadOnly here will force\\nthe ReadOnly setting in VolumeMounts."', args=[d.arg(name='readOnly', type=d.T.boolean)]),
                withReadOnly(readOnly): { azureFile+: { readOnly: readOnly } },
                '#withSecretName':: d.fn(help='"secretName is the  name of secret that contains Azure Storage Account Name and Key"', args=[d.arg(name='secretName', type=d.T.string)]),
                withSecretName(secretName): { azureFile+: { secretName: secretName } },
                '#withShareName':: d.fn(help='"shareName is the azure share Name"', args=[d.arg(name='shareName', type=d.T.string)]),
                withShareName(shareName): { azureFile+: { shareName: shareName } },
              },
              '#cephfs':: d.obj(help="\"cephFS represents a Ceph FS mount on the host that shares a pod's lifetime.\\nDeprecated: CephFS is deprecated and the in-tree cephfs type is no longer supported.\""),
              cephfs: {
                '#secretRef':: d.obj(help='"secretRef is Optional: SecretRef is reference to the authentication secret for User, default is empty.\\nMore info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it"'),
                secretRef: {
                  '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
                  withName(name): { cephfs+: { secretRef+: { name: name } } },
                },
                '#withMonitors':: d.fn(help='"monitors is Required: Monitors is a collection of Ceph monitors\\nMore info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it"', args=[d.arg(name='monitors', type=d.T.array)]),
                withMonitors(monitors): { cephfs+: { monitors: if std.isArray(v=monitors) then monitors else [monitors] } },
                '#withMonitorsMixin':: d.fn(help='"monitors is Required: Monitors is a collection of Ceph monitors\\nMore info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='monitors', type=d.T.array)]),
                withMonitorsMixin(monitors): { cephfs+: { monitors+: if std.isArray(v=monitors) then monitors else [monitors] } },
                '#withPath':: d.fn(help='"path is Optional: Used as the mounted root, rather than the full Ceph tree, default is /"', args=[d.arg(name='path', type=d.T.string)]),
                withPath(path): { cephfs+: { path: path } },
                '#withReadOnly':: d.fn(help='"readOnly is Optional: Defaults to false (read/write). ReadOnly here will force\\nthe ReadOnly setting in VolumeMounts.\\nMore info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it"', args=[d.arg(name='readOnly', type=d.T.boolean)]),
                withReadOnly(readOnly): { cephfs+: { readOnly: readOnly } },
                '#withSecretFile':: d.fn(help='"secretFile is Optional: SecretFile is the path to key ring for User, default is /etc/ceph/user.secret\\nMore info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it"', args=[d.arg(name='secretFile', type=d.T.string)]),
                withSecretFile(secretFile): { cephfs+: { secretFile: secretFile } },
                '#withUser':: d.fn(help='"user is optional: User is the rados user name, default is admin\\nMore info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it"', args=[d.arg(name='user', type=d.T.string)]),
                withUser(user): { cephfs+: { user: user } },
              },
              '#cinder':: d.obj(help='"cinder represents a cinder volume attached and mounted on kubelets host machine.\\nDeprecated: Cinder is deprecated. All operations for the in-tree cinder type\\nare redirected to the cinder.csi.openstack.org CSI driver.\\nMore info: https://examples.k8s.io/mysql-cinder-pd/README.md"'),
              cinder: {
                '#secretRef':: d.obj(help='"secretRef is optional: points to a secret object containing parameters used to connect\\nto OpenStack."'),
                secretRef: {
                  '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
                  withName(name): { cinder+: { secretRef+: { name: name } } },
                },
                '#withFsType':: d.fn(help='"fsType is the filesystem type to mount.\\nMust be a filesystem type supported by the host operating system.\\nExamples: \\"ext4\\", \\"xfs\\", \\"ntfs\\". Implicitly inferred to be \\"ext4\\" if unspecified.\\nMore info: https://examples.k8s.io/mysql-cinder-pd/README.md"', args=[d.arg(name='fsType', type=d.T.string)]),
                withFsType(fsType): { cinder+: { fsType: fsType } },
                '#withReadOnly':: d.fn(help='"readOnly defaults to false (read/write). ReadOnly here will force\\nthe ReadOnly setting in VolumeMounts.\\nMore info: https://examples.k8s.io/mysql-cinder-pd/README.md"', args=[d.arg(name='readOnly', type=d.T.boolean)]),
                withReadOnly(readOnly): { cinder+: { readOnly: readOnly } },
                '#withVolumeID':: d.fn(help='"volumeID used to identify the volume in cinder.\\nMore info: https://examples.k8s.io/mysql-cinder-pd/README.md"', args=[d.arg(name='volumeID', type=d.T.string)]),
                withVolumeID(volumeID): { cinder+: { volumeID: volumeID } },
              },
              '#configMap':: d.obj(help='"configMap represents a configMap that should populate this volume"'),
              configMap: {
                '#items':: d.obj(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nConfigMap will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the ConfigMap,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\""),
                items: {
                  '#withKey':: d.fn(help='"key is the key to project."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { key: key },
                  '#withMode':: d.fn(help='"mode is Optional: mode bits used to set permissions on this file.\\nMust be an octal value between 0000 and 0777 or a decimal value between 0 and 511.\\nYAML accepts both octal and decimal values, JSON requires decimal values for mode bits.\\nIf not specified, the volume defaultMode will be used.\\nThis might be in conflict with other options that affect the file\\nmode, like fsGroup, and the result can be other mode bits set."', args=[d.arg(name='mode', type=d.T.integer)]),
                  withMode(mode): { mode: mode },
                  '#withPath':: d.fn(help="\"path is the relative path of the file to map the key to.\\nMay not be an absolute path.\\nMay not contain the path element '..'.\\nMay not start with the string '..'.\"", args=[d.arg(name='path', type=d.T.string)]),
                  withPath(path): { path: path },
                },
                '#withDefaultMode':: d.fn(help='"defaultMode is optional: mode bits used to set permissions on created files by default.\\nMust be an octal value between 0000 and 0777 or a decimal value between 0 and 511.\\nYAML accepts both octal and decimal values, JSON requires decimal values for mode bits.\\nDefaults to 0644.\\nDirectories within the path are not affected by this setting.\\nThis might be in conflict with other options that affect the file\\nmode, like fsGroup, and the result can be other mode bits set."', args=[d.arg(name='defaultMode', type=d.T.integer)]),
                withDefaultMode(defaultMode): { configMap+: { defaultMode: defaultMode } },
                '#withItems':: d.fn(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nConfigMap will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the ConfigMap,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\"", args=[d.arg(name='items', type=d.T.array)]),
                withItems(items): { configMap+: { items: if std.isArray(v=items) then items else [items] } },
                '#withItemsMixin':: d.fn(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nConfigMap will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the ConfigMap,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='items', type=d.T.array)]),
                withItemsMixin(items): { configMap+: { items+: if std.isArray(v=items) then items else [items] } },
                '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
                withName(name): { configMap+: { name: name } },
                '#withOptional':: d.fn(help='"optional specify whether the ConfigMap or its keys must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
                withOptional(optional): { configMap+: { optional: optional } },
              },
              '#csi':: d.obj(help='"csi (Container Storage Interface) represents ephemeral storage that is handled by certain external CSI drivers."'),
              csi: {
                '#nodePublishSecretRef':: d.obj(help='"nodePublishSecretRef is a reference to the secret object containing\\nsensitive information to pass to the CSI driver to complete the CSI\\nNodePublishVolume and NodeUnpublishVolume calls.\\nThis field is optional, and  may be empty if no secret is required. If the\\nsecret object contains more than one secret, all secret references are passed."'),
                nodePublishSecretRef: {
                  '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
                  withName(name): { csi+: { nodePublishSecretRef+: { name: name } } },
                },
                '#withDriver':: d.fn(help='"driver is the name of the CSI driver that handles this volume.\\nConsult with your admin for the correct name as registered in the cluster."', args=[d.arg(name='driver', type=d.T.string)]),
                withDriver(driver): { csi+: { driver: driver } },
                '#withFsType':: d.fn(help='"fsType to mount. Ex. \\"ext4\\", \\"xfs\\", \\"ntfs\\".\\nIf not provided, the empty value is passed to the associated CSI driver\\nwhich will determine the default filesystem to apply."', args=[d.arg(name='fsType', type=d.T.string)]),
                withFsType(fsType): { csi+: { fsType: fsType } },
                '#withReadOnly':: d.fn(help='"readOnly specifies a read-only configuration for the volume.\\nDefaults to false (read/write)."', args=[d.arg(name='readOnly', type=d.T.boolean)]),
                withReadOnly(readOnly): { csi+: { readOnly: readOnly } },
                '#withVolumeAttributes':: d.fn(help="\"volumeAttributes stores driver-specific properties that are passed to the CSI\\ndriver. Consult your driver's documentation for supported values.\"", args=[d.arg(name='volumeAttributes', type=d.T.object)]),
                withVolumeAttributes(volumeAttributes): { csi+: { volumeAttributes: volumeAttributes } },
                '#withVolumeAttributesMixin':: d.fn(help="\"volumeAttributes stores driver-specific properties that are passed to the CSI\\ndriver. Consult your driver's documentation for supported values.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='volumeAttributes', type=d.T.object)]),
                withVolumeAttributesMixin(volumeAttributes): { csi+: { volumeAttributes+: volumeAttributes } },
              },
              '#downwardAPI':: d.obj(help='"downwardAPI represents downward API about the pod that should populate this volume"'),
              downwardAPI: {
                '#items':: d.obj(help='"Items is a list of downward API volume file"'),
                items: {
                  '#fieldRef':: d.obj(help='"Required: Selects a field of the pod: only annotations, labels, name, namespace and uid are supported."'),
                  fieldRef: {
                    '#withApiVersion':: d.fn(help='"Version of the schema the FieldPath is written in terms of, defaults to \\"v1\\"."', args=[d.arg(name='apiVersion', type=d.T.string)]),
                    withApiVersion(apiVersion): { fieldRef+: { apiVersion: apiVersion } },
                    '#withFieldPath':: d.fn(help='"Path of the field to select in the specified API version."', args=[d.arg(name='fieldPath', type=d.T.string)]),
                    withFieldPath(fieldPath): { fieldRef+: { fieldPath: fieldPath } },
                  },
                  '#resourceFieldRef':: d.obj(help='"Selects a resource of the container: only resources limits and requests\\n(limits.cpu, limits.memory, requests.cpu and requests.memory) are currently supported."'),
                  resourceFieldRef: {
                    '#withContainerName':: d.fn(help='"Container name: required for volumes, optional for env vars"', args=[d.arg(name='containerName', type=d.T.string)]),
                    withContainerName(containerName): { resourceFieldRef+: { containerName: containerName } },
                    '#withDivisor':: d.fn(help='"Specifies the output format of the exposed resources, defaults to \\"1\\', args=[d.arg(name='divisor', type=d.T.any)]),
                    withDivisor(divisor): { resourceFieldRef+: { divisor: divisor } },
                    '#withResource':: d.fn(help='"Required: resource to select"', args=[d.arg(name='resource', type=d.T.string)]),
                    withResource(resource): { resourceFieldRef+: { resource: resource } },
                  },
                  '#withMode':: d.fn(help='"Optional: mode bits used to set permissions on this file, must be an octal value\\nbetween 0000 and 0777 or a decimal value between 0 and 511.\\nYAML accepts both octal and decimal values, JSON requires decimal values for mode bits.\\nIf not specified, the volume defaultMode will be used.\\nThis might be in conflict with other options that affect the file\\nmode, like fsGroup, and the result can be other mode bits set."', args=[d.arg(name='mode', type=d.T.integer)]),
                  withMode(mode): { mode: mode },
                  '#withPath':: d.fn(help="\"Required: Path is  the relative path name of the file to be created. Must not be absolute or contain the '..' path. Must be utf-8 encoded. The first item of the relative path must not start with '..'\"", args=[d.arg(name='path', type=d.T.string)]),
                  withPath(path): { path: path },
                },
                '#withDefaultMode':: d.fn(help='"Optional: mode bits to use on created files by default. Must be a\\nOptional: mode bits used to set permissions on created files by default.\\nMust be an octal value between 0000 and 0777 or a decimal value between 0 and 511.\\nYAML accepts both octal and decimal values, JSON requires decimal values for mode bits.\\nDefaults to 0644.\\nDirectories within the path are not affected by this setting.\\nThis might be in conflict with other options that affect the file\\nmode, like fsGroup, and the result can be other mode bits set."', args=[d.arg(name='defaultMode', type=d.T.integer)]),
                withDefaultMode(defaultMode): { downwardAPI+: { defaultMode: defaultMode } },
                '#withItems':: d.fn(help='"Items is a list of downward API volume file"', args=[d.arg(name='items', type=d.T.array)]),
                withItems(items): { downwardAPI+: { items: if std.isArray(v=items) then items else [items] } },
                '#withItemsMixin':: d.fn(help='"Items is a list of downward API volume file"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='items', type=d.T.array)]),
                withItemsMixin(items): { downwardAPI+: { items+: if std.isArray(v=items) then items else [items] } },
              },
              '#emptyDir':: d.obj(help="\"emptyDir represents a temporary directory that shares a pod's lifetime.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#emptydir\""),
              emptyDir: {
                '#withMedium':: d.fn(help="\"medium represents what type of storage medium should back this directory.\\nThe default is \\\"\\\" which means to use the node's default medium.\\nMust be an empty string (default) or Memory.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#emptydir\"", args=[d.arg(name='medium', type=d.T.string)]),
                withMedium(medium): { emptyDir+: { medium: medium } },
                '#withSizeLimit':: d.fn(help='"sizeLimit is the total amount of local storage required for this EmptyDir volume.\\nThe size limit is also applicable for memory medium.\\nThe maximum usage on memory medium EmptyDir would be the minimum value between\\nthe SizeLimit specified here and the sum of memory limits of all containers in a pod.\\nThe default is nil which means that the limit is undefined.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#emptydir"', args=[d.arg(name='sizeLimit', type=d.T.any)]),
                withSizeLimit(sizeLimit): { emptyDir+: { sizeLimit: sizeLimit } },
              },
              '#ephemeral':: d.obj(help="\"ephemeral represents a volume that is handled by a cluster storage driver.\\nThe volume's lifecycle is tied to the pod that defines it - it will be created before the pod starts,\\nand deleted when the pod is removed.\\n\\nUse this if:\\na) the volume is only needed while the pod runs,\\nb) features of normal volumes like restoring from snapshot or capacity\\n   tracking are needed,\\nc) the storage driver is specified through a storage class, and\\nd) the storage driver supports dynamic volume provisioning through\\n   a PersistentVolumeClaim (see EphemeralVolumeSource for more\\n   information on the connection between this volume type\\n   and PersistentVolumeClaim).\\n\\nUse PersistentVolumeClaim or one of the vendor-specific\\nAPIs for volumes that persist for longer than the lifecycle\\nof an individual pod.\\n\\nUse CSI for light-weight local ephemeral volumes if the CSI driver is meant to\\nbe used that way - see the documentation of the driver for\\nmore information.\\n\\nA pod can use both types of ephemeral volumes and\\npersistent volumes at the same time.\""),
              ephemeral: {
                '#volumeClaimTemplate':: d.obj(help='"Will be used to create a stand-alone PVC to provision the volume.\\nThe pod in which this EphemeralVolumeSource is embedded will be the\\nowner of the PVC, i.e. the PVC will be deleted together with the\\npod.  The name of the PVC will be `<pod name>-<volume name>` where\\n`<volume name>` is the name from the `PodSpec.Volumes` array\\nentry. Pod validation will reject the pod if the concatenated name\\nis not valid for a PVC (for example, too long).\\n\\nAn existing PVC with that name that is not owned by the pod\\nwill *not* be used for the pod to avoid using an unrelated\\nvolume by mistake. Starting the pod is then blocked until\\nthe unrelated PVC is removed. If such a pre-created PVC is\\nmeant to be used by the pod, the PVC has to updated with an\\nowner reference to the pod once the pod exists. Normally\\nthis should not be necessary, but it may be useful when\\nmanually reconstructing a broken cluster.\\n\\nThis field is read-only and no changes will be made by Kubernetes\\nto the PVC after it has been created.\\n\\nRequired, must not be nil."'),
                volumeClaimTemplate: {
                  '#spec':: d.obj(help='"The specification for the PersistentVolumeClaim. The entire content is\\ncopied unchanged into the PVC that gets created from this\\ntemplate. The same fields as in a PersistentVolumeClaim\\nare also valid here."'),
                  spec: {
                    '#dataSource':: d.obj(help='"dataSource field can be used to specify either:\\n* An existing VolumeSnapshot object (snapshot.storage.k8s.io/VolumeSnapshot)\\n* An existing PVC (PersistentVolumeClaim)\\nIf the provisioner or an external controller can support the specified data source,\\nit will create a new volume based on the contents of the specified data source.\\nWhen the AnyVolumeDataSource feature gate is enabled, dataSource contents will be copied to dataSourceRef,\\nand dataSourceRef contents will be copied to dataSource when dataSourceRef.namespace is not specified.\\nIf the namespace is specified, then dataSourceRef will not be copied to dataSource."'),
                    dataSource: {
                      '#withApiGroup':: d.fn(help='"APIGroup is the group for the resource being referenced.\\nIf APIGroup is not specified, the specified Kind must be in the core API group.\\nFor any other third-party types, APIGroup is required."', args=[d.arg(name='apiGroup', type=d.T.string)]),
                      withApiGroup(apiGroup): { ephemeral+: { volumeClaimTemplate+: { spec+: { dataSource+: { apiGroup: apiGroup } } } } },
                      '#withKind':: d.fn(help='"Kind is the type of resource being referenced"', args=[d.arg(name='kind', type=d.T.string)]),
                      withKind(kind): { ephemeral+: { volumeClaimTemplate+: { spec+: { dataSource+: { kind: kind } } } } },
                      '#withName':: d.fn(help='"Name is the name of resource being referenced"', args=[d.arg(name='name', type=d.T.string)]),
                      withName(name): { ephemeral+: { volumeClaimTemplate+: { spec+: { dataSource+: { name: name } } } } },
                    },
                    '#dataSourceRef':: d.obj(help="\"dataSourceRef specifies the object from which to populate the volume with data, if a non-empty\\nvolume is desired. This may be any object from a non-empty API group (non\\ncore object) or a PersistentVolumeClaim object.\\nWhen this field is specified, volume binding will only succeed if the type of\\nthe specified object matches some installed volume populator or dynamic\\nprovisioner.\\nThis field will replace the functionality of the dataSource field and as such\\nif both fields are non-empty, they must have the same value. For backwards\\ncompatibility, when namespace isn't specified in dataSourceRef,\\nboth fields (dataSource and dataSourceRef) will be set to the same\\nvalue automatically if one of them is empty and the other is non-empty.\\nWhen namespace is specified in dataSourceRef,\\ndataSource isn't set to the same value and must be empty.\\nThere are three important differences between dataSource and dataSourceRef:\\n* While dataSource only allows two specific types of objects, dataSourceRef\\n  allows any non-core object, as well as PersistentVolumeClaim objects.\\n* While dataSource ignores disallowed values (dropping them), dataSourceRef\\n  preserves all values, and generates an error if a disallowed value is\\n  specified.\\n* While dataSource only allows local objects, dataSourceRef allows objects\\n  in any namespaces.\\n(Beta) Using this field requires the AnyVolumeDataSource feature gate to be enabled.\\n(Alpha) Using the namespace field of dataSourceRef requires the CrossNamespaceVolumeDataSource feature gate to be enabled.\""),
                    dataSourceRef: {
                      '#withApiGroup':: d.fn(help='"APIGroup is the group for the resource being referenced.\\nIf APIGroup is not specified, the specified Kind must be in the core API group.\\nFor any other third-party types, APIGroup is required."', args=[d.arg(name='apiGroup', type=d.T.string)]),
                      withApiGroup(apiGroup): { ephemeral+: { volumeClaimTemplate+: { spec+: { dataSourceRef+: { apiGroup: apiGroup } } } } },
                      '#withKind':: d.fn(help='"Kind is the type of resource being referenced"', args=[d.arg(name='kind', type=d.T.string)]),
                      withKind(kind): { ephemeral+: { volumeClaimTemplate+: { spec+: { dataSourceRef+: { kind: kind } } } } },
                      '#withName':: d.fn(help='"Name is the name of resource being referenced"', args=[d.arg(name='name', type=d.T.string)]),
                      withName(name): { ephemeral+: { volumeClaimTemplate+: { spec+: { dataSourceRef+: { name: name } } } } },
                      '#withNamespace':: d.fn(help="\"Namespace is the namespace of resource being referenced\\nNote that when a namespace is specified, a gateway.networking.k8s.io/ReferenceGrant object is required in the referent namespace to allow that namespace's owner to accept the reference. See the ReferenceGrant documentation for details.\\n(Alpha) This field requires the CrossNamespaceVolumeDataSource feature gate to be enabled.\"", args=[d.arg(name='namespace', type=d.T.string)]),
                      withNamespace(namespace): { ephemeral+: { volumeClaimTemplate+: { spec+: { dataSourceRef+: { namespace: namespace } } } } },
                    },
                    '#resources':: d.obj(help='"resources represents the minimum resources the volume should have.\\nIf RecoverVolumeExpansionFailure feature is enabled users are allowed to specify resource requirements\\nthat are lower than previous value but must still be higher than capacity recorded in the\\nstatus field of the claim.\\nMore info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#resources"'),
                    resources: {
                      '#withLimits':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='limits', type=d.T.object)]),
                      withLimits(limits): { ephemeral+: { volumeClaimTemplate+: { spec+: { resources+: { limits: limits } } } } },
                      '#withLimitsMixin':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='limits', type=d.T.object)]),
                      withLimitsMixin(limits): { ephemeral+: { volumeClaimTemplate+: { spec+: { resources+: { limits+: limits } } } } },
                      '#withRequests':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='requests', type=d.T.object)]),
                      withRequests(requests): { ephemeral+: { volumeClaimTemplate+: { spec+: { resources+: { requests: requests } } } } },
                      '#withRequestsMixin':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requests', type=d.T.object)]),
                      withRequestsMixin(requests): { ephemeral+: { volumeClaimTemplate+: { spec+: { resources+: { requests+: requests } } } } },
                    },
                    '#selector':: d.obj(help='"selector is a label query over volumes to consider for binding."'),
                    selector: {
                      '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                      matchExpressions: {
                        '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                        withKey(key): { key: key },
                        '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                        withOperator(operator): { operator: operator },
                        '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                        withValues(values): { values: if std.isArray(v=values) then values else [values] },
                        '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                        withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                      },
                      '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                      withMatchExpressions(matchExpressions): { ephemeral+: { volumeClaimTemplate+: { spec+: { selector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } } } },
                      '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                      withMatchExpressionsMixin(matchExpressions): { ephemeral+: { volumeClaimTemplate+: { spec+: { selector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } } } },
                      '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                      withMatchLabels(matchLabels): { ephemeral+: { volumeClaimTemplate+: { spec+: { selector+: { matchLabels: matchLabels } } } } },
                      '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                      withMatchLabelsMixin(matchLabels): { ephemeral+: { volumeClaimTemplate+: { spec+: { selector+: { matchLabels+: matchLabels } } } } },
                    },
                    '#withAccessModes':: d.fn(help='"accessModes contains the desired access modes the volume should have.\\nMore info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#access-modes-1"', args=[d.arg(name='accessModes', type=d.T.array)]),
                    withAccessModes(accessModes): { ephemeral+: { volumeClaimTemplate+: { spec+: { accessModes: if std.isArray(v=accessModes) then accessModes else [accessModes] } } } },
                    '#withAccessModesMixin':: d.fn(help='"accessModes contains the desired access modes the volume should have.\\nMore info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#access-modes-1"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='accessModes', type=d.T.array)]),
                    withAccessModesMixin(accessModes): { ephemeral+: { volumeClaimTemplate+: { spec+: { accessModes+: if std.isArray(v=accessModes) then accessModes else [accessModes] } } } },
                    '#withStorageClassName':: d.fn(help='"storageClassName is the name of the StorageClass required by the claim.\\nMore info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#class-1"', args=[d.arg(name='storageClassName', type=d.T.string)]),
                    withStorageClassName(storageClassName): { ephemeral+: { volumeClaimTemplate+: { spec+: { storageClassName: storageClassName } } } },
                    '#withVolumeAttributesClassName':: d.fn(help="\"volumeAttributesClassName may be used to set the VolumeAttributesClass used by this claim.\\nIf specified, the CSI driver will create or update the volume with the attributes defined\\nin the corresponding VolumeAttributesClass. This has a different purpose than storageClassName,\\nit can be changed after the claim is created. An empty string value means that no VolumeAttributesClass\\nwill be applied to the claim but it's not allowed to reset this field to empty string once it is set.\\nIf unspecified and the PersistentVolumeClaim is unbound, the default VolumeAttributesClass\\nwill be set by the persistentvolume controller if it exists.\\nIf the resource referred to by volumeAttributesClass does not exist, this PersistentVolumeClaim will be\\nset to a Pending state, as reflected by the modifyVolumeStatus field, until such as a resource\\nexists.\\nMore info: https://kubernetes.io/docs/concepts/storage/volume-attributes-classes/\\n(Beta) Using this field requires the VolumeAttributesClass feature gate to be enabled (off by default).\"", args=[d.arg(name='volumeAttributesClassName', type=d.T.string)]),
                    withVolumeAttributesClassName(volumeAttributesClassName): { ephemeral+: { volumeClaimTemplate+: { spec+: { volumeAttributesClassName: volumeAttributesClassName } } } },
                    '#withVolumeMode':: d.fn(help='"volumeMode defines what type of volume is required by the claim.\\nValue of Filesystem is implied when not included in claim spec."', args=[d.arg(name='volumeMode', type=d.T.string)]),
                    withVolumeMode(volumeMode): { ephemeral+: { volumeClaimTemplate+: { spec+: { volumeMode: volumeMode } } } },
                    '#withVolumeName':: d.fn(help='"volumeName is the binding reference to the PersistentVolume backing this claim."', args=[d.arg(name='volumeName', type=d.T.string)]),
                    withVolumeName(volumeName): { ephemeral+: { volumeClaimTemplate+: { spec+: { volumeName: volumeName } } } },
                  },
                  '#withMetadata':: d.fn(help='"May contain labels and annotations that will be copied into the PVC\\nwhen creating it. No other fields are allowed and will be rejected during\\nvalidation."', args=[d.arg(name='metadata', type=d.T.object)]),
                  withMetadata(metadata): { ephemeral+: { volumeClaimTemplate+: { metadata: metadata } } },
                  '#withMetadataMixin':: d.fn(help='"May contain labels and annotations that will be copied into the PVC\\nwhen creating it. No other fields are allowed and will be rejected during\\nvalidation."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='metadata', type=d.T.object)]),
                  withMetadataMixin(metadata): { ephemeral+: { volumeClaimTemplate+: { metadata+: metadata } } },
                },
              },
              '#fc':: d.obj(help="\"fc represents a Fibre Channel resource that is attached to a kubelet's host machine and then exposed to the pod.\""),
              fc: {
                '#withFsType':: d.fn(help='"fsType is the filesystem type to mount.\\nMust be a filesystem type supported by the host operating system.\\nEx. \\"ext4\\", \\"xfs\\", \\"ntfs\\". Implicitly inferred to be \\"ext4\\" if unspecified."', args=[d.arg(name='fsType', type=d.T.string)]),
                withFsType(fsType): { fc+: { fsType: fsType } },
                '#withLun':: d.fn(help='"lun is Optional: FC target lun number"', args=[d.arg(name='lun', type=d.T.integer)]),
                withLun(lun): { fc+: { lun: lun } },
                '#withReadOnly':: d.fn(help='"readOnly is Optional: Defaults to false (read/write). ReadOnly here will force\\nthe ReadOnly setting in VolumeMounts."', args=[d.arg(name='readOnly', type=d.T.boolean)]),
                withReadOnly(readOnly): { fc+: { readOnly: readOnly } },
                '#withTargetWWNs':: d.fn(help='"targetWWNs is Optional: FC target worldwide names (WWNs)"', args=[d.arg(name='targetWWNs', type=d.T.array)]),
                withTargetWWNs(targetWWNs): { fc+: { targetWWNs: if std.isArray(v=targetWWNs) then targetWWNs else [targetWWNs] } },
                '#withTargetWWNsMixin':: d.fn(help='"targetWWNs is Optional: FC target worldwide names (WWNs)"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='targetWWNs', type=d.T.array)]),
                withTargetWWNsMixin(targetWWNs): { fc+: { targetWWNs+: if std.isArray(v=targetWWNs) then targetWWNs else [targetWWNs] } },
                '#withWwids':: d.fn(help='"wwids Optional: FC volume world wide identifiers (wwids)\\nEither wwids or combination of targetWWNs and lun must be set, but not both simultaneously."', args=[d.arg(name='wwids', type=d.T.array)]),
                withWwids(wwids): { fc+: { wwids: if std.isArray(v=wwids) then wwids else [wwids] } },
                '#withWwidsMixin':: d.fn(help='"wwids Optional: FC volume world wide identifiers (wwids)\\nEither wwids or combination of targetWWNs and lun must be set, but not both simultaneously."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='wwids', type=d.T.array)]),
                withWwidsMixin(wwids): { fc+: { wwids+: if std.isArray(v=wwids) then wwids else [wwids] } },
              },
              '#flexVolume':: d.obj(help='"flexVolume represents a generic volume resource that is\\nprovisioned/attached using an exec based plugin.\\nDeprecated: FlexVolume is deprecated. Consider using a CSIDriver instead."'),
              flexVolume: {
                '#secretRef':: d.obj(help='"secretRef is Optional: secretRef is reference to the secret object containing\\nsensitive information to pass to the plugin scripts. This may be\\nempty if no secret object is specified. If the secret object\\ncontains more than one secret, all secrets are passed to the plugin\\nscripts."'),
                secretRef: {
                  '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
                  withName(name): { flexVolume+: { secretRef+: { name: name } } },
                },
                '#withDriver':: d.fn(help='"driver is the name of the driver to use for this volume."', args=[d.arg(name='driver', type=d.T.string)]),
                withDriver(driver): { flexVolume+: { driver: driver } },
                '#withFsType':: d.fn(help='"fsType is the filesystem type to mount.\\nMust be a filesystem type supported by the host operating system.\\nEx. \\"ext4\\", \\"xfs\\", \\"ntfs\\". The default filesystem depends on FlexVolume script."', args=[d.arg(name='fsType', type=d.T.string)]),
                withFsType(fsType): { flexVolume+: { fsType: fsType } },
                '#withOptions':: d.fn(help='"options is Optional: this field holds extra command options if any."', args=[d.arg(name='options', type=d.T.object)]),
                withOptions(options): { flexVolume+: { options: options } },
                '#withOptionsMixin':: d.fn(help='"options is Optional: this field holds extra command options if any."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='options', type=d.T.object)]),
                withOptionsMixin(options): { flexVolume+: { options+: options } },
                '#withReadOnly':: d.fn(help='"readOnly is Optional: defaults to false (read/write). ReadOnly here will force\\nthe ReadOnly setting in VolumeMounts."', args=[d.arg(name='readOnly', type=d.T.boolean)]),
                withReadOnly(readOnly): { flexVolume+: { readOnly: readOnly } },
              },
              '#flocker':: d.obj(help="\"flocker represents a Flocker volume attached to a kubelet's host machine. This depends on the Flocker control service being running.\\nDeprecated: Flocker is deprecated and the in-tree flocker type is no longer supported.\""),
              flocker: {
                '#withDatasetName':: d.fn(help='"datasetName is Name of the dataset stored as metadata -> name on the dataset for Flocker\\nshould be considered as deprecated"', args=[d.arg(name='datasetName', type=d.T.string)]),
                withDatasetName(datasetName): { flocker+: { datasetName: datasetName } },
                '#withDatasetUUID':: d.fn(help='"datasetUUID is the UUID of the dataset. This is unique identifier of a Flocker dataset"', args=[d.arg(name='datasetUUID', type=d.T.string)]),
                withDatasetUUID(datasetUUID): { flocker+: { datasetUUID: datasetUUID } },
              },
              '#gcePersistentDisk':: d.obj(help="\"gcePersistentDisk represents a GCE Disk resource that is attached to a\\nkubelet's host machine and then exposed to the pod.\\nDeprecated: GCEPersistentDisk is deprecated. All operations for the in-tree\\ngcePersistentDisk type are redirected to the pd.csi.storage.gke.io CSI driver.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk\""),
              gcePersistentDisk: {
                '#withFsType':: d.fn(help='"fsType is filesystem type of the volume that you want to mount.\\nTip: Ensure that the filesystem type is supported by the host operating system.\\nExamples: \\"ext4\\", \\"xfs\\", \\"ntfs\\". Implicitly inferred to be \\"ext4\\" if unspecified.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk"', args=[d.arg(name='fsType', type=d.T.string)]),
                withFsType(fsType): { gcePersistentDisk+: { fsType: fsType } },
                '#withPartition':: d.fn(help='"partition is the partition in the volume that you want to mount.\\nIf omitted, the default is to mount by volume name.\\nExamples: For volume /dev/sda1, you specify the partition as \\"1\\".\\nSimilarly, the volume partition for /dev/sda is \\"0\\" (or you can leave the property empty).\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk"', args=[d.arg(name='partition', type=d.T.integer)]),
                withPartition(partition): { gcePersistentDisk+: { partition: partition } },
                '#withPdName':: d.fn(help='"pdName is unique name of the PD resource in GCE. Used to identify the disk in GCE.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk"', args=[d.arg(name='pdName', type=d.T.string)]),
                withPdName(pdName): { gcePersistentDisk+: { pdName: pdName } },
                '#withReadOnly':: d.fn(help='"readOnly here will force the ReadOnly setting in VolumeMounts.\\nDefaults to false.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk"', args=[d.arg(name='readOnly', type=d.T.boolean)]),
                withReadOnly(readOnly): { gcePersistentDisk+: { readOnly: readOnly } },
              },
              '#gitRepo':: d.obj(help="\"gitRepo represents a git repository at a particular revision.\\nDeprecated: GitRepo is deprecated. To provision a container with a git repo, mount an\\nEmptyDir into an InitContainer that clones the repo using git, then mount the EmptyDir\\ninto the Pod's container.\""),
              gitRepo: {
                '#withDirectory':: d.fn(help="\"directory is the target directory name.\\nMust not contain or start with '..'.  If '.' is supplied, the volume directory will be the\\ngit repository.  Otherwise, if specified, the volume will contain the git repository in\\nthe subdirectory with the given name.\"", args=[d.arg(name='directory', type=d.T.string)]),
                withDirectory(directory): { gitRepo+: { directory: directory } },
                '#withRepository':: d.fn(help='"repository is the URL"', args=[d.arg(name='repository', type=d.T.string)]),
                withRepository(repository): { gitRepo+: { repository: repository } },
                '#withRevision':: d.fn(help='"revision is the commit hash for the specified revision."', args=[d.arg(name='revision', type=d.T.string)]),
                withRevision(revision): { gitRepo+: { revision: revision } },
              },
              '#glusterfs':: d.obj(help="\"glusterfs represents a Glusterfs mount on the host that shares a pod's lifetime.\\nDeprecated: Glusterfs is deprecated and the in-tree glusterfs type is no longer supported.\\nMore info: https://examples.k8s.io/volumes/glusterfs/README.md\""),
              glusterfs: {
                '#withEndpoints':: d.fn(help='"endpoints is the endpoint name that details Glusterfs topology.\\nMore info: https://examples.k8s.io/volumes/glusterfs/README.md#create-a-pod"', args=[d.arg(name='endpoints', type=d.T.string)]),
                withEndpoints(endpoints): { glusterfs+: { endpoints: endpoints } },
                '#withPath':: d.fn(help='"path is the Glusterfs volume path.\\nMore info: https://examples.k8s.io/volumes/glusterfs/README.md#create-a-pod"', args=[d.arg(name='path', type=d.T.string)]),
                withPath(path): { glusterfs+: { path: path } },
                '#withReadOnly':: d.fn(help='"readOnly here will force the Glusterfs volume to be mounted with read-only permissions.\\nDefaults to false.\\nMore info: https://examples.k8s.io/volumes/glusterfs/README.md#create-a-pod"', args=[d.arg(name='readOnly', type=d.T.boolean)]),
                withReadOnly(readOnly): { glusterfs+: { readOnly: readOnly } },
              },
              '#hostPath':: d.obj(help='"hostPath represents a pre-existing file or directory on the host\\nmachine that is directly exposed to the container. This is generally\\nused for system agents or other privileged things that are allowed\\nto see the host machine. Most containers will NOT need this.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#hostpath"'),
              hostPath: {
                '#withPath':: d.fn(help='"path of the directory on the host.\\nIf the path is a symlink, it will follow the link to the real path.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#hostpath"', args=[d.arg(name='path', type=d.T.string)]),
                withPath(path): { hostPath+: { path: path } },
                '#withType':: d.fn(help='"type for HostPath Volume\\nDefaults to \\"\\"\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#hostpath"', args=[d.arg(name='type', type=d.T.string)]),
                withType(type): { hostPath+: { type: type } },
              },
              '#image':: d.obj(help="\"image represents an OCI object (a container image or artifact) pulled and mounted on the kubelet's host machine.\\nThe volume is resolved at pod startup depending on which PullPolicy value is provided:\\n\\n- Always: the kubelet always attempts to pull the reference. Container creation will fail If the pull fails.\\n- Never: the kubelet never pulls the reference and only uses a local image or artifact. Container creation will fail if the reference isn't present.\\n- IfNotPresent: the kubelet pulls if the reference isn't already present on disk. Container creation will fail if the reference isn't present and the pull fails.\\n\\nThe volume gets re-resolved if the pod gets deleted and recreated, which means that new remote content will become available on pod recreation.\\nA failure to resolve or pull the image during pod startup will block containers from starting and may add significant latency. Failures will be retried using normal volume backoff and will be reported on the pod reason and message.\\nThe types of objects that may be mounted by this volume are defined by the container runtime implementation on a host machine and at minimum must include all valid types supported by the container image field.\\nThe OCI object gets mounted in a single directory (spec.containers[*].volumeMounts.mountPath) by merging the manifest layers in the same way as for container images.\\nThe volume will be mounted read-only (ro) and non-executable files (noexec).\\nSub path mounts for containers are not supported (spec.containers[*].volumeMounts.subpath) before 1.33.\\nThe field spec.securityContext.fsGroupChangePolicy has no effect on this volume type.\""),
              image: {
                '#withPullPolicy':: d.fn(help="\"Policy for pulling OCI objects. Possible values are:\\nAlways: the kubelet always attempts to pull the reference. Container creation will fail If the pull fails.\\nNever: the kubelet never pulls the reference and only uses a local image or artifact. Container creation will fail if the reference isn't present.\\nIfNotPresent: the kubelet pulls if the reference isn't already present on disk. Container creation will fail if the reference isn't present and the pull fails.\\nDefaults to Always if :latest tag is specified, or IfNotPresent otherwise.\"", args=[d.arg(name='pullPolicy', type=d.T.string)]),
                withPullPolicy(pullPolicy): { image+: { pullPolicy: pullPolicy } },
                '#withReference':: d.fn(help='"Required: Image or artifact reference to be used.\\nBehaves in the same way as pod.spec.containers[*].image.\\nPull secrets will be assembled in the same way as for the container image by looking up node credentials, SA image pull secrets, and pod spec image pull secrets.\\nMore info: https://kubernetes.io/docs/concepts/containers/images\\nThis field is optional to allow higher level config management to default or override\\ncontainer images in workload controllers like Deployments and StatefulSets."', args=[d.arg(name='reference', type=d.T.string)]),
                withReference(reference): { image+: { reference: reference } },
              },
              '#iscsi':: d.obj(help="\"iscsi represents an ISCSI Disk resource that is attached to a\\nkubelet's host machine and then exposed to the pod.\\nMore info: https://examples.k8s.io/volumes/iscsi/README.md\""),
              iscsi: {
                '#secretRef':: d.obj(help='"secretRef is the CHAP Secret for iSCSI target and initiator authentication"'),
                secretRef: {
                  '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
                  withName(name): { iscsi+: { secretRef+: { name: name } } },
                },
                '#withChapAuthDiscovery':: d.fn(help='"chapAuthDiscovery defines whether support iSCSI Discovery CHAP authentication"', args=[d.arg(name='chapAuthDiscovery', type=d.T.boolean)]),
                withChapAuthDiscovery(chapAuthDiscovery): { iscsi+: { chapAuthDiscovery: chapAuthDiscovery } },
                '#withChapAuthSession':: d.fn(help='"chapAuthSession defines whether support iSCSI Session CHAP authentication"', args=[d.arg(name='chapAuthSession', type=d.T.boolean)]),
                withChapAuthSession(chapAuthSession): { iscsi+: { chapAuthSession: chapAuthSession } },
                '#withFsType':: d.fn(help='"fsType is the filesystem type of the volume that you want to mount.\\nTip: Ensure that the filesystem type is supported by the host operating system.\\nExamples: \\"ext4\\", \\"xfs\\", \\"ntfs\\". Implicitly inferred to be \\"ext4\\" if unspecified.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#iscsi"', args=[d.arg(name='fsType', type=d.T.string)]),
                withFsType(fsType): { iscsi+: { fsType: fsType } },
                '#withInitiatorName':: d.fn(help='"initiatorName is the custom iSCSI Initiator Name.\\nIf initiatorName is specified with iscsiInterface simultaneously, new iSCSI interface\\n<target portal>:<volume name> will be created for the connection."', args=[d.arg(name='initiatorName', type=d.T.string)]),
                withInitiatorName(initiatorName): { iscsi+: { initiatorName: initiatorName } },
                '#withIqn':: d.fn(help='"iqn is the target iSCSI Qualified Name."', args=[d.arg(name='iqn', type=d.T.string)]),
                withIqn(iqn): { iscsi+: { iqn: iqn } },
                '#withIscsiInterface':: d.fn(help="\"iscsiInterface is the interface Name that uses an iSCSI transport.\\nDefaults to 'default' (tcp).\"", args=[d.arg(name='iscsiInterface', type=d.T.string)]),
                withIscsiInterface(iscsiInterface): { iscsi+: { iscsiInterface: iscsiInterface } },
                '#withLun':: d.fn(help='"lun represents iSCSI Target Lun number."', args=[d.arg(name='lun', type=d.T.integer)]),
                withLun(lun): { iscsi+: { lun: lun } },
                '#withPortals':: d.fn(help='"portals is the iSCSI Target Portal List. The portal is either an IP or ip_addr:port if the port\\nis other than default (typically TCP ports 860 and 3260)."', args=[d.arg(name='portals', type=d.T.array)]),
                withPortals(portals): { iscsi+: { portals: if std.isArray(v=portals) then portals else [portals] } },
                '#withPortalsMixin':: d.fn(help='"portals is the iSCSI Target Portal List. The portal is either an IP or ip_addr:port if the port\\nis other than default (typically TCP ports 860 and 3260)."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='portals', type=d.T.array)]),
                withPortalsMixin(portals): { iscsi+: { portals+: if std.isArray(v=portals) then portals else [portals] } },
                '#withReadOnly':: d.fn(help='"readOnly here will force the ReadOnly setting in VolumeMounts.\\nDefaults to false."', args=[d.arg(name='readOnly', type=d.T.boolean)]),
                withReadOnly(readOnly): { iscsi+: { readOnly: readOnly } },
                '#withTargetPortal':: d.fn(help='"targetPortal is iSCSI Target Portal. The Portal is either an IP or ip_addr:port if the port\\nis other than default (typically TCP ports 860 and 3260)."', args=[d.arg(name='targetPortal', type=d.T.string)]),
                withTargetPortal(targetPortal): { iscsi+: { targetPortal: targetPortal } },
              },
              '#nfs':: d.obj(help="\"nfs represents an NFS mount on the host that shares a pod's lifetime\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#nfs\""),
              nfs: {
                '#withPath':: d.fn(help='"path that is exported by the NFS server.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#nfs"', args=[d.arg(name='path', type=d.T.string)]),
                withPath(path): { nfs+: { path: path } },
                '#withReadOnly':: d.fn(help='"readOnly here will force the NFS export to be mounted with read-only permissions.\\nDefaults to false.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#nfs"', args=[d.arg(name='readOnly', type=d.T.boolean)]),
                withReadOnly(readOnly): { nfs+: { readOnly: readOnly } },
                '#withServer':: d.fn(help='"server is the hostname or IP address of the NFS server.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#nfs"', args=[d.arg(name='server', type=d.T.string)]),
                withServer(server): { nfs+: { server: server } },
              },
              '#persistentVolumeClaim':: d.obj(help='"persistentVolumeClaimVolumeSource represents a reference to a\\nPersistentVolumeClaim in the same namespace.\\nMore info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims"'),
              persistentVolumeClaim: {
                '#withClaimName':: d.fn(help='"claimName is the name of a PersistentVolumeClaim in the same namespace as the pod using this volume.\\nMore info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims"', args=[d.arg(name='claimName', type=d.T.string)]),
                withClaimName(claimName): { persistentVolumeClaim+: { claimName: claimName } },
                '#withReadOnly':: d.fn(help='"readOnly Will force the ReadOnly setting in VolumeMounts.\\nDefault false."', args=[d.arg(name='readOnly', type=d.T.boolean)]),
                withReadOnly(readOnly): { persistentVolumeClaim+: { readOnly: readOnly } },
              },
              '#photonPersistentDisk':: d.obj(help='"photonPersistentDisk represents a PhotonController persistent disk attached and mounted on kubelets host machine.\\nDeprecated: PhotonPersistentDisk is deprecated and the in-tree photonPersistentDisk type is no longer supported."'),
              photonPersistentDisk: {
                '#withFsType':: d.fn(help='"fsType is the filesystem type to mount.\\nMust be a filesystem type supported by the host operating system.\\nEx. \\"ext4\\", \\"xfs\\", \\"ntfs\\". Implicitly inferred to be \\"ext4\\" if unspecified."', args=[d.arg(name='fsType', type=d.T.string)]),
                withFsType(fsType): { photonPersistentDisk+: { fsType: fsType } },
                '#withPdID':: d.fn(help='"pdID is the ID that identifies Photon Controller persistent disk"', args=[d.arg(name='pdID', type=d.T.string)]),
                withPdID(pdID): { photonPersistentDisk+: { pdID: pdID } },
              },
              '#portworxVolume':: d.obj(help='"portworxVolume represents a portworx volume attached and mounted on kubelets host machine.\\nDeprecated: PortworxVolume is deprecated. All operations for the in-tree portworxVolume type\\nare redirected to the pxd.portworx.com CSI driver when the CSIMigrationPortworx feature-gate\\nis on."'),
              portworxVolume: {
                '#withFsType':: d.fn(help='"fSType represents the filesystem type to mount\\nMust be a filesystem type supported by the host operating system.\\nEx. \\"ext4\\", \\"xfs\\". Implicitly inferred to be \\"ext4\\" if unspecified."', args=[d.arg(name='fsType', type=d.T.string)]),
                withFsType(fsType): { portworxVolume+: { fsType: fsType } },
                '#withReadOnly':: d.fn(help='"readOnly defaults to false (read/write). ReadOnly here will force\\nthe ReadOnly setting in VolumeMounts."', args=[d.arg(name='readOnly', type=d.T.boolean)]),
                withReadOnly(readOnly): { portworxVolume+: { readOnly: readOnly } },
                '#withVolumeID':: d.fn(help='"volumeID uniquely identifies a Portworx volume"', args=[d.arg(name='volumeID', type=d.T.string)]),
                withVolumeID(volumeID): { portworxVolume+: { volumeID: volumeID } },
              },
              '#projected':: d.obj(help='"projected items for all in one resources secrets, configmaps, and downward API"'),
              projected: {
                '#sources':: d.obj(help='"sources is the list of volume projections. Each entry in this list\\nhandles one source."'),
                sources: {
                  '#clusterTrustBundle':: d.obj(help='"ClusterTrustBundle allows a pod to access the `.spec.trustBundle` field\\nof ClusterTrustBundle objects in an auto-updating file.\\n\\nAlpha, gated by the ClusterTrustBundleProjection feature gate.\\n\\nClusterTrustBundle objects can either be selected by name, or by the\\ncombination of signer name and a label selector.\\n\\nKubelet performs aggressive normalization of the PEM contents written\\ninto the pod filesystem.  Esoteric PEM features such as inter-block\\ncomments and block headers are stripped.  Certificates are deduplicated.\\nThe ordering of certificates within the file is arbitrary, and Kubelet\\nmay change the order over time."'),
                  clusterTrustBundle: {
                    '#labelSelector':: d.obj(help='"Select all ClusterTrustBundles that match this label selector.  Only has\\neffect if signerName is set.  Mutually-exclusive with name.  If unset,\\ninterpreted as \\"match nothing\\".  If set but empty, interpreted as \\"match\\neverything\\"."'),
                    labelSelector: {
                      '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                      matchExpressions: {
                        '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                        withKey(key): { key: key },
                        '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                        withOperator(operator): { operator: operator },
                        '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                        withValues(values): { values: if std.isArray(v=values) then values else [values] },
                        '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                        withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                      },
                      '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                      withMatchExpressions(matchExpressions): { clusterTrustBundle+: { labelSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                      '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                      withMatchExpressionsMixin(matchExpressions): { clusterTrustBundle+: { labelSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                      '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                      withMatchLabels(matchLabels): { clusterTrustBundle+: { labelSelector+: { matchLabels: matchLabels } } },
                      '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                      withMatchLabelsMixin(matchLabels): { clusterTrustBundle+: { labelSelector+: { matchLabels+: matchLabels } } },
                    },
                    '#withName':: d.fn(help='"Select a single ClusterTrustBundle by object name.  Mutually-exclusive\\nwith signerName and labelSelector."', args=[d.arg(name='name', type=d.T.string)]),
                    withName(name): { clusterTrustBundle+: { name: name } },
                    '#withOptional':: d.fn(help="\"If true, don't block pod startup if the referenced ClusterTrustBundle(s)\\naren't available.  If using name, then the named ClusterTrustBundle is\\nallowed not to exist.  If using signerName, then the combination of\\nsignerName and labelSelector is allowed to match zero\\nClusterTrustBundles.\"", args=[d.arg(name='optional', type=d.T.boolean)]),
                    withOptional(optional): { clusterTrustBundle+: { optional: optional } },
                    '#withPath':: d.fn(help='"Relative path from the volume root to write the bundle."', args=[d.arg(name='path', type=d.T.string)]),
                    withPath(path): { clusterTrustBundle+: { path: path } },
                    '#withSignerName':: d.fn(help='"Select all ClusterTrustBundles that match this signer name.\\nMutually-exclusive with name.  The contents of all selected\\nClusterTrustBundles will be unified and deduplicated."', args=[d.arg(name='signerName', type=d.T.string)]),
                    withSignerName(signerName): { clusterTrustBundle+: { signerName: signerName } },
                  },
                  '#configMap':: d.obj(help='"configMap information about the configMap data to project"'),
                  configMap: {
                    '#items':: d.obj(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nConfigMap will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the ConfigMap,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\""),
                    items: {
                      '#withKey':: d.fn(help='"key is the key to project."', args=[d.arg(name='key', type=d.T.string)]),
                      withKey(key): { key: key },
                      '#withMode':: d.fn(help='"mode is Optional: mode bits used to set permissions on this file.\\nMust be an octal value between 0000 and 0777 or a decimal value between 0 and 511.\\nYAML accepts both octal and decimal values, JSON requires decimal values for mode bits.\\nIf not specified, the volume defaultMode will be used.\\nThis might be in conflict with other options that affect the file\\nmode, like fsGroup, and the result can be other mode bits set."', args=[d.arg(name='mode', type=d.T.integer)]),
                      withMode(mode): { mode: mode },
                      '#withPath':: d.fn(help="\"path is the relative path of the file to map the key to.\\nMay not be an absolute path.\\nMay not contain the path element '..'.\\nMay not start with the string '..'.\"", args=[d.arg(name='path', type=d.T.string)]),
                      withPath(path): { path: path },
                    },
                    '#withItems':: d.fn(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nConfigMap will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the ConfigMap,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\"", args=[d.arg(name='items', type=d.T.array)]),
                    withItems(items): { configMap+: { items: if std.isArray(v=items) then items else [items] } },
                    '#withItemsMixin':: d.fn(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nConfigMap will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the ConfigMap,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='items', type=d.T.array)]),
                    withItemsMixin(items): { configMap+: { items+: if std.isArray(v=items) then items else [items] } },
                    '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
                    withName(name): { configMap+: { name: name } },
                    '#withOptional':: d.fn(help='"optional specify whether the ConfigMap or its keys must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
                    withOptional(optional): { configMap+: { optional: optional } },
                  },
                  '#downwardAPI':: d.obj(help='"downwardAPI information about the downwardAPI data to project"'),
                  downwardAPI: {
                    '#items':: d.obj(help='"Items is a list of DownwardAPIVolume file"'),
                    items: {
                      '#fieldRef':: d.obj(help='"Required: Selects a field of the pod: only annotations, labels, name, namespace and uid are supported."'),
                      fieldRef: {
                        '#withApiVersion':: d.fn(help='"Version of the schema the FieldPath is written in terms of, defaults to \\"v1\\"."', args=[d.arg(name='apiVersion', type=d.T.string)]),
                        withApiVersion(apiVersion): { fieldRef+: { apiVersion: apiVersion } },
                        '#withFieldPath':: d.fn(help='"Path of the field to select in the specified API version."', args=[d.arg(name='fieldPath', type=d.T.string)]),
                        withFieldPath(fieldPath): { fieldRef+: { fieldPath: fieldPath } },
                      },
                      '#resourceFieldRef':: d.obj(help='"Selects a resource of the container: only resources limits and requests\\n(limits.cpu, limits.memory, requests.cpu and requests.memory) are currently supported."'),
                      resourceFieldRef: {
                        '#withContainerName':: d.fn(help='"Container name: required for volumes, optional for env vars"', args=[d.arg(name='containerName', type=d.T.string)]),
                        withContainerName(containerName): { resourceFieldRef+: { containerName: containerName } },
                        '#withDivisor':: d.fn(help='"Specifies the output format of the exposed resources, defaults to \\"1\\', args=[d.arg(name='divisor', type=d.T.any)]),
                        withDivisor(divisor): { resourceFieldRef+: { divisor: divisor } },
                        '#withResource':: d.fn(help='"Required: resource to select"', args=[d.arg(name='resource', type=d.T.string)]),
                        withResource(resource): { resourceFieldRef+: { resource: resource } },
                      },
                      '#withMode':: d.fn(help='"Optional: mode bits used to set permissions on this file, must be an octal value\\nbetween 0000 and 0777 or a decimal value between 0 and 511.\\nYAML accepts both octal and decimal values, JSON requires decimal values for mode bits.\\nIf not specified, the volume defaultMode will be used.\\nThis might be in conflict with other options that affect the file\\nmode, like fsGroup, and the result can be other mode bits set."', args=[d.arg(name='mode', type=d.T.integer)]),
                      withMode(mode): { mode: mode },
                      '#withPath':: d.fn(help="\"Required: Path is  the relative path name of the file to be created. Must not be absolute or contain the '..' path. Must be utf-8 encoded. The first item of the relative path must not start with '..'\"", args=[d.arg(name='path', type=d.T.string)]),
                      withPath(path): { path: path },
                    },
                    '#withItems':: d.fn(help='"Items is a list of DownwardAPIVolume file"', args=[d.arg(name='items', type=d.T.array)]),
                    withItems(items): { downwardAPI+: { items: if std.isArray(v=items) then items else [items] } },
                    '#withItemsMixin':: d.fn(help='"Items is a list of DownwardAPIVolume file"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='items', type=d.T.array)]),
                    withItemsMixin(items): { downwardAPI+: { items+: if std.isArray(v=items) then items else [items] } },
                  },
                  '#secret':: d.obj(help='"secret information about the secret data to project"'),
                  secret: {
                    '#items':: d.obj(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nSecret will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the Secret,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\""),
                    items: {
                      '#withKey':: d.fn(help='"key is the key to project."', args=[d.arg(name='key', type=d.T.string)]),
                      withKey(key): { key: key },
                      '#withMode':: d.fn(help='"mode is Optional: mode bits used to set permissions on this file.\\nMust be an octal value between 0000 and 0777 or a decimal value between 0 and 511.\\nYAML accepts both octal and decimal values, JSON requires decimal values for mode bits.\\nIf not specified, the volume defaultMode will be used.\\nThis might be in conflict with other options that affect the file\\nmode, like fsGroup, and the result can be other mode bits set."', args=[d.arg(name='mode', type=d.T.integer)]),
                      withMode(mode): { mode: mode },
                      '#withPath':: d.fn(help="\"path is the relative path of the file to map the key to.\\nMay not be an absolute path.\\nMay not contain the path element '..'.\\nMay not start with the string '..'.\"", args=[d.arg(name='path', type=d.T.string)]),
                      withPath(path): { path: path },
                    },
                    '#withItems':: d.fn(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nSecret will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the Secret,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\"", args=[d.arg(name='items', type=d.T.array)]),
                    withItems(items): { secret+: { items: if std.isArray(v=items) then items else [items] } },
                    '#withItemsMixin':: d.fn(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nSecret will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the Secret,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='items', type=d.T.array)]),
                    withItemsMixin(items): { secret+: { items+: if std.isArray(v=items) then items else [items] } },
                    '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
                    withName(name): { secret+: { name: name } },
                    '#withOptional':: d.fn(help='"optional field specify whether the Secret or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
                    withOptional(optional): { secret+: { optional: optional } },
                  },
                  '#serviceAccountToken':: d.obj(help='"serviceAccountToken is information about the serviceAccountToken data to project"'),
                  serviceAccountToken: {
                    '#withAudience':: d.fn(help='"audience is the intended audience of the token. A recipient of a token\\nmust identify itself with an identifier specified in the audience of the\\ntoken, and otherwise should reject the token. The audience defaults to the\\nidentifier of the apiserver."', args=[d.arg(name='audience', type=d.T.string)]),
                    withAudience(audience): { serviceAccountToken+: { audience: audience } },
                    '#withExpirationSeconds':: d.fn(help='"expirationSeconds is the requested duration of validity of the service\\naccount token. As the token approaches expiration, the kubelet volume\\nplugin will proactively rotate the service account token. The kubelet will\\nstart trying to rotate the token if the token is older than 80 percent of\\nits time to live or if the token is older than 24 hours.Defaults to 1 hour\\nand must be at least 10 minutes."', args=[d.arg(name='expirationSeconds', type=d.T.integer)]),
                    withExpirationSeconds(expirationSeconds): { serviceAccountToken+: { expirationSeconds: expirationSeconds } },
                    '#withPath':: d.fn(help='"path is the path relative to the mount point of the file to project the\\ntoken into."', args=[d.arg(name='path', type=d.T.string)]),
                    withPath(path): { serviceAccountToken+: { path: path } },
                  },
                },
                '#withDefaultMode':: d.fn(help='"defaultMode are the mode bits used to set permissions on created files by default.\\nMust be an octal value between 0000 and 0777 or a decimal value between 0 and 511.\\nYAML accepts both octal and decimal values, JSON requires decimal values for mode bits.\\nDirectories within the path are not affected by this setting.\\nThis might be in conflict with other options that affect the file\\nmode, like fsGroup, and the result can be other mode bits set."', args=[d.arg(name='defaultMode', type=d.T.integer)]),
                withDefaultMode(defaultMode): { projected+: { defaultMode: defaultMode } },
                '#withSources':: d.fn(help='"sources is the list of volume projections. Each entry in this list\\nhandles one source."', args=[d.arg(name='sources', type=d.T.array)]),
                withSources(sources): { projected+: { sources: if std.isArray(v=sources) then sources else [sources] } },
                '#withSourcesMixin':: d.fn(help='"sources is the list of volume projections. Each entry in this list\\nhandles one source."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='sources', type=d.T.array)]),
                withSourcesMixin(sources): { projected+: { sources+: if std.isArray(v=sources) then sources else [sources] } },
              },
              '#quobyte':: d.obj(help="\"quobyte represents a Quobyte mount on the host that shares a pod's lifetime.\\nDeprecated: Quobyte is deprecated and the in-tree quobyte type is no longer supported.\""),
              quobyte: {
                '#withGroup':: d.fn(help='"group to map volume access to\\nDefault is no group"', args=[d.arg(name='group', type=d.T.string)]),
                withGroup(group): { quobyte+: { group: group } },
                '#withReadOnly':: d.fn(help='"readOnly here will force the Quobyte volume to be mounted with read-only permissions.\\nDefaults to false."', args=[d.arg(name='readOnly', type=d.T.boolean)]),
                withReadOnly(readOnly): { quobyte+: { readOnly: readOnly } },
                '#withRegistry':: d.fn(help='"registry represents a single or multiple Quobyte Registry services\\nspecified as a string as host:port pair (multiple entries are separated with commas)\\nwhich acts as the central registry for volumes"', args=[d.arg(name='registry', type=d.T.string)]),
                withRegistry(registry): { quobyte+: { registry: registry } },
                '#withTenant':: d.fn(help='"tenant owning the given Quobyte volume in the Backend\\nUsed with dynamically provisioned Quobyte volumes, value is set by the plugin"', args=[d.arg(name='tenant', type=d.T.string)]),
                withTenant(tenant): { quobyte+: { tenant: tenant } },
                '#withUser':: d.fn(help='"user to map volume access to\\nDefaults to serivceaccount user"', args=[d.arg(name='user', type=d.T.string)]),
                withUser(user): { quobyte+: { user: user } },
                '#withVolume':: d.fn(help='"volume is a string that references an already created Quobyte volume by name."', args=[d.arg(name='volume', type=d.T.string)]),
                withVolume(volume): { quobyte+: { volume: volume } },
              },
              '#rbd':: d.obj(help="\"rbd represents a Rados Block Device mount on the host that shares a pod's lifetime.\\nDeprecated: RBD is deprecated and the in-tree rbd type is no longer supported.\\nMore info: https://examples.k8s.io/volumes/rbd/README.md\""),
              rbd: {
                '#secretRef':: d.obj(help='"secretRef is name of the authentication secret for RBDUser. If provided\\noverrides keyring.\\nDefault is nil.\\nMore info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it"'),
                secretRef: {
                  '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
                  withName(name): { rbd+: { secretRef+: { name: name } } },
                },
                '#withFsType':: d.fn(help='"fsType is the filesystem type of the volume that you want to mount.\\nTip: Ensure that the filesystem type is supported by the host operating system.\\nExamples: \\"ext4\\", \\"xfs\\", \\"ntfs\\". Implicitly inferred to be \\"ext4\\" if unspecified.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#rbd"', args=[d.arg(name='fsType', type=d.T.string)]),
                withFsType(fsType): { rbd+: { fsType: fsType } },
                '#withImage':: d.fn(help='"image is the rados image name.\\nMore info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it"', args=[d.arg(name='image', type=d.T.string)]),
                withImage(image): { rbd+: { image: image } },
                '#withKeyring':: d.fn(help='"keyring is the path to key ring for RBDUser.\\nDefault is /etc/ceph/keyring.\\nMore info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it"', args=[d.arg(name='keyring', type=d.T.string)]),
                withKeyring(keyring): { rbd+: { keyring: keyring } },
                '#withMonitors':: d.fn(help='"monitors is a collection of Ceph monitors.\\nMore info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it"', args=[d.arg(name='monitors', type=d.T.array)]),
                withMonitors(monitors): { rbd+: { monitors: if std.isArray(v=monitors) then monitors else [monitors] } },
                '#withMonitorsMixin':: d.fn(help='"monitors is a collection of Ceph monitors.\\nMore info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='monitors', type=d.T.array)]),
                withMonitorsMixin(monitors): { rbd+: { monitors+: if std.isArray(v=monitors) then monitors else [monitors] } },
                '#withPool':: d.fn(help='"pool is the rados pool name.\\nDefault is rbd.\\nMore info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it"', args=[d.arg(name='pool', type=d.T.string)]),
                withPool(pool): { rbd+: { pool: pool } },
                '#withReadOnly':: d.fn(help='"readOnly here will force the ReadOnly setting in VolumeMounts.\\nDefaults to false.\\nMore info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it"', args=[d.arg(name='readOnly', type=d.T.boolean)]),
                withReadOnly(readOnly): { rbd+: { readOnly: readOnly } },
                '#withUser':: d.fn(help='"user is the rados user name.\\nDefault is admin.\\nMore info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it"', args=[d.arg(name='user', type=d.T.string)]),
                withUser(user): { rbd+: { user: user } },
              },
              '#scaleIO':: d.obj(help='"scaleIO represents a ScaleIO persistent volume attached and mounted on Kubernetes nodes.\\nDeprecated: ScaleIO is deprecated and the in-tree scaleIO type is no longer supported."'),
              scaleIO: {
                '#secretRef':: d.obj(help='"secretRef references to the secret for ScaleIO user and other\\nsensitive information. If this is not provided, Login operation will fail."'),
                secretRef: {
                  '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
                  withName(name): { scaleIO+: { secretRef+: { name: name } } },
                },
                '#withFsType':: d.fn(help='"fsType is the filesystem type to mount.\\nMust be a filesystem type supported by the host operating system.\\nEx. \\"ext4\\", \\"xfs\\", \\"ntfs\\".\\nDefault is \\"xfs\\"."', args=[d.arg(name='fsType', type=d.T.string)]),
                withFsType(fsType): { scaleIO+: { fsType: fsType } },
                '#withGateway':: d.fn(help='"gateway is the host address of the ScaleIO API Gateway."', args=[d.arg(name='gateway', type=d.T.string)]),
                withGateway(gateway): { scaleIO+: { gateway: gateway } },
                '#withProtectionDomain':: d.fn(help='"protectionDomain is the name of the ScaleIO Protection Domain for the configured storage."', args=[d.arg(name='protectionDomain', type=d.T.string)]),
                withProtectionDomain(protectionDomain): { scaleIO+: { protectionDomain: protectionDomain } },
                '#withReadOnly':: d.fn(help='"readOnly Defaults to false (read/write). ReadOnly here will force\\nthe ReadOnly setting in VolumeMounts."', args=[d.arg(name='readOnly', type=d.T.boolean)]),
                withReadOnly(readOnly): { scaleIO+: { readOnly: readOnly } },
                '#withSslEnabled':: d.fn(help='"sslEnabled Flag enable/disable SSL communication with Gateway, default false"', args=[d.arg(name='sslEnabled', type=d.T.boolean)]),
                withSslEnabled(sslEnabled): { scaleIO+: { sslEnabled: sslEnabled } },
                '#withStorageMode':: d.fn(help='"storageMode indicates whether the storage for a volume should be ThickProvisioned or ThinProvisioned.\\nDefault is ThinProvisioned."', args=[d.arg(name='storageMode', type=d.T.string)]),
                withStorageMode(storageMode): { scaleIO+: { storageMode: storageMode } },
                '#withStoragePool':: d.fn(help='"storagePool is the ScaleIO Storage Pool associated with the protection domain."', args=[d.arg(name='storagePool', type=d.T.string)]),
                withStoragePool(storagePool): { scaleIO+: { storagePool: storagePool } },
                '#withSystem':: d.fn(help='"system is the name of the storage system as configured in ScaleIO."', args=[d.arg(name='system', type=d.T.string)]),
                withSystem(system): { scaleIO+: { system: system } },
                '#withVolumeName':: d.fn(help='"volumeName is the name of a volume already created in the ScaleIO system\\nthat is associated with this volume source."', args=[d.arg(name='volumeName', type=d.T.string)]),
                withVolumeName(volumeName): { scaleIO+: { volumeName: volumeName } },
              },
              '#secret':: d.obj(help='"secret represents a secret that should populate this volume.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#secret"'),
              secret: {
                '#items':: d.obj(help="\"items If unspecified, each key-value pair in the Data field of the referenced\\nSecret will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the Secret,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\""),
                items: {
                  '#withKey':: d.fn(help='"key is the key to project."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { key: key },
                  '#withMode':: d.fn(help='"mode is Optional: mode bits used to set permissions on this file.\\nMust be an octal value between 0000 and 0777 or a decimal value between 0 and 511.\\nYAML accepts both octal and decimal values, JSON requires decimal values for mode bits.\\nIf not specified, the volume defaultMode will be used.\\nThis might be in conflict with other options that affect the file\\nmode, like fsGroup, and the result can be other mode bits set."', args=[d.arg(name='mode', type=d.T.integer)]),
                  withMode(mode): { mode: mode },
                  '#withPath':: d.fn(help="\"path is the relative path of the file to map the key to.\\nMay not be an absolute path.\\nMay not contain the path element '..'.\\nMay not start with the string '..'.\"", args=[d.arg(name='path', type=d.T.string)]),
                  withPath(path): { path: path },
                },
                '#withDefaultMode':: d.fn(help='"defaultMode is Optional: mode bits used to set permissions on created files by default.\\nMust be an octal value between 0000 and 0777 or a decimal value between 0 and 511.\\nYAML accepts both octal and decimal values, JSON requires decimal values\\nfor mode bits. Defaults to 0644.\\nDirectories within the path are not affected by this setting.\\nThis might be in conflict with other options that affect the file\\nmode, like fsGroup, and the result can be other mode bits set."', args=[d.arg(name='defaultMode', type=d.T.integer)]),
                withDefaultMode(defaultMode): { secret+: { defaultMode: defaultMode } },
                '#withItems':: d.fn(help="\"items If unspecified, each key-value pair in the Data field of the referenced\\nSecret will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the Secret,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\"", args=[d.arg(name='items', type=d.T.array)]),
                withItems(items): { secret+: { items: if std.isArray(v=items) then items else [items] } },
                '#withItemsMixin':: d.fn(help="\"items If unspecified, each key-value pair in the Data field of the referenced\\nSecret will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the Secret,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='items', type=d.T.array)]),
                withItemsMixin(items): { secret+: { items+: if std.isArray(v=items) then items else [items] } },
                '#withOptional':: d.fn(help='"optional field specify whether the Secret or its keys must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
                withOptional(optional): { secret+: { optional: optional } },
                '#withSecretName':: d.fn(help="\"secretName is the name of the secret in the pod's namespace to use.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#secret\"", args=[d.arg(name='secretName', type=d.T.string)]),
                withSecretName(secretName): { secret+: { secretName: secretName } },
              },
              '#storageos':: d.obj(help='"storageOS represents a StorageOS volume attached and mounted on Kubernetes nodes.\\nDeprecated: StorageOS is deprecated and the in-tree storageos type is no longer supported."'),
              storageos: {
                '#secretRef':: d.obj(help='"secretRef specifies the secret to use for obtaining the StorageOS API\\ncredentials.  If not specified, default values will be attempted."'),
                secretRef: {
                  '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
                  withName(name): { storageos+: { secretRef+: { name: name } } },
                },
                '#withFsType':: d.fn(help='"fsType is the filesystem type to mount.\\nMust be a filesystem type supported by the host operating system.\\nEx. \\"ext4\\", \\"xfs\\", \\"ntfs\\". Implicitly inferred to be \\"ext4\\" if unspecified."', args=[d.arg(name='fsType', type=d.T.string)]),
                withFsType(fsType): { storageos+: { fsType: fsType } },
                '#withReadOnly':: d.fn(help='"readOnly defaults to false (read/write). ReadOnly here will force\\nthe ReadOnly setting in VolumeMounts."', args=[d.arg(name='readOnly', type=d.T.boolean)]),
                withReadOnly(readOnly): { storageos+: { readOnly: readOnly } },
                '#withVolumeName':: d.fn(help='"volumeName is the human-readable name of the StorageOS volume.  Volume\\nnames are only unique within a namespace."', args=[d.arg(name='volumeName', type=d.T.string)]),
                withVolumeName(volumeName): { storageos+: { volumeName: volumeName } },
                '#withVolumeNamespace':: d.fn(help="\"volumeNamespace specifies the scope of the volume within StorageOS.  If no\\nnamespace is specified then the Pod's namespace will be used.  This allows the\\nKubernetes name scoping to be mirrored within StorageOS for tighter integration.\\nSet VolumeName to any name to override the default behaviour.\\nSet to \\\"default\\\" if you are not using namespaces within StorageOS.\\nNamespaces that do not pre-exist within StorageOS will be created.\"", args=[d.arg(name='volumeNamespace', type=d.T.string)]),
                withVolumeNamespace(volumeNamespace): { storageos+: { volumeNamespace: volumeNamespace } },
              },
              '#vsphereVolume':: d.obj(help='"vsphereVolume represents a vSphere volume attached and mounted on kubelets host machine.\\nDeprecated: VsphereVolume is deprecated. All operations for the in-tree vsphereVolume type\\nare redirected to the csi.vsphere.vmware.com CSI driver."'),
              vsphereVolume: {
                '#withFsType':: d.fn(help='"fsType is filesystem type to mount.\\nMust be a filesystem type supported by the host operating system.\\nEx. \\"ext4\\", \\"xfs\\", \\"ntfs\\". Implicitly inferred to be \\"ext4\\" if unspecified."', args=[d.arg(name='fsType', type=d.T.string)]),
                withFsType(fsType): { vsphereVolume+: { fsType: fsType } },
                '#withStoragePolicyID':: d.fn(help='"storagePolicyID is the storage Policy Based Management (SPBM) profile ID associated with the StoragePolicyName."', args=[d.arg(name='storagePolicyID', type=d.T.string)]),
                withStoragePolicyID(storagePolicyID): { vsphereVolume+: { storagePolicyID: storagePolicyID } },
                '#withStoragePolicyName':: d.fn(help='"storagePolicyName is the storage Policy Based Management (SPBM) profile name."', args=[d.arg(name='storagePolicyName', type=d.T.string)]),
                withStoragePolicyName(storagePolicyName): { vsphereVolume+: { storagePolicyName: storagePolicyName } },
                '#withVolumePath':: d.fn(help='"volumePath is the path that identifies vSphere volume vmdk"', args=[d.arg(name='volumePath', type=d.T.string)]),
                withVolumePath(volumePath): { vsphereVolume+: { volumePath: volumePath } },
              },
              '#withName':: d.fn(help='"name of the volume.\\nMust be a DNS_LABEL and unique within the pod.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { name: name },
            },
            '#withAnnotations':: d.fn(help='"Annotations are the annotations that should be appended to the pods.\\nBy default, no pod annotations are appended."', args=[d.arg(name='annotations', type=d.T.object)]),
            withAnnotations(annotations): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { pod+: { annotations: annotations } } } } } },
            '#withAnnotationsMixin':: d.fn(help='"Annotations are the annotations that should be appended to the pods.\\nBy default, no pod annotations are appended."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='annotations', type=d.T.object)]),
            withAnnotationsMixin(annotations): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { pod+: { annotations+: annotations } } } } } },
            '#withImagePullSecrets':: d.fn(help='"ImagePullSecrets is an optional list of references to secrets\\nin the same namespace to use for pulling any of the images used by this PodSpec.\\nIf specified, these secrets will be passed to individual puller implementations for them to use.\\nMore info: https://kubernetes.io/docs/concepts/containers/images#specifying-imagepullsecrets-on-a-pod"', args=[d.arg(name='imagePullSecrets', type=d.T.array)]),
            withImagePullSecrets(imagePullSecrets): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { pod+: { imagePullSecrets: if std.isArray(v=imagePullSecrets) then imagePullSecrets else [imagePullSecrets] } } } } } },
            '#withImagePullSecretsMixin':: d.fn(help='"ImagePullSecrets is an optional list of references to secrets\\nin the same namespace to use for pulling any of the images used by this PodSpec.\\nIf specified, these secrets will be passed to individual puller implementations for them to use.\\nMore info: https://kubernetes.io/docs/concepts/containers/images#specifying-imagepullsecrets-on-a-pod"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='imagePullSecrets', type=d.T.array)]),
            withImagePullSecretsMixin(imagePullSecrets): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { pod+: { imagePullSecrets+: if std.isArray(v=imagePullSecrets) then imagePullSecrets else [imagePullSecrets] } } } } } },
            '#withLabels':: d.fn(help='"Labels are the additional labels that should be tagged to the pods.\\nBy default, no additional pod labels are tagged."', args=[d.arg(name='labels', type=d.T.object)]),
            withLabels(labels): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { pod+: { labels: labels } } } } } },
            '#withLabelsMixin':: d.fn(help='"Labels are the additional labels that should be tagged to the pods.\\nBy default, no additional pod labels are tagged."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labels', type=d.T.object)]),
            withLabelsMixin(labels): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { pod+: { labels+: labels } } } } } },
            '#withNodeSelector':: d.fn(help="\"NodeSelector is a selector which must be true for the pod to fit on a node.\\nSelector which must match a node's labels for the pod to be scheduled on that node.\\nMore info: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\"", args=[d.arg(name='nodeSelector', type=d.T.object)]),
            withNodeSelector(nodeSelector): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { pod+: { nodeSelector: nodeSelector } } } } } },
            '#withNodeSelectorMixin':: d.fn(help="\"NodeSelector is a selector which must be true for the pod to fit on a node.\\nSelector which must match a node's labels for the pod to be scheduled on that node.\\nMore info: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='nodeSelector', type=d.T.object)]),
            withNodeSelectorMixin(nodeSelector): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { pod+: { nodeSelector+: nodeSelector } } } } } },
            '#withTolerations':: d.fn(help="\"If specified, the pod's tolerations.\"", args=[d.arg(name='tolerations', type=d.T.array)]),
            withTolerations(tolerations): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { pod+: { tolerations: if std.isArray(v=tolerations) then tolerations else [tolerations] } } } } } },
            '#withTolerationsMixin':: d.fn(help="\"If specified, the pod's tolerations.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='tolerations', type=d.T.array)]),
            withTolerationsMixin(tolerations): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { pod+: { tolerations+: if std.isArray(v=tolerations) then tolerations else [tolerations] } } } } } },
            '#withTopologySpreadConstraints':: d.fn(help='"TopologySpreadConstraints describes how a group of pods ought to spread across topology\\ndomains. Scheduler will schedule pods in a way which abides by the constraints.\\nAll topologySpreadConstraints are ANDed."', args=[d.arg(name='topologySpreadConstraints', type=d.T.array)]),
            withTopologySpreadConstraints(topologySpreadConstraints): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { pod+: { topologySpreadConstraints: if std.isArray(v=topologySpreadConstraints) then topologySpreadConstraints else [topologySpreadConstraints] } } } } } },
            '#withTopologySpreadConstraintsMixin':: d.fn(help='"TopologySpreadConstraints describes how a group of pods ought to spread across topology\\ndomains. Scheduler will schedule pods in a way which abides by the constraints.\\nAll topologySpreadConstraints are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='topologySpreadConstraints', type=d.T.array)]),
            withTopologySpreadConstraintsMixin(topologySpreadConstraints): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { pod+: { topologySpreadConstraints+: if std.isArray(v=topologySpreadConstraints) then topologySpreadConstraints else [topologySpreadConstraints] } } } } } },
            '#withVolumes':: d.fn(help='"Volumes that can be mounted by containers belonging to the pod.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes"', args=[d.arg(name='volumes', type=d.T.array)]),
            withVolumes(volumes): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { pod+: { volumes: if std.isArray(v=volumes) then volumes else [volumes] } } } } } },
            '#withVolumesMixin':: d.fn(help='"Volumes that can be mounted by containers belonging to the pod.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='volumes', type=d.T.array)]),
            withVolumesMixin(volumes): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { pod+: { volumes+: if std.isArray(v=volumes) then volumes else [volumes] } } } } } },
          },
          '#strategy':: d.obj(help='"The deployment strategy to use to replace existing pods with new ones."'),
          strategy: {
            '#rollingUpdate':: d.obj(help='"Rolling update config params. Present only if DeploymentStrategyType =\\nRollingUpdate."'),
            rollingUpdate: {
              '#withMaxSurge':: d.fn(help='"The maximum number of pods that can be scheduled above the desired number of\\npods.\\nValue can be an absolute number (ex: 5) or a percentage of desired pods (ex: 10%).\\nThis can not be 0 if MaxUnavailable is 0.\\nAbsolute number is calculated from percentage by rounding up.\\nDefaults to 25%.\\nExample: when this is set to 30%, the new ReplicaSet can be scaled up immediately when\\nthe rolling update starts, such that the total number of old and new pods do not exceed\\n130% of desired pods. Once old pods have been killed,\\nnew ReplicaSet can be scaled up further, ensuring that total number of pods running\\nat any time during the update is at most 130% of desired pods."', args=[d.arg(name='maxSurge', type=d.T.any)]),
              withMaxSurge(maxSurge): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { strategy+: { rollingUpdate+: { maxSurge: maxSurge } } } } } } },
              '#withMaxUnavailable':: d.fn(help='"The maximum number of pods that can be unavailable during the update.\\nValue can be an absolute number (ex: 5) or a percentage of desired pods (ex: 10%).\\nAbsolute number is calculated from percentage by rounding down.\\nThis can not be 0 if MaxSurge is 0.\\nDefaults to 25%.\\nExample: when this is set to 30%, the old ReplicaSet can be scaled down to 70% of desired pods\\nimmediately when the rolling update starts. Once new pods are ready, old ReplicaSet\\ncan be scaled down further, followed by scaling up the new ReplicaSet, ensuring\\nthat the total number of pods available at all times during the update is at\\nleast 70% of desired pods."', args=[d.arg(name='maxUnavailable', type=d.T.any)]),
              withMaxUnavailable(maxUnavailable): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { strategy+: { rollingUpdate+: { maxUnavailable: maxUnavailable } } } } } } },
            },
            '#withType':: d.fn(help='"Type of deployment. Can be \\"Recreate\\" or \\"RollingUpdate\\". Default is RollingUpdate."', args=[d.arg(name='type', type=d.T.string)]),
            withType(type): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { strategy+: { type: type } } } } } },
          },
          '#withInitContainers':: d.fn(help='"List of initialization containers belonging to the pod.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/init-containers/"', args=[d.arg(name='initContainers', type=d.T.array)]),
          withInitContainers(initContainers): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { initContainers: if std.isArray(v=initContainers) then initContainers else [initContainers] } } } } },
          '#withInitContainersMixin':: d.fn(help='"List of initialization containers belonging to the pod.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/init-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='initContainers', type=d.T.array)]),
          withInitContainersMixin(initContainers): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { initContainers+: if std.isArray(v=initContainers) then initContainers else [initContainers] } } } } },
          '#withName':: d.fn(help='"Name of the deployment.\\nWhen unset, this defaults to an autogenerated name."', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { name: name } } } } },
          '#withReplicas':: d.fn(help='"Replicas is the number of desired pods. Defaults to 1."', args=[d.arg(name='replicas', type=d.T.integer)]),
          withReplicas(replicas): { spec+: { provider+: { kubernetes+: { envoyDeployment+: { replicas: replicas } } } } },
        },
        '#envoyHpa':: d.obj(help='"EnvoyHpa defines the Horizontal Pod Autoscaler settings for Envoy Proxy Deployment."'),
        envoyHpa: {
          '#behavior':: d.obj(help='"behavior configures the scaling behavior of the target\\nin both Up and Down directions (scaleUp and scaleDown fields respectively).\\nIf not set, the default HPAScalingRules for scale up and scale down are used.\\nSee k8s.io.autoscaling.v2.HorizontalPodAutoScalerBehavior."'),
          behavior: {
            '#scaleDown':: d.obj(help='"scaleDown is scaling policy for scaling Down.\\nIf not set, the default value is to allow to scale down to minReplicas pods, with a\\n300 second stabilization window (i.e., the highest recommendation for\\nthe last 300sec is used)."'),
            scaleDown: {
              '#policies':: d.obj(help='"policies is a list of potential scaling polices which can be used during scaling.\\nIf not set, use the default values:\\n- For scale up: allow doubling the number of pods, or an absolute change of 4 pods in a 15s window.\\n- For scale down: allow all pods to be removed in a 15s window."'),
              policies: {
                '#withPeriodSeconds':: d.fn(help='"periodSeconds specifies the window of time for which the policy should hold true.\\nPeriodSeconds must be greater than zero and less than or equal to 1800 (30 min)."', args=[d.arg(name='periodSeconds', type=d.T.integer)]),
                withPeriodSeconds(periodSeconds): { periodSeconds: periodSeconds },
                '#withType':: d.fn(help='"type is used to specify the scaling policy."', args=[d.arg(name='type', type=d.T.string)]),
                withType(type): { type: type },
                '#withValue':: d.fn(help='"value contains the amount of change which is permitted by the policy.\\nIt must be greater than zero"', args=[d.arg(name='value', type=d.T.integer)]),
                withValue(value): { value: value },
              },
              '#withPolicies':: d.fn(help='"policies is a list of potential scaling polices which can be used during scaling.\\nIf not set, use the default values:\\n- For scale up: allow doubling the number of pods, or an absolute change of 4 pods in a 15s window.\\n- For scale down: allow all pods to be removed in a 15s window."', args=[d.arg(name='policies', type=d.T.array)]),
              withPolicies(policies): { spec+: { provider+: { kubernetes+: { envoyHpa+: { behavior+: { scaleDown+: { policies: if std.isArray(v=policies) then policies else [policies] } } } } } } },
              '#withPoliciesMixin':: d.fn(help='"policies is a list of potential scaling polices which can be used during scaling.\\nIf not set, use the default values:\\n- For scale up: allow doubling the number of pods, or an absolute change of 4 pods in a 15s window.\\n- For scale down: allow all pods to be removed in a 15s window."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='policies', type=d.T.array)]),
              withPoliciesMixin(policies): { spec+: { provider+: { kubernetes+: { envoyHpa+: { behavior+: { scaleDown+: { policies+: if std.isArray(v=policies) then policies else [policies] } } } } } } },
              '#withSelectPolicy':: d.fn(help='"selectPolicy is used to specify which policy should be used.\\nIf not set, the default value Max is used."', args=[d.arg(name='selectPolicy', type=d.T.string)]),
              withSelectPolicy(selectPolicy): { spec+: { provider+: { kubernetes+: { envoyHpa+: { behavior+: { scaleDown+: { selectPolicy: selectPolicy } } } } } } },
              '#withStabilizationWindowSeconds':: d.fn(help='"stabilizationWindowSeconds is the number of seconds for which past recommendations should be\\nconsidered while scaling up or scaling down.\\nStabilizationWindowSeconds must be greater than or equal to zero and less than or equal to 3600 (one hour).\\nIf not set, use the default values:\\n- For scale up: 0 (i.e. no stabilization is done).\\n- For scale down: 300 (i.e. the stabilization window is 300 seconds long)."', args=[d.arg(name='stabilizationWindowSeconds', type=d.T.integer)]),
              withStabilizationWindowSeconds(stabilizationWindowSeconds): { spec+: { provider+: { kubernetes+: { envoyHpa+: { behavior+: { scaleDown+: { stabilizationWindowSeconds: stabilizationWindowSeconds } } } } } } },
              '#withTolerance':: d.fn(help='"tolerance is the tolerance on the ratio between the current and desired\\nmetric value under which no updates are made to the desired number of\\nreplicas (e.g. 0.01 for 1%). Must be greater than or equal to zero. If not\\nset, the default cluster-wide tolerance is applied (by default 10%).\\n\\nFor example, if autoscaling is configured with a memory consumption target of 100Mi,\\nand scale-down and scale-up tolerances of 5% and 1% respectively, scaling will be\\ntriggered when the actual consumption falls below 95Mi or exceeds 101Mi.\\n\\nThis is an alpha field and requires enabling the HPAConfigurableTolerance\\nfeature gate."', args=[d.arg(name='tolerance', type=d.T.any)]),
              withTolerance(tolerance): { spec+: { provider+: { kubernetes+: { envoyHpa+: { behavior+: { scaleDown+: { tolerance: tolerance } } } } } } },
            },
            '#scaleUp':: d.obj(help='"scaleUp is scaling policy for scaling Up.\\nIf not set, the default value is the higher of:\\n  * increase no more than 4 pods per 60 seconds\\n  * double the number of pods per 60 seconds\\nNo stabilization is used."'),
            scaleUp: {
              '#policies':: d.obj(help='"policies is a list of potential scaling polices which can be used during scaling.\\nIf not set, use the default values:\\n- For scale up: allow doubling the number of pods, or an absolute change of 4 pods in a 15s window.\\n- For scale down: allow all pods to be removed in a 15s window."'),
              policies: {
                '#withPeriodSeconds':: d.fn(help='"periodSeconds specifies the window of time for which the policy should hold true.\\nPeriodSeconds must be greater than zero and less than or equal to 1800 (30 min)."', args=[d.arg(name='periodSeconds', type=d.T.integer)]),
                withPeriodSeconds(periodSeconds): { periodSeconds: periodSeconds },
                '#withType':: d.fn(help='"type is used to specify the scaling policy."', args=[d.arg(name='type', type=d.T.string)]),
                withType(type): { type: type },
                '#withValue':: d.fn(help='"value contains the amount of change which is permitted by the policy.\\nIt must be greater than zero"', args=[d.arg(name='value', type=d.T.integer)]),
                withValue(value): { value: value },
              },
              '#withPolicies':: d.fn(help='"policies is a list of potential scaling polices which can be used during scaling.\\nIf not set, use the default values:\\n- For scale up: allow doubling the number of pods, or an absolute change of 4 pods in a 15s window.\\n- For scale down: allow all pods to be removed in a 15s window."', args=[d.arg(name='policies', type=d.T.array)]),
              withPolicies(policies): { spec+: { provider+: { kubernetes+: { envoyHpa+: { behavior+: { scaleUp+: { policies: if std.isArray(v=policies) then policies else [policies] } } } } } } },
              '#withPoliciesMixin':: d.fn(help='"policies is a list of potential scaling polices which can be used during scaling.\\nIf not set, use the default values:\\n- For scale up: allow doubling the number of pods, or an absolute change of 4 pods in a 15s window.\\n- For scale down: allow all pods to be removed in a 15s window."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='policies', type=d.T.array)]),
              withPoliciesMixin(policies): { spec+: { provider+: { kubernetes+: { envoyHpa+: { behavior+: { scaleUp+: { policies+: if std.isArray(v=policies) then policies else [policies] } } } } } } },
              '#withSelectPolicy':: d.fn(help='"selectPolicy is used to specify which policy should be used.\\nIf not set, the default value Max is used."', args=[d.arg(name='selectPolicy', type=d.T.string)]),
              withSelectPolicy(selectPolicy): { spec+: { provider+: { kubernetes+: { envoyHpa+: { behavior+: { scaleUp+: { selectPolicy: selectPolicy } } } } } } },
              '#withStabilizationWindowSeconds':: d.fn(help='"stabilizationWindowSeconds is the number of seconds for which past recommendations should be\\nconsidered while scaling up or scaling down.\\nStabilizationWindowSeconds must be greater than or equal to zero and less than or equal to 3600 (one hour).\\nIf not set, use the default values:\\n- For scale up: 0 (i.e. no stabilization is done).\\n- For scale down: 300 (i.e. the stabilization window is 300 seconds long)."', args=[d.arg(name='stabilizationWindowSeconds', type=d.T.integer)]),
              withStabilizationWindowSeconds(stabilizationWindowSeconds): { spec+: { provider+: { kubernetes+: { envoyHpa+: { behavior+: { scaleUp+: { stabilizationWindowSeconds: stabilizationWindowSeconds } } } } } } },
              '#withTolerance':: d.fn(help='"tolerance is the tolerance on the ratio between the current and desired\\nmetric value under which no updates are made to the desired number of\\nreplicas (e.g. 0.01 for 1%). Must be greater than or equal to zero. If not\\nset, the default cluster-wide tolerance is applied (by default 10%).\\n\\nFor example, if autoscaling is configured with a memory consumption target of 100Mi,\\nand scale-down and scale-up tolerances of 5% and 1% respectively, scaling will be\\ntriggered when the actual consumption falls below 95Mi or exceeds 101Mi.\\n\\nThis is an alpha field and requires enabling the HPAConfigurableTolerance\\nfeature gate."', args=[d.arg(name='tolerance', type=d.T.any)]),
              withTolerance(tolerance): { spec+: { provider+: { kubernetes+: { envoyHpa+: { behavior+: { scaleUp+: { tolerance: tolerance } } } } } } },
            },
          },
          '#metrics':: d.obj(help='"metrics contains the specifications for which to use to calculate the\\ndesired replica count (the maximum replica count across all metrics will\\nbe used).\\nIf left empty, it defaults to being based on CPU utilization with average on 80% usage."'),
          metrics: {
            '#containerResource':: d.obj(help='"containerResource refers to a resource metric (such as those specified in\\nrequests and limits) known to Kubernetes describing a single container in\\neach pod of the current scale target (e.g. CPU or memory). Such metrics are\\nbuilt in to Kubernetes, and have special scaling options on top of those\\navailable to normal per-pod metrics using the \\"pods\\" source."'),
            containerResource: {
              '#target':: d.obj(help='"target specifies the target value for the given metric"'),
              target: {
                '#withAverageUtilization':: d.fn(help='"averageUtilization is the target value of the average of the\\nresource metric across all relevant pods, represented as a percentage of\\nthe requested value of the resource for the pods.\\nCurrently only valid for Resource metric source type"', args=[d.arg(name='averageUtilization', type=d.T.integer)]),
                withAverageUtilization(averageUtilization): { containerResource+: { target+: { averageUtilization: averageUtilization } } },
                '#withAverageValue':: d.fn(help='"averageValue is the target value of the average of the\\nmetric across all relevant pods (as a quantity)"', args=[d.arg(name='averageValue', type=d.T.any)]),
                withAverageValue(averageValue): { containerResource+: { target+: { averageValue: averageValue } } },
                '#withType':: d.fn(help='"type represents whether the metric type is Utilization, Value, or AverageValue"', args=[d.arg(name='type', type=d.T.string)]),
                withType(type): { containerResource+: { target+: { type: type } } },
                '#withValue':: d.fn(help='"value is the target value of the metric (as a quantity)."', args=[d.arg(name='value', type=d.T.any)]),
                withValue(value): { containerResource+: { target+: { value: value } } },
              },
              '#withContainer':: d.fn(help='"container is the name of the container in the pods of the scaling target"', args=[d.arg(name='container', type=d.T.string)]),
              withContainer(container): { containerResource+: { container: container } },
              '#withName':: d.fn(help='"name is the name of the resource in question."', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { containerResource+: { name: name } },
            },
            '#external':: d.obj(help='"external refers to a global metric that is not associated\\nwith any Kubernetes object. It allows autoscaling based on information\\ncoming from components running outside of cluster\\n(for example length of queue in cloud messaging service, or\\nQPS from loadbalancer running outside of cluster)."'),
            external: {
              '#metric':: d.obj(help='"metric identifies the target metric by name and selector"'),
              metric: {
                '#selector':: d.obj(help='"selector is the string-encoded form of a standard kubernetes label selector for the given metric\\nWhen set, it is passed as an additional parameter to the metrics server for more specific metrics scoping.\\nWhen unset, just the metricName will be used to gather metrics."'),
                selector: {
                  '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                  matchExpressions: {
                    '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                    withKey(key): { key: key },
                    '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                    withOperator(operator): { operator: operator },
                    '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                    withValues(values): { values: if std.isArray(v=values) then values else [values] },
                    '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                    withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                  },
                  '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressions(matchExpressions): { external+: { metric+: { selector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } } },
                  '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressionsMixin(matchExpressions): { external+: { metric+: { selector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } } },
                  '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabels(matchLabels): { external+: { metric+: { selector+: { matchLabels: matchLabels } } } },
                  '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabelsMixin(matchLabels): { external+: { metric+: { selector+: { matchLabels+: matchLabels } } } },
                },
                '#withName':: d.fn(help='"name is the name of the given metric"', args=[d.arg(name='name', type=d.T.string)]),
                withName(name): { external+: { metric+: { name: name } } },
              },
              '#target':: d.obj(help='"target specifies the target value for the given metric"'),
              target: {
                '#withAverageUtilization':: d.fn(help='"averageUtilization is the target value of the average of the\\nresource metric across all relevant pods, represented as a percentage of\\nthe requested value of the resource for the pods.\\nCurrently only valid for Resource metric source type"', args=[d.arg(name='averageUtilization', type=d.T.integer)]),
                withAverageUtilization(averageUtilization): { external+: { target+: { averageUtilization: averageUtilization } } },
                '#withAverageValue':: d.fn(help='"averageValue is the target value of the average of the\\nmetric across all relevant pods (as a quantity)"', args=[d.arg(name='averageValue', type=d.T.any)]),
                withAverageValue(averageValue): { external+: { target+: { averageValue: averageValue } } },
                '#withType':: d.fn(help='"type represents whether the metric type is Utilization, Value, or AverageValue"', args=[d.arg(name='type', type=d.T.string)]),
                withType(type): { external+: { target+: { type: type } } },
                '#withValue':: d.fn(help='"value is the target value of the metric (as a quantity)."', args=[d.arg(name='value', type=d.T.any)]),
                withValue(value): { external+: { target+: { value: value } } },
              },
            },
            '#object':: d.obj(help='"object refers to a metric describing a single kubernetes object\\n(for example, hits-per-second on an Ingress object)."'),
            object: {
              '#describedObject':: d.obj(help='"describedObject specifies the descriptions of a object,such as kind,name apiVersion"'),
              describedObject: {
                '#withApiVersion':: d.fn(help='"apiVersion is the API version of the referent"', args=[d.arg(name='apiVersion', type=d.T.string)]),
                withApiVersion(apiVersion): { object+: { describedObject+: { apiVersion: apiVersion } } },
                '#withKind':: d.fn(help='"kind is the kind of the referent; More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds"', args=[d.arg(name='kind', type=d.T.string)]),
                withKind(kind): { object+: { describedObject+: { kind: kind } } },
                '#withName':: d.fn(help='"name is the name of the referent; More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
                withName(name): { object+: { describedObject+: { name: name } } },
              },
              '#metric':: d.obj(help='"metric identifies the target metric by name and selector"'),
              metric: {
                '#selector':: d.obj(help='"selector is the string-encoded form of a standard kubernetes label selector for the given metric\\nWhen set, it is passed as an additional parameter to the metrics server for more specific metrics scoping.\\nWhen unset, just the metricName will be used to gather metrics."'),
                selector: {
                  '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                  matchExpressions: {
                    '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                    withKey(key): { key: key },
                    '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                    withOperator(operator): { operator: operator },
                    '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                    withValues(values): { values: if std.isArray(v=values) then values else [values] },
                    '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                    withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                  },
                  '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressions(matchExpressions): { object+: { metric+: { selector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } } },
                  '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressionsMixin(matchExpressions): { object+: { metric+: { selector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } } },
                  '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabels(matchLabels): { object+: { metric+: { selector+: { matchLabels: matchLabels } } } },
                  '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabelsMixin(matchLabels): { object+: { metric+: { selector+: { matchLabels+: matchLabels } } } },
                },
                '#withName':: d.fn(help='"name is the name of the given metric"', args=[d.arg(name='name', type=d.T.string)]),
                withName(name): { object+: { metric+: { name: name } } },
              },
              '#target':: d.obj(help='"target specifies the target value for the given metric"'),
              target: {
                '#withAverageUtilization':: d.fn(help='"averageUtilization is the target value of the average of the\\nresource metric across all relevant pods, represented as a percentage of\\nthe requested value of the resource for the pods.\\nCurrently only valid for Resource metric source type"', args=[d.arg(name='averageUtilization', type=d.T.integer)]),
                withAverageUtilization(averageUtilization): { object+: { target+: { averageUtilization: averageUtilization } } },
                '#withAverageValue':: d.fn(help='"averageValue is the target value of the average of the\\nmetric across all relevant pods (as a quantity)"', args=[d.arg(name='averageValue', type=d.T.any)]),
                withAverageValue(averageValue): { object+: { target+: { averageValue: averageValue } } },
                '#withType':: d.fn(help='"type represents whether the metric type is Utilization, Value, or AverageValue"', args=[d.arg(name='type', type=d.T.string)]),
                withType(type): { object+: { target+: { type: type } } },
                '#withValue':: d.fn(help='"value is the target value of the metric (as a quantity)."', args=[d.arg(name='value', type=d.T.any)]),
                withValue(value): { object+: { target+: { value: value } } },
              },
            },
            '#pods':: d.obj(help='"pods refers to a metric describing each pod in the current scale target\\n(for example, transactions-processed-per-second).  The values will be\\naveraged together before being compared to the target value."'),
            pods: {
              '#metric':: d.obj(help='"metric identifies the target metric by name and selector"'),
              metric: {
                '#selector':: d.obj(help='"selector is the string-encoded form of a standard kubernetes label selector for the given metric\\nWhen set, it is passed as an additional parameter to the metrics server for more specific metrics scoping.\\nWhen unset, just the metricName will be used to gather metrics."'),
                selector: {
                  '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                  matchExpressions: {
                    '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                    withKey(key): { key: key },
                    '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                    withOperator(operator): { operator: operator },
                    '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                    withValues(values): { values: if std.isArray(v=values) then values else [values] },
                    '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                    withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                  },
                  '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressions(matchExpressions): { pods+: { metric+: { selector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } } },
                  '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressionsMixin(matchExpressions): { pods+: { metric+: { selector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } } },
                  '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabels(matchLabels): { pods+: { metric+: { selector+: { matchLabels: matchLabels } } } },
                  '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabelsMixin(matchLabels): { pods+: { metric+: { selector+: { matchLabels+: matchLabels } } } },
                },
                '#withName':: d.fn(help='"name is the name of the given metric"', args=[d.arg(name='name', type=d.T.string)]),
                withName(name): { pods+: { metric+: { name: name } } },
              },
              '#target':: d.obj(help='"target specifies the target value for the given metric"'),
              target: {
                '#withAverageUtilization':: d.fn(help='"averageUtilization is the target value of the average of the\\nresource metric across all relevant pods, represented as a percentage of\\nthe requested value of the resource for the pods.\\nCurrently only valid for Resource metric source type"', args=[d.arg(name='averageUtilization', type=d.T.integer)]),
                withAverageUtilization(averageUtilization): { pods+: { target+: { averageUtilization: averageUtilization } } },
                '#withAverageValue':: d.fn(help='"averageValue is the target value of the average of the\\nmetric across all relevant pods (as a quantity)"', args=[d.arg(name='averageValue', type=d.T.any)]),
                withAverageValue(averageValue): { pods+: { target+: { averageValue: averageValue } } },
                '#withType':: d.fn(help='"type represents whether the metric type is Utilization, Value, or AverageValue"', args=[d.arg(name='type', type=d.T.string)]),
                withType(type): { pods+: { target+: { type: type } } },
                '#withValue':: d.fn(help='"value is the target value of the metric (as a quantity)."', args=[d.arg(name='value', type=d.T.any)]),
                withValue(value): { pods+: { target+: { value: value } } },
              },
            },
            '#resource':: d.obj(help='"resource refers to a resource metric (such as those specified in\\nrequests and limits) known to Kubernetes describing each pod in the\\ncurrent scale target (e.g. CPU or memory). Such metrics are built in to\\nKubernetes, and have special scaling options on top of those available\\nto normal per-pod metrics using the \\"pods\\" source."'),
            resource: {
              '#target':: d.obj(help='"target specifies the target value for the given metric"'),
              target: {
                '#withAverageUtilization':: d.fn(help='"averageUtilization is the target value of the average of the\\nresource metric across all relevant pods, represented as a percentage of\\nthe requested value of the resource for the pods.\\nCurrently only valid for Resource metric source type"', args=[d.arg(name='averageUtilization', type=d.T.integer)]),
                withAverageUtilization(averageUtilization): { resource+: { target+: { averageUtilization: averageUtilization } } },
                '#withAverageValue':: d.fn(help='"averageValue is the target value of the average of the\\nmetric across all relevant pods (as a quantity)"', args=[d.arg(name='averageValue', type=d.T.any)]),
                withAverageValue(averageValue): { resource+: { target+: { averageValue: averageValue } } },
                '#withType':: d.fn(help='"type represents whether the metric type is Utilization, Value, or AverageValue"', args=[d.arg(name='type', type=d.T.string)]),
                withType(type): { resource+: { target+: { type: type } } },
                '#withValue':: d.fn(help='"value is the target value of the metric (as a quantity)."', args=[d.arg(name='value', type=d.T.any)]),
                withValue(value): { resource+: { target+: { value: value } } },
              },
              '#withName':: d.fn(help='"name is the name of the resource in question."', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { resource+: { name: name } },
            },
            '#withType':: d.fn(help='"type is the type of metric source.  It should be one of \\"ContainerResource\\", \\"External\\",\\n\\"Object\\", \\"Pods\\" or \\"Resource\\", each mapping to a matching field in the object."', args=[d.arg(name='type', type=d.T.string)]),
            withType(type): { type: type },
          },
          '#patch':: d.obj(help='"Patch defines how to perform the patch operation to the HorizontalPodAutoscaler"'),
          patch: {
            '#withType':: d.fn(help='"Type is the type of merge operation to perform\\n\\nBy default, StrategicMerge is used as the patch type."', args=[d.arg(name='type', type=d.T.string)]),
            withType(type): { spec+: { provider+: { kubernetes+: { envoyHpa+: { patch+: { type: type } } } } } },
            '#withValue':: d.fn(help='"Object contains the raw configuration for merged object"', args=[d.arg(name='value', type=d.T.any)]),
            withValue(value): { spec+: { provider+: { kubernetes+: { envoyHpa+: { patch+: { value: value } } } } } },
          },
          '#withMaxReplicas':: d.fn(help='"maxReplicas is the upper limit for the number of replicas to which the autoscaler can scale up.\\nIt cannot be less that minReplicas."', args=[d.arg(name='maxReplicas', type=d.T.integer)]),
          withMaxReplicas(maxReplicas): { spec+: { provider+: { kubernetes+: { envoyHpa+: { maxReplicas: maxReplicas } } } } },
          '#withMetrics':: d.fn(help='"metrics contains the specifications for which to use to calculate the\\ndesired replica count (the maximum replica count across all metrics will\\nbe used).\\nIf left empty, it defaults to being based on CPU utilization with average on 80% usage."', args=[d.arg(name='metrics', type=d.T.array)]),
          withMetrics(metrics): { spec+: { provider+: { kubernetes+: { envoyHpa+: { metrics: if std.isArray(v=metrics) then metrics else [metrics] } } } } },
          '#withMetricsMixin':: d.fn(help='"metrics contains the specifications for which to use to calculate the\\ndesired replica count (the maximum replica count across all metrics will\\nbe used).\\nIf left empty, it defaults to being based on CPU utilization with average on 80% usage."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='metrics', type=d.T.array)]),
          withMetricsMixin(metrics): { spec+: { provider+: { kubernetes+: { envoyHpa+: { metrics+: if std.isArray(v=metrics) then metrics else [metrics] } } } } },
          '#withMinReplicas':: d.fn(help='"minReplicas is the lower limit for the number of replicas to which the autoscaler\\ncan scale down. It defaults to 1 replica."', args=[d.arg(name='minReplicas', type=d.T.integer)]),
          withMinReplicas(minReplicas): { spec+: { provider+: { kubernetes+: { envoyHpa+: { minReplicas: minReplicas } } } } },
        },
        '#envoyPDB':: d.obj(help='"EnvoyPDB allows to control the pod disruption budget of an Envoy Proxy."'),
        envoyPDB: {
          '#patch':: d.obj(help='"Patch defines how to perform the patch operation to the PodDisruptionBudget"'),
          patch: {
            '#withType':: d.fn(help='"Type is the type of merge operation to perform\\n\\nBy default, StrategicMerge is used as the patch type."', args=[d.arg(name='type', type=d.T.string)]),
            withType(type): { spec+: { provider+: { kubernetes+: { envoyPDB+: { patch+: { type: type } } } } } },
            '#withValue':: d.fn(help='"Object contains the raw configuration for merged object"', args=[d.arg(name='value', type=d.T.any)]),
            withValue(value): { spec+: { provider+: { kubernetes+: { envoyPDB+: { patch+: { value: value } } } } } },
          },
          '#withMaxUnavailable':: d.fn(help='"MaxUnavailable specifies the maximum amount of pods (can be expressed as integers or as a percentage) that can be unavailable at all times during voluntary disruptions,\\nsuch as node drains or updates. This setting ensures that your envoy proxy maintains a certain level of availability\\nand resilience during maintenance operations. Cannot be combined with minAvailable."', args=[d.arg(name='maxUnavailable', type=d.T.any)]),
          withMaxUnavailable(maxUnavailable): { spec+: { provider+: { kubernetes+: { envoyPDB+: { maxUnavailable: maxUnavailable } } } } },
          '#withMinAvailable':: d.fn(help='"MinAvailable specifies the minimum amount of pods (can be expressed as integers or as a percentage) that must be available at all times during voluntary disruptions,\\nsuch as node drains or updates. This setting ensures that your envoy proxy maintains a certain level of availability\\nand resilience during maintenance operations. Cannot be combined with maxUnavailable."', args=[d.arg(name='minAvailable', type=d.T.any)]),
          withMinAvailable(minAvailable): { spec+: { provider+: { kubernetes+: { envoyPDB+: { minAvailable: minAvailable } } } } },
        },
        '#envoyService':: d.obj(help='"EnvoyService defines the desired state of the Envoy service resource.\\nIf unspecified, default settings for the managed Envoy service resource\\nare applied."'),
        envoyService: {
          '#patch':: d.obj(help='"Patch defines how to perform the patch operation to the service"'),
          patch: {
            '#withType':: d.fn(help='"Type is the type of merge operation to perform\\n\\nBy default, StrategicMerge is used as the patch type."', args=[d.arg(name='type', type=d.T.string)]),
            withType(type): { spec+: { provider+: { kubernetes+: { envoyService+: { patch+: { type: type } } } } } },
            '#withValue':: d.fn(help='"Object contains the raw configuration for merged object"', args=[d.arg(name='value', type=d.T.any)]),
            withValue(value): { spec+: { provider+: { kubernetes+: { envoyService+: { patch+: { value: value } } } } } },
          },
          '#withAllocateLoadBalancerNodePorts':: d.fn(help='"AllocateLoadBalancerNodePorts defines if NodePorts will be automatically allocated for\\nservices with type LoadBalancer. Default is \\"true\\". It may be set to \\"false\\" if the cluster\\nload-balancer does not rely on NodePorts. If the caller requests specific NodePorts (by specifying a\\nvalue), those requests will be respected, regardless of this field. This field may only be set for\\nservices with type LoadBalancer and will be cleared if the type is changed to any other type."', args=[d.arg(name='allocateLoadBalancerNodePorts', type=d.T.boolean)]),
          withAllocateLoadBalancerNodePorts(allocateLoadBalancerNodePorts): { spec+: { provider+: { kubernetes+: { envoyService+: { allocateLoadBalancerNodePorts: allocateLoadBalancerNodePorts } } } } },
          '#withAnnotations':: d.fn(help='"Annotations that should be appended to the service.\\nBy default, no annotations are appended."', args=[d.arg(name='annotations', type=d.T.object)]),
          withAnnotations(annotations): { spec+: { provider+: { kubernetes+: { envoyService+: { annotations: annotations } } } } },
          '#withAnnotationsMixin':: d.fn(help='"Annotations that should be appended to the service.\\nBy default, no annotations are appended."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='annotations', type=d.T.object)]),
          withAnnotationsMixin(annotations): { spec+: { provider+: { kubernetes+: { envoyService+: { annotations+: annotations } } } } },
          '#withExternalTrafficPolicy':: d.fn(help='"ExternalTrafficPolicy determines the externalTrafficPolicy for the Envoy Service. Valid options\\nare Local and Cluster. Default is \\"Local\\". \\"Local\\" means traffic will only go to pods on the node\\nreceiving the traffic. \\"Cluster\\" means connections are loadbalanced to all pods in the cluster."', args=[d.arg(name='externalTrafficPolicy', type=d.T.string)]),
          withExternalTrafficPolicy(externalTrafficPolicy): { spec+: { provider+: { kubernetes+: { envoyService+: { externalTrafficPolicy: externalTrafficPolicy } } } } },
          '#withLabels':: d.fn(help='"Labels that should be appended to the service.\\nBy default, no labels are appended."', args=[d.arg(name='labels', type=d.T.object)]),
          withLabels(labels): { spec+: { provider+: { kubernetes+: { envoyService+: { labels: labels } } } } },
          '#withLabelsMixin':: d.fn(help='"Labels that should be appended to the service.\\nBy default, no labels are appended."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labels', type=d.T.object)]),
          withLabelsMixin(labels): { spec+: { provider+: { kubernetes+: { envoyService+: { labels+: labels } } } } },
          '#withLoadBalancerClass':: d.fn(help='"LoadBalancerClass, when specified, allows for choosing the LoadBalancer provider\\nimplementation if more than one are available or is otherwise expected to be specified"', args=[d.arg(name='loadBalancerClass', type=d.T.string)]),
          withLoadBalancerClass(loadBalancerClass): { spec+: { provider+: { kubernetes+: { envoyService+: { loadBalancerClass: loadBalancerClass } } } } },
          '#withLoadBalancerIP':: d.fn(help='"LoadBalancerIP defines the IP Address of the underlying load balancer service. This field\\nmay be ignored if the load balancer provider does not support this feature.\\nThis field has been deprecated in Kubernetes, but it is still used for setting the IP Address in some cloud\\nproviders such as GCP."', args=[d.arg(name='loadBalancerIP', type=d.T.string)]),
          withLoadBalancerIP(loadBalancerIP): { spec+: { provider+: { kubernetes+: { envoyService+: { loadBalancerIP: loadBalancerIP } } } } },
          '#withLoadBalancerSourceRanges':: d.fn(help='"LoadBalancerSourceRanges defines a list of allowed IP addresses which will be configured as\\nfirewall rules on the platform providers load balancer. This is not guaranteed to be working as\\nit happens outside of kubernetes and has to be supported and handled by the platform provider.\\nThis field may only be set for services with type LoadBalancer and will be cleared if the type\\nis changed to any other type."', args=[d.arg(name='loadBalancerSourceRanges', type=d.T.array)]),
          withLoadBalancerSourceRanges(loadBalancerSourceRanges): { spec+: { provider+: { kubernetes+: { envoyService+: { loadBalancerSourceRanges: if std.isArray(v=loadBalancerSourceRanges) then loadBalancerSourceRanges else [loadBalancerSourceRanges] } } } } },
          '#withLoadBalancerSourceRangesMixin':: d.fn(help='"LoadBalancerSourceRanges defines a list of allowed IP addresses which will be configured as\\nfirewall rules on the platform providers load balancer. This is not guaranteed to be working as\\nit happens outside of kubernetes and has to be supported and handled by the platform provider.\\nThis field may only be set for services with type LoadBalancer and will be cleared if the type\\nis changed to any other type."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='loadBalancerSourceRanges', type=d.T.array)]),
          withLoadBalancerSourceRangesMixin(loadBalancerSourceRanges): { spec+: { provider+: { kubernetes+: { envoyService+: { loadBalancerSourceRanges+: if std.isArray(v=loadBalancerSourceRanges) then loadBalancerSourceRanges else [loadBalancerSourceRanges] } } } } },
          '#withName':: d.fn(help='"Name of the service.\\nWhen unset, this defaults to an autogenerated name."', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { spec+: { provider+: { kubernetes+: { envoyService+: { name: name } } } } },
          '#withType':: d.fn(help='"Type determines how the Service is exposed. Defaults to LoadBalancer.\\nValid options are ClusterIP, LoadBalancer and NodePort.\\n\\"LoadBalancer\\" means a service will be exposed via an external load balancer (if the cloud provider supports it).\\n\\"ClusterIP\\" means a service will only be accessible inside the cluster, via the cluster IP.\\n\\"NodePort\\" means a service will be exposed on a static Port on all Nodes of the cluster."', args=[d.arg(name='type', type=d.T.string)]),
          withType(type): { spec+: { provider+: { kubernetes+: { envoyService+: { type: type } } } } },
        },
        '#withUseListenerPortAsContainerPort':: d.fn(help='"UseListenerPortAsContainerPort disables the port shifting feature in the Envoy Proxy.\\nWhen set to false (default value), if the service port is a privileged port (1-1023), add a constant to the value converting it into an ephemeral port.\\nThis allows the container to bind to the port without needing a CAP_NET_BIND_SERVICE capability."', args=[d.arg(name='useListenerPortAsContainerPort', type=d.T.boolean)]),
        withUseListenerPortAsContainerPort(useListenerPortAsContainerPort): { spec+: { provider+: { kubernetes+: { useListenerPortAsContainerPort: useListenerPortAsContainerPort } } } },
      },
      '#withType':: d.fn(help='"Type is the type of resource provider to use. A resource provider provides\\ninfrastructure resources for running the data plane, e.g. Envoy proxy, and\\noptional auxiliary control planes. Supported types are \\"Kubernetes\\"."', args=[d.arg(name='type', type=d.T.string)]),
      withType(type): { spec+: { provider+: { type: type } } },
    },
    '#shutdown':: d.obj(help='"Shutdown defines configuration for graceful envoy shutdown process."'),
    shutdown: {
      '#withDrainTimeout':: d.fn(help="\"DrainTimeout defines the graceful drain timeout. This should be less than the pod's terminationGracePeriodSeconds.\\nIf unspecified, defaults to 60 seconds.\"", args=[d.arg(name='drainTimeout', type=d.T.string)]),
      withDrainTimeout(drainTimeout): { spec+: { shutdown+: { drainTimeout: drainTimeout } } },
      '#withMinDrainDuration':: d.fn(help='"MinDrainDuration defines the minimum drain duration allowing time for endpoint deprogramming to complete.\\nIf unspecified, defaults to 10 seconds."', args=[d.arg(name='minDrainDuration', type=d.T.string)]),
      withMinDrainDuration(minDrainDuration): { spec+: { shutdown+: { minDrainDuration: minDrainDuration } } },
    },
    '#telemetry':: d.obj(help='"Telemetry defines telemetry parameters for managed proxies."'),
    telemetry: {
      '#accessLog':: d.obj(help='"AccessLogs defines accesslog parameters for managed proxies.\\nIf unspecified, will send default format to stdout."'),
      accessLog: {
        '#settings':: d.obj(help='"Settings defines accesslog settings for managed proxies.\\nIf unspecified, will send default format to stdout."'),
        settings: {
          '#format':: d.obj(help='"Format defines the format of accesslog.\\nThis will be ignored if sink type is ALS."'),
          format: {
            '#withJson':: d.fn(help="\"JSON is additional attributes that describe the specific event occurrence.\\nStructured format for the envoy access logs. Envoy [command operators](https://www.envoyproxy.io/docs/envoy/latest/configuration/observability/access_log/usage#command-operators)\\ncan be used as values for fields within the Struct.\\nIt's required when the format type is \\\"JSON\\\".\"", args=[d.arg(name='json', type=d.T.object)]),
            withJson(json): { format+: { json: json } },
            '#withJsonMixin':: d.fn(help="\"JSON is additional attributes that describe the specific event occurrence.\\nStructured format for the envoy access logs. Envoy [command operators](https://www.envoyproxy.io/docs/envoy/latest/configuration/observability/access_log/usage#command-operators)\\ncan be used as values for fields within the Struct.\\nIt's required when the format type is \\\"JSON\\\".\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='json', type=d.T.object)]),
            withJsonMixin(json): { format+: { json+: json } },
            '#withText':: d.fn(help="\"Text defines the text accesslog format, following Envoy accesslog formatting,\\nIt's required when the format type is \\\"Text\\\".\\nEnvoy [command operators](https://www.envoyproxy.io/docs/envoy/latest/configuration/observability/access_log/usage#command-operators) may be used in the format.\\nThe [format string documentation](https://www.envoyproxy.io/docs/envoy/latest/configuration/observability/access_log/usage#config-access-log-format-strings) provides more information.\"", args=[d.arg(name='text', type=d.T.string)]),
            withText(text): { format+: { text: text } },
            '#withType':: d.fn(help='"Type defines the type of accesslog format."', args=[d.arg(name='type', type=d.T.string)]),
            withType(type): { format+: { type: type } },
          },
          '#sinks':: d.obj(help='"Sinks defines the sinks of accesslog."'),
          sinks: {
            '#als':: d.obj(help='"ALS defines the gRPC Access Log Service (ALS) sink."'),
            als: {
              '#backendRef':: d.obj(help='"BackendRef references a Kubernetes object that represents the\\nbackend server to which the authorization request will be sent.\\n\\nDeprecated: Use BackendRefs instead."'),
              backendRef: {
                '#withGroup':: d.fn(help='"Group is the group of the referent. For example, \\"gateway.networking.k8s.io\\".\\nWhen unspecified or empty string, core API group is inferred."', args=[d.arg(name='group', type=d.T.string)]),
                withGroup(group): { als+: { backendRef+: { group: group } } },
                '#withKind':: d.fn(help='"Kind is the Kubernetes resource kind of the referent. For example\\n\\"Service\\".\\n\\nDefaults to \\"Service\\" when not specified.\\n\\nExternalName services can refer to CNAME DNS records that may live\\noutside of the cluster and as such are difficult to reason about in\\nterms of conformance. They also may not be safe to forward to (see\\nCVE-2021-25740 for more information). Implementations SHOULD NOT\\nsupport ExternalName Services.\\n\\nSupport: Core (Services with a type other than ExternalName)\\n\\nSupport: Implementation-specific (Services with type ExternalName)"', args=[d.arg(name='kind', type=d.T.string)]),
                withKind(kind): { als+: { backendRef+: { kind: kind } } },
                '#withName':: d.fn(help='"Name is the name of the referent."', args=[d.arg(name='name', type=d.T.string)]),
                withName(name): { als+: { backendRef+: { name: name } } },
                '#withNamespace':: d.fn(help="\"Namespace is the namespace of the backend. When unspecified, the local\\nnamespace is inferred.\\n\\nNote that when a namespace different than the local namespace is specified,\\na ReferenceGrant object is required in the referent namespace to allow that\\nnamespace's owner to accept the reference. See the ReferenceGrant\\ndocumentation for details.\\n\\nSupport: Core\"", args=[d.arg(name='namespace', type=d.T.string)]),
                withNamespace(namespace): { als+: { backendRef+: { namespace: namespace } } },
                '#withPort':: d.fn(help='"Port specifies the destination port number to use for this resource.\\nPort is required when the referent is a Kubernetes Service. In this\\ncase, the port number is the service port number, not the target port.\\nFor other resources, destination port might be derived from the referent\\nresource or this field."', args=[d.arg(name='port', type=d.T.integer)]),
                withPort(port): { als+: { backendRef+: { port: port } } },
              },
              '#backendRefs':: d.obj(help='"BackendRefs references a Kubernetes object that represents the\\nbackend server to which the authorization request will be sent."'),
              backendRefs: {
                '#withFallback':: d.fn(help='"Fallback indicates whether the backend is designated as a fallback.\\nMultiple fallback backends can be configured.\\nIt is highly recommended to configure active or passive health checks to ensure that failover can be detected\\nwhen the active backends become unhealthy and to automatically readjust once the primary backends are healthy again.\\nThe overprovisioning factor is set to 1.4, meaning the fallback backends will only start receiving traffic when\\nthe health of the active backends falls below 72%."', args=[d.arg(name='fallback', type=d.T.boolean)]),
                withFallback(fallback): { fallback: fallback },
                '#withGroup':: d.fn(help='"Group is the group of the referent. For example, \\"gateway.networking.k8s.io\\".\\nWhen unspecified or empty string, core API group is inferred."', args=[d.arg(name='group', type=d.T.string)]),
                withGroup(group): { group: group },
                '#withKind':: d.fn(help='"Kind is the Kubernetes resource kind of the referent. For example\\n\\"Service\\".\\n\\nDefaults to \\"Service\\" when not specified.\\n\\nExternalName services can refer to CNAME DNS records that may live\\noutside of the cluster and as such are difficult to reason about in\\nterms of conformance. They also may not be safe to forward to (see\\nCVE-2021-25740 for more information). Implementations SHOULD NOT\\nsupport ExternalName Services.\\n\\nSupport: Core (Services with a type other than ExternalName)\\n\\nSupport: Implementation-specific (Services with type ExternalName)"', args=[d.arg(name='kind', type=d.T.string)]),
                withKind(kind): { kind: kind },
                '#withName':: d.fn(help='"Name is the name of the referent."', args=[d.arg(name='name', type=d.T.string)]),
                withName(name): { name: name },
                '#withNamespace':: d.fn(help="\"Namespace is the namespace of the backend. When unspecified, the local\\nnamespace is inferred.\\n\\nNote that when a namespace different than the local namespace is specified,\\na ReferenceGrant object is required in the referent namespace to allow that\\nnamespace's owner to accept the reference. See the ReferenceGrant\\ndocumentation for details.\\n\\nSupport: Core\"", args=[d.arg(name='namespace', type=d.T.string)]),
                withNamespace(namespace): { namespace: namespace },
                '#withPort':: d.fn(help='"Port specifies the destination port number to use for this resource.\\nPort is required when the referent is a Kubernetes Service. In this\\ncase, the port number is the service port number, not the target port.\\nFor other resources, destination port might be derived from the referent\\nresource or this field."', args=[d.arg(name='port', type=d.T.integer)]),
                withPort(port): { port: port },
              },
              '#backendSettings':: d.obj(help='"BackendSettings holds configuration for managing the connection\\nto the backend."'),
              backendSettings: {
                '#circuitBreaker':: d.obj(help='"Circuit Breaker settings for the upstream connections and requests.\\nIf not set, circuit breakers will be enabled with the default thresholds"'),
                circuitBreaker: {
                  '#perEndpoint':: d.obj(help='"PerEndpoint defines Circuit Breakers that will apply per-endpoint for an upstream cluster"'),
                  perEndpoint: {
                    '#withMaxConnections':: d.fn(help='"MaxConnections configures the maximum number of connections that Envoy will establish per-endpoint to the referenced backend defined within a xRoute rule."', args=[d.arg(name='maxConnections', type=d.T.integer)]),
                    withMaxConnections(maxConnections): { als+: { backendSettings+: { circuitBreaker+: { perEndpoint+: { maxConnections: maxConnections } } } } },
                  },
                  '#withMaxConnections':: d.fn(help='"The maximum number of connections that Envoy will establish to the referenced backend defined within a xRoute rule."', args=[d.arg(name='maxConnections', type=d.T.integer)]),
                  withMaxConnections(maxConnections): { als+: { backendSettings+: { circuitBreaker+: { maxConnections: maxConnections } } } },
                  '#withMaxParallelRequests':: d.fn(help='"The maximum number of parallel requests that Envoy will make to the referenced backend defined within a xRoute rule."', args=[d.arg(name='maxParallelRequests', type=d.T.integer)]),
                  withMaxParallelRequests(maxParallelRequests): { als+: { backendSettings+: { circuitBreaker+: { maxParallelRequests: maxParallelRequests } } } },
                  '#withMaxParallelRetries':: d.fn(help='"The maximum number of parallel retries that Envoy will make to the referenced backend defined within a xRoute rule."', args=[d.arg(name='maxParallelRetries', type=d.T.integer)]),
                  withMaxParallelRetries(maxParallelRetries): { als+: { backendSettings+: { circuitBreaker+: { maxParallelRetries: maxParallelRetries } } } },
                  '#withMaxPendingRequests':: d.fn(help='"The maximum number of pending requests that Envoy will queue to the referenced backend defined within a xRoute rule."', args=[d.arg(name='maxPendingRequests', type=d.T.integer)]),
                  withMaxPendingRequests(maxPendingRequests): { als+: { backendSettings+: { circuitBreaker+: { maxPendingRequests: maxPendingRequests } } } },
                  '#withMaxRequestsPerConnection':: d.fn(help='"The maximum number of requests that Envoy will make over a single connection to the referenced backend defined within a xRoute rule.\\nDefault: unlimited."', args=[d.arg(name='maxRequestsPerConnection', type=d.T.integer)]),
                  withMaxRequestsPerConnection(maxRequestsPerConnection): { als+: { backendSettings+: { circuitBreaker+: { maxRequestsPerConnection: maxRequestsPerConnection } } } },
                },
                '#connection':: d.obj(help='"Connection includes backend connection settings."'),
                connection: {
                  '#withBufferLimit':: d.fn(help="\"BufferLimit Soft limit on size of the cluster’s connections read and write buffers.\\nBufferLimit applies to connection streaming (maybe non-streaming) channel between processes, it's in user space.\\nIf unspecified, an implementation defined default is applied (32768 bytes).\\nFor example, 20Mi, 1Gi, 256Ki etc.\\nNote: that when the suffix is not provided, the value is interpreted as bytes.\"", args=[d.arg(name='bufferLimit', type=d.T.any)]),
                  withBufferLimit(bufferLimit): { als+: { backendSettings+: { connection+: { bufferLimit: bufferLimit } } } },
                  '#withSocketBufferLimit':: d.fn(help="\"SocketBufferLimit provides configuration for the maximum buffer size in bytes for each socket\\nto backend.\\nSocketBufferLimit applies to socket streaming channel between TCP/IP stacks, it's in kernel space.\\nFor example, 20Mi, 1Gi, 256Ki etc.\\nNote that when the suffix is not provided, the value is interpreted as bytes.\"", args=[d.arg(name='socketBufferLimit', type=d.T.any)]),
                  withSocketBufferLimit(socketBufferLimit): { als+: { backendSettings+: { connection+: { socketBufferLimit: socketBufferLimit } } } },
                },
                '#dns':: d.obj(help='"DNS includes dns resolution settings."'),
                dns: {
                  '#withDnsRefreshRate':: d.fn(help='"DNSRefreshRate specifies the rate at which DNS records should be refreshed.\\nDefaults to 30 seconds."', args=[d.arg(name='dnsRefreshRate', type=d.T.string)]),
                  withDnsRefreshRate(dnsRefreshRate): { als+: { backendSettings+: { dns+: { dnsRefreshRate: dnsRefreshRate } } } },
                  '#withLookupFamily':: d.fn(help='"LookupFamily determines how Envoy would resolve DNS for Routes where the backend is specified as a fully qualified domain name (FQDN).\\nIf set, this configuration overrides other defaults."', args=[d.arg(name='lookupFamily', type=d.T.string)]),
                  withLookupFamily(lookupFamily): { als+: { backendSettings+: { dns+: { lookupFamily: lookupFamily } } } },
                  '#withRespectDnsTtl':: d.fn(help='"RespectDNSTTL indicates whether the DNS Time-To-Live (TTL) should be respected.\\nIf the value is set to true, the DNS refresh rate will be set to the resource record’s TTL.\\nDefaults to true."', args=[d.arg(name='respectDnsTtl', type=d.T.boolean)]),
                  withRespectDnsTtl(respectDnsTtl): { als+: { backendSettings+: { dns+: { respectDnsTtl: respectDnsTtl } } } },
                },
                '#healthCheck':: d.obj(help='"HealthCheck allows gateway to perform active health checking on backends."'),
                healthCheck: {
                  '#active':: d.obj(help='"Active health check configuration"'),
                  active: {
                    '#grpc':: d.obj(help="\"GRPC defines the configuration of the GRPC health checker.\\nIt's optional, and can only be used if the specified type is GRPC.\""),
                    grpc: {
                      '#withService':: d.fn(help='"Service to send in the health check request.\\nIf this is not specified, then the health check request applies to the entire\\nserver and not to a specific service."', args=[d.arg(name='service', type=d.T.string)]),
                      withService(service): { als+: { backendSettings+: { healthCheck+: { active+: { grpc+: { service: service } } } } } },
                    },
                    '#http':: d.obj(help="\"HTTP defines the configuration of http health checker.\\nIt's required while the health checker type is HTTP.\""),
                    http: {
                      '#expectedResponse':: d.obj(help='"ExpectedResponse defines a list of HTTP expected responses to match."'),
                      expectedResponse: {
                        '#withBinary':: d.fn(help='"Binary payload base64 encoded."', args=[d.arg(name='binary', type=d.T.string)]),
                        withBinary(binary): { als+: { backendSettings+: { healthCheck+: { active+: { http+: { expectedResponse+: { binary: binary } } } } } } },
                        '#withText':: d.fn(help='"Text payload in plain text."', args=[d.arg(name='text', type=d.T.string)]),
                        withText(text): { als+: { backendSettings+: { healthCheck+: { active+: { http+: { expectedResponse+: { text: text } } } } } } },
                        '#withType':: d.fn(help='"Type defines the type of the payload."', args=[d.arg(name='type', type=d.T.string)]),
                        withType(type): { als+: { backendSettings+: { healthCheck+: { active+: { http+: { expectedResponse+: { type: type } } } } } } },
                      },
                      '#withExpectedStatuses':: d.fn(help='"ExpectedStatuses defines a list of HTTP response statuses considered healthy.\\nDefaults to 200 only"', args=[d.arg(name='expectedStatuses', type=d.T.array)]),
                      withExpectedStatuses(expectedStatuses): { als+: { backendSettings+: { healthCheck+: { active+: { http+: { expectedStatuses: if std.isArray(v=expectedStatuses) then expectedStatuses else [expectedStatuses] } } } } } },
                      '#withExpectedStatusesMixin':: d.fn(help='"ExpectedStatuses defines a list of HTTP response statuses considered healthy.\\nDefaults to 200 only"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='expectedStatuses', type=d.T.array)]),
                      withExpectedStatusesMixin(expectedStatuses): { als+: { backendSettings+: { healthCheck+: { active+: { http+: { expectedStatuses+: if std.isArray(v=expectedStatuses) then expectedStatuses else [expectedStatuses] } } } } } },
                      '#withMethod':: d.fn(help='"Method defines the HTTP method used for health checking.\\nDefaults to GET"', args=[d.arg(name='method', type=d.T.string)]),
                      withMethod(method): { als+: { backendSettings+: { healthCheck+: { active+: { http+: { method: method } } } } } },
                      '#withPath':: d.fn(help='"Path defines the HTTP path that will be requested during health checking."', args=[d.arg(name='path', type=d.T.string)]),
                      withPath(path): { als+: { backendSettings+: { healthCheck+: { active+: { http+: { path: path } } } } } },
                    },
                    '#tcp':: d.obj(help="\"TCP defines the configuration of tcp health checker.\\nIt's required while the health checker type is TCP.\""),
                    tcp: {
                      '#receive':: d.obj(help='"Receive defines the expected response payload."'),
                      receive: {
                        '#withBinary':: d.fn(help='"Binary payload base64 encoded."', args=[d.arg(name='binary', type=d.T.string)]),
                        withBinary(binary): { als+: { backendSettings+: { healthCheck+: { active+: { tcp+: { receive+: { binary: binary } } } } } } },
                        '#withText':: d.fn(help='"Text payload in plain text."', args=[d.arg(name='text', type=d.T.string)]),
                        withText(text): { als+: { backendSettings+: { healthCheck+: { active+: { tcp+: { receive+: { text: text } } } } } } },
                        '#withType':: d.fn(help='"Type defines the type of the payload."', args=[d.arg(name='type', type=d.T.string)]),
                        withType(type): { als+: { backendSettings+: { healthCheck+: { active+: { tcp+: { receive+: { type: type } } } } } } },
                      },
                      '#send':: d.obj(help='"Send defines the request payload."'),
                      send: {
                        '#withBinary':: d.fn(help='"Binary payload base64 encoded."', args=[d.arg(name='binary', type=d.T.string)]),
                        withBinary(binary): { als+: { backendSettings+: { healthCheck+: { active+: { tcp+: { send+: { binary: binary } } } } } } },
                        '#withText':: d.fn(help='"Text payload in plain text."', args=[d.arg(name='text', type=d.T.string)]),
                        withText(text): { als+: { backendSettings+: { healthCheck+: { active+: { tcp+: { send+: { text: text } } } } } } },
                        '#withType':: d.fn(help='"Type defines the type of the payload."', args=[d.arg(name='type', type=d.T.string)]),
                        withType(type): { als+: { backendSettings+: { healthCheck+: { active+: { tcp+: { send+: { type: type } } } } } } },
                      },
                    },
                    '#withHealthyThreshold':: d.fn(help='"HealthyThreshold defines the number of healthy health checks required before a backend host is marked healthy."', args=[d.arg(name='healthyThreshold', type=d.T.integer)]),
                    withHealthyThreshold(healthyThreshold): { als+: { backendSettings+: { healthCheck+: { active+: { healthyThreshold: healthyThreshold } } } } },
                    '#withInterval':: d.fn(help='"Interval defines the time between active health checks."', args=[d.arg(name='interval', type=d.T.string)]),
                    withInterval(interval): { als+: { backendSettings+: { healthCheck+: { active+: { interval: interval } } } } },
                    '#withTimeout':: d.fn(help='"Timeout defines the time to wait for a health check response."', args=[d.arg(name='timeout', type=d.T.string)]),
                    withTimeout(timeout): { als+: { backendSettings+: { healthCheck+: { active+: { timeout: timeout } } } } },
                    '#withType':: d.fn(help='"Type defines the type of health checker."', args=[d.arg(name='type', type=d.T.string)]),
                    withType(type): { als+: { backendSettings+: { healthCheck+: { active+: { type: type } } } } },
                    '#withUnhealthyThreshold':: d.fn(help='"UnhealthyThreshold defines the number of unhealthy health checks required before a backend host is marked unhealthy."', args=[d.arg(name='unhealthyThreshold', type=d.T.integer)]),
                    withUnhealthyThreshold(unhealthyThreshold): { als+: { backendSettings+: { healthCheck+: { active+: { unhealthyThreshold: unhealthyThreshold } } } } },
                  },
                  '#passive':: d.obj(help='"Passive passive check configuration"'),
                  passive: {
                    '#withBaseEjectionTime':: d.fn(help='"BaseEjectionTime defines the base duration for which a host will be ejected on consecutive failures."', args=[d.arg(name='baseEjectionTime', type=d.T.string)]),
                    withBaseEjectionTime(baseEjectionTime): { als+: { backendSettings+: { healthCheck+: { passive+: { baseEjectionTime: baseEjectionTime } } } } },
                    '#withConsecutive5XxErrors':: d.fn(help='"Consecutive5xxErrors sets the number of consecutive 5xx errors triggering ejection."', args=[d.arg(name='consecutive5XxErrors', type=d.T.integer)]),
                    withConsecutive5XxErrors(consecutive5XxErrors): { als+: { backendSettings+: { healthCheck+: { passive+: { consecutive5XxErrors: consecutive5XxErrors } } } } },
                    '#withConsecutiveGatewayErrors':: d.fn(help='"ConsecutiveGatewayErrors sets the number of consecutive gateway errors triggering ejection."', args=[d.arg(name='consecutiveGatewayErrors', type=d.T.integer)]),
                    withConsecutiveGatewayErrors(consecutiveGatewayErrors): { als+: { backendSettings+: { healthCheck+: { passive+: { consecutiveGatewayErrors: consecutiveGatewayErrors } } } } },
                    '#withConsecutiveLocalOriginFailures':: d.fn(help='"ConsecutiveLocalOriginFailures sets the number of consecutive local origin failures triggering ejection.\\nParameter takes effect only when split_external_local_origin_errors is set to true."', args=[d.arg(name='consecutiveLocalOriginFailures', type=d.T.integer)]),
                    withConsecutiveLocalOriginFailures(consecutiveLocalOriginFailures): { als+: { backendSettings+: { healthCheck+: { passive+: { consecutiveLocalOriginFailures: consecutiveLocalOriginFailures } } } } },
                    '#withInterval':: d.fn(help='"Interval defines the time between passive health checks."', args=[d.arg(name='interval', type=d.T.string)]),
                    withInterval(interval): { als+: { backendSettings+: { healthCheck+: { passive+: { interval: interval } } } } },
                    '#withMaxEjectionPercent':: d.fn(help='"MaxEjectionPercent sets the maximum percentage of hosts in a cluster that can be ejected."', args=[d.arg(name='maxEjectionPercent', type=d.T.integer)]),
                    withMaxEjectionPercent(maxEjectionPercent): { als+: { backendSettings+: { healthCheck+: { passive+: { maxEjectionPercent: maxEjectionPercent } } } } },
                    '#withSplitExternalLocalOriginErrors':: d.fn(help='"SplitExternalLocalOriginErrors enables splitting of errors between external and local origin."', args=[d.arg(name='splitExternalLocalOriginErrors', type=d.T.boolean)]),
                    withSplitExternalLocalOriginErrors(splitExternalLocalOriginErrors): { als+: { backendSettings+: { healthCheck+: { passive+: { splitExternalLocalOriginErrors: splitExternalLocalOriginErrors } } } } },
                  },
                  '#withPanicThreshold':: d.fn(help="\"When number of unhealthy endpoints for a backend reaches this threshold\\nEnvoy will disregard health status and balance across all endpoints.\\nIt's designed to prevent a situation in which host failures cascade throughout the cluster\\nas load increases. If not set, the default value is 50%. To disable panic mode, set value to `0`.\"", args=[d.arg(name='panicThreshold', type=d.T.integer)]),
                  withPanicThreshold(panicThreshold): { als+: { backendSettings+: { healthCheck+: { panicThreshold: panicThreshold } } } },
                },
                '#http2':: d.obj(help='"HTTP2 provides HTTP/2 configuration for backend connections."'),
                http2: {
                  '#withInitialConnectionWindowSize':: d.fn(help='"InitialConnectionWindowSize sets the initial window size for HTTP/2 connections.\\nIf not set, the default value is 1 MiB."', args=[d.arg(name='initialConnectionWindowSize', type=d.T.any)]),
                  withInitialConnectionWindowSize(initialConnectionWindowSize): { als+: { backendSettings+: { http2+: { initialConnectionWindowSize: initialConnectionWindowSize } } } },
                  '#withInitialStreamWindowSize':: d.fn(help='"InitialStreamWindowSize sets the initial window size for HTTP/2 streams.\\nIf not set, the default value is 64 KiB(64*1024)."', args=[d.arg(name='initialStreamWindowSize', type=d.T.any)]),
                  withInitialStreamWindowSize(initialStreamWindowSize): { als+: { backendSettings+: { http2+: { initialStreamWindowSize: initialStreamWindowSize } } } },
                  '#withMaxConcurrentStreams':: d.fn(help='"MaxConcurrentStreams sets the maximum number of concurrent streams allowed per connection.\\nIf not set, the default value is 100."', args=[d.arg(name='maxConcurrentStreams', type=d.T.integer)]),
                  withMaxConcurrentStreams(maxConcurrentStreams): { als+: { backendSettings+: { http2+: { maxConcurrentStreams: maxConcurrentStreams } } } },
                  '#withOnInvalidMessage':: d.fn(help="\"OnInvalidMessage determines if Envoy will terminate the connection or just the offending stream in the event of HTTP messaging error\\nIt's recommended for L2 Envoy deployments to set this value to TerminateStream.\\nhttps://www.envoyproxy.io/docs/envoy/latest/configuration/best_practices/level_two\\nDefault: TerminateConnection\"", args=[d.arg(name='onInvalidMessage', type=d.T.string)]),
                  withOnInvalidMessage(onInvalidMessage): { als+: { backendSettings+: { http2+: { onInvalidMessage: onInvalidMessage } } } },
                },
                '#loadBalancer':: d.obj(help='"LoadBalancer policy to apply when routing traffic from the gateway to\\nthe backend endpoints. Defaults to `LeastRequest`."'),
                loadBalancer: {
                  '#consistentHash':: d.obj(help='"ConsistentHash defines the configuration when the load balancer type is\\nset to ConsistentHash"'),
                  consistentHash: {
                    '#cookie':: d.obj(help='"Cookie configures the cookie hash policy when the consistent hash type is set to Cookie."'),
                    cookie: {
                      '#withAttributes':: d.fn(help='"Additional Attributes to set for the generated cookie."', args=[d.arg(name='attributes', type=d.T.object)]),
                      withAttributes(attributes): { als+: { backendSettings+: { loadBalancer+: { consistentHash+: { cookie+: { attributes: attributes } } } } } },
                      '#withAttributesMixin':: d.fn(help='"Additional Attributes to set for the generated cookie."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='attributes', type=d.T.object)]),
                      withAttributesMixin(attributes): { als+: { backendSettings+: { loadBalancer+: { consistentHash+: { cookie+: { attributes+: attributes } } } } } },
                      '#withName':: d.fn(help='"Name of the cookie to hash.\\nIf this cookie does not exist in the request, Envoy will generate a cookie and set\\nthe TTL on the response back to the client based on Layer 4\\nattributes of the backend endpoint, to ensure that these future requests\\ngo to the same backend endpoint. Make sure to set the TTL field for this case."', args=[d.arg(name='name', type=d.T.string)]),
                      withName(name): { als+: { backendSettings+: { loadBalancer+: { consistentHash+: { cookie+: { name: name } } } } } },
                      '#withTtl':: d.fn(help='"TTL of the generated cookie if the cookie is not present. This value sets the\\nMax-Age attribute value."', args=[d.arg(name='ttl', type=d.T.string)]),
                      withTtl(ttl): { als+: { backendSettings+: { loadBalancer+: { consistentHash+: { cookie+: { ttl: ttl } } } } } },
                    },
                    '#header':: d.obj(help='"Header configures the header hash policy when the consistent hash type is set to Header."'),
                    header: {
                      '#withName':: d.fn(help='"Name of the header to hash."', args=[d.arg(name='name', type=d.T.string)]),
                      withName(name): { als+: { backendSettings+: { loadBalancer+: { consistentHash+: { header+: { name: name } } } } } },
                    },
                    '#withTableSize':: d.fn(help='"The table size for consistent hashing, must be prime number limited to 5000011."', args=[d.arg(name='tableSize', type=d.T.integer)]),
                    withTableSize(tableSize): { als+: { backendSettings+: { loadBalancer+: { consistentHash+: { tableSize: tableSize } } } } },
                    '#withType':: d.fn(help='"ConsistentHashType defines the type of input to hash on. Valid Type values are\\n\\"SourceIP\\",\\n\\"Header\\",\\n\\"Cookie\\"."', args=[d.arg(name='type', type=d.T.string)]),
                    withType(type): { als+: { backendSettings+: { loadBalancer+: { consistentHash+: { type: type } } } } },
                  },
                  '#slowStart':: d.obj(help='"SlowStart defines the configuration related to the slow start load balancer policy.\\nIf set, during slow start window, traffic sent to the newly added hosts will gradually increase.\\nCurrently this is only supported for RoundRobin and LeastRequest load balancers"'),
                  slowStart: {
                    '#withWindow':: d.fn(help='"Window defines the duration of the warm up period for newly added host.\\nDuring slow start window, traffic sent to the newly added hosts will gradually increase.\\nCurrently only supports linear growth of traffic. For additional details,\\nsee https://www.envoyproxy.io/docs/envoy/latest/api-v3/config/cluster/v3/cluster.proto#config-cluster-v3-cluster-slowstartconfig"', args=[d.arg(name='window', type=d.T.string)]),
                    withWindow(window): { als+: { backendSettings+: { loadBalancer+: { slowStart+: { window: window } } } } },
                  },
                  '#withType':: d.fn(help='"Type decides the type of Load Balancer policy.\\nValid LoadBalancerType values are\\n\\"ConsistentHash\\",\\n\\"LeastRequest\\",\\n\\"Random\\",\\n\\"RoundRobin\\"."', args=[d.arg(name='type', type=d.T.string)]),
                  withType(type): { als+: { backendSettings+: { loadBalancer+: { type: type } } } },
                },
                '#proxyProtocol':: d.obj(help='"ProxyProtocol enables the Proxy Protocol when communicating with the backend."'),
                proxyProtocol: {
                  '#withVersion':: d.fn(help='"Version of ProxyProtol\\nValid ProxyProtocolVersion values are\\n\\"V1\\"\\n\\"V2\\', args=[d.arg(name='version', type=d.T.string)]),
                  withVersion(version): { als+: { backendSettings+: { proxyProtocol+: { version: version } } } },
                },
                '#retry':: d.obj(help='"Retry provides more advanced usage, allowing users to customize the number of retries, retry fallback strategy, and retry triggering conditions.\\nIf not set, retry will be disabled."'),
                retry: {
                  '#perRetry':: d.obj(help='"PerRetry is the retry policy to be applied per retry attempt."'),
                  perRetry: {
                    '#backOff':: d.obj(help='"Backoff is the backoff policy to be applied per retry attempt. gateway uses a fully jittered exponential\\nback-off algorithm for retries. For additional details,\\nsee https://www.envoyproxy.io/docs/envoy/latest/configuration/http/http_filters/router_filter#config-http-filters-router-x-envoy-max-retries"'),
                    backOff: {
                      '#withBaseInterval':: d.fn(help='"BaseInterval is the base interval between retries."', args=[d.arg(name='baseInterval', type=d.T.string)]),
                      withBaseInterval(baseInterval): { als+: { backendSettings+: { retry+: { perRetry+: { backOff+: { baseInterval: baseInterval } } } } } },
                      '#withMaxInterval':: d.fn(help='"MaxInterval is the maximum interval between retries. This parameter is optional, but must be greater than or equal to the base_interval if set.\\nThe default is 10 times the base_interval"', args=[d.arg(name='maxInterval', type=d.T.string)]),
                      withMaxInterval(maxInterval): { als+: { backendSettings+: { retry+: { perRetry+: { backOff+: { maxInterval: maxInterval } } } } } },
                    },
                    '#withTimeout':: d.fn(help='"Timeout is the timeout per retry attempt."', args=[d.arg(name='timeout', type=d.T.string)]),
                    withTimeout(timeout): { als+: { backendSettings+: { retry+: { perRetry+: { timeout: timeout } } } } },
                  },
                  '#retryOn':: d.obj(help='"RetryOn specifies the retry trigger condition.\\n\\nIf not specified, the default is to retry on connect-failure,refused-stream,unavailable,cancelled,retriable-status-codes(503)."'),
                  retryOn: {
                    '#withHttpStatusCodes':: d.fn(help='"HttpStatusCodes specifies the http status codes to be retried.\\nThe retriable-status-codes trigger must also be configured for these status codes to trigger a retry."', args=[d.arg(name='httpStatusCodes', type=d.T.array)]),
                    withHttpStatusCodes(httpStatusCodes): { als+: { backendSettings+: { retry+: { retryOn+: { httpStatusCodes: if std.isArray(v=httpStatusCodes) then httpStatusCodes else [httpStatusCodes] } } } } },
                    '#withHttpStatusCodesMixin':: d.fn(help='"HttpStatusCodes specifies the http status codes to be retried.\\nThe retriable-status-codes trigger must also be configured for these status codes to trigger a retry."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='httpStatusCodes', type=d.T.array)]),
                    withHttpStatusCodesMixin(httpStatusCodes): { als+: { backendSettings+: { retry+: { retryOn+: { httpStatusCodes+: if std.isArray(v=httpStatusCodes) then httpStatusCodes else [httpStatusCodes] } } } } },
                    '#withTriggers':: d.fn(help='"Triggers specifies the retry trigger condition(Http/Grpc)."', args=[d.arg(name='triggers', type=d.T.array)]),
                    withTriggers(triggers): { als+: { backendSettings+: { retry+: { retryOn+: { triggers: if std.isArray(v=triggers) then triggers else [triggers] } } } } },
                    '#withTriggersMixin':: d.fn(help='"Triggers specifies the retry trigger condition(Http/Grpc)."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='triggers', type=d.T.array)]),
                    withTriggersMixin(triggers): { als+: { backendSettings+: { retry+: { retryOn+: { triggers+: if std.isArray(v=triggers) then triggers else [triggers] } } } } },
                  },
                  '#withNumRetries':: d.fn(help='"NumRetries is the number of retries to be attempted. Defaults to 2."', args=[d.arg(name='numRetries', type=d.T.integer)]),
                  withNumRetries(numRetries): { als+: { backendSettings+: { retry+: { numRetries: numRetries } } } },
                },
                '#tcpKeepalive':: d.obj(help='"TcpKeepalive settings associated with the upstream client connection.\\nDisabled by default."'),
                tcpKeepalive: {
                  '#withIdleTime':: d.fn(help='"The duration a connection needs to be idle before keep-alive\\nprobes start being sent.\\nThe duration format is\\nDefaults to `7200s`."', args=[d.arg(name='idleTime', type=d.T.string)]),
                  withIdleTime(idleTime): { als+: { backendSettings+: { tcpKeepalive+: { idleTime: idleTime } } } },
                  '#withInterval':: d.fn(help='"The duration between keep-alive probes.\\nDefaults to `75s`."', args=[d.arg(name='interval', type=d.T.string)]),
                  withInterval(interval): { als+: { backendSettings+: { tcpKeepalive+: { interval: interval } } } },
                  '#withProbes':: d.fn(help='"The total number of unacknowledged probes to send before deciding\\nthe connection is dead.\\nDefaults to 9."', args=[d.arg(name='probes', type=d.T.integer)]),
                  withProbes(probes): { als+: { backendSettings+: { tcpKeepalive+: { probes: probes } } } },
                },
                '#timeout':: d.obj(help='"Timeout settings for the backend connections."'),
                timeout: {
                  '#http':: d.obj(help='"Timeout settings for HTTP."'),
                  http: {
                    '#withConnectionIdleTimeout':: d.fn(help='"The idle timeout for an HTTP connection. Idle time is defined as a period in which there are no active requests in the connection.\\nDefault: 1 hour."', args=[d.arg(name='connectionIdleTimeout', type=d.T.string)]),
                    withConnectionIdleTimeout(connectionIdleTimeout): { als+: { backendSettings+: { timeout+: { http+: { connectionIdleTimeout: connectionIdleTimeout } } } } },
                    '#withMaxConnectionDuration':: d.fn(help='"The maximum duration of an HTTP connection.\\nDefault: unlimited."', args=[d.arg(name='maxConnectionDuration', type=d.T.string)]),
                    withMaxConnectionDuration(maxConnectionDuration): { als+: { backendSettings+: { timeout+: { http+: { maxConnectionDuration: maxConnectionDuration } } } } },
                    '#withRequestTimeout':: d.fn(help='"RequestTimeout is the time until which entire response is received from the upstream."', args=[d.arg(name='requestTimeout', type=d.T.string)]),
                    withRequestTimeout(requestTimeout): { als+: { backendSettings+: { timeout+: { http+: { requestTimeout: requestTimeout } } } } },
                  },
                  '#tcp':: d.obj(help='"Timeout settings for TCP."'),
                  tcp: {
                    '#withConnectTimeout':: d.fn(help='"The timeout for network connection establishment, including TCP and TLS handshakes.\\nDefault: 10 seconds."', args=[d.arg(name='connectTimeout', type=d.T.string)]),
                    withConnectTimeout(connectTimeout): { als+: { backendSettings+: { timeout+: { tcp+: { connectTimeout: connectTimeout } } } } },
                  },
                },
              },
              '#http':: d.obj(help='"HTTP defines additional configuration specific to HTTP access logs."'),
              http: {
                '#withRequestHeaders':: d.fn(help='"RequestHeaders defines request headers to include in log entries sent to the access log service."', args=[d.arg(name='requestHeaders', type=d.T.array)]),
                withRequestHeaders(requestHeaders): { als+: { http+: { requestHeaders: if std.isArray(v=requestHeaders) then requestHeaders else [requestHeaders] } } },
                '#withRequestHeadersMixin':: d.fn(help='"RequestHeaders defines request headers to include in log entries sent to the access log service."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requestHeaders', type=d.T.array)]),
                withRequestHeadersMixin(requestHeaders): { als+: { http+: { requestHeaders+: if std.isArray(v=requestHeaders) then requestHeaders else [requestHeaders] } } },
                '#withResponseHeaders':: d.fn(help='"ResponseHeaders defines response headers to include in log entries sent to the access log service."', args=[d.arg(name='responseHeaders', type=d.T.array)]),
                withResponseHeaders(responseHeaders): { als+: { http+: { responseHeaders: if std.isArray(v=responseHeaders) then responseHeaders else [responseHeaders] } } },
                '#withResponseHeadersMixin':: d.fn(help='"ResponseHeaders defines response headers to include in log entries sent to the access log service."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='responseHeaders', type=d.T.array)]),
                withResponseHeadersMixin(responseHeaders): { als+: { http+: { responseHeaders+: if std.isArray(v=responseHeaders) then responseHeaders else [responseHeaders] } } },
                '#withResponseTrailers':: d.fn(help='"ResponseTrailers defines response trailers to include in log entries sent to the access log service."', args=[d.arg(name='responseTrailers', type=d.T.array)]),
                withResponseTrailers(responseTrailers): { als+: { http+: { responseTrailers: if std.isArray(v=responseTrailers) then responseTrailers else [responseTrailers] } } },
                '#withResponseTrailersMixin':: d.fn(help='"ResponseTrailers defines response trailers to include in log entries sent to the access log service."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='responseTrailers', type=d.T.array)]),
                withResponseTrailersMixin(responseTrailers): { als+: { http+: { responseTrailers+: if std.isArray(v=responseTrailers) then responseTrailers else [responseTrailers] } } },
              },
              '#withBackendRefs':: d.fn(help='"BackendRefs references a Kubernetes object that represents the\\nbackend server to which the authorization request will be sent."', args=[d.arg(name='backendRefs', type=d.T.array)]),
              withBackendRefs(backendRefs): { als+: { backendRefs: if std.isArray(v=backendRefs) then backendRefs else [backendRefs] } },
              '#withBackendRefsMixin':: d.fn(help='"BackendRefs references a Kubernetes object that represents the\\nbackend server to which the authorization request will be sent."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='backendRefs', type=d.T.array)]),
              withBackendRefsMixin(backendRefs): { als+: { backendRefs+: if std.isArray(v=backendRefs) then backendRefs else [backendRefs] } },
              '#withLogName':: d.fn(help='"LogName defines the friendly name of the access log to be returned in\\nStreamAccessLogsMessage.Identifier. This allows the access log server\\nto differentiate between different access logs coming from the same Envoy."', args=[d.arg(name='logName', type=d.T.string)]),
              withLogName(logName): { als+: { logName: logName } },
              '#withType':: d.fn(help='"Type defines the type of accesslog. Supported types are \\"HTTP\\" and \\"TCP\\"."', args=[d.arg(name='type', type=d.T.string)]),
              withType(type): { als+: { type: type } },
            },
            '#file':: d.obj(help='"File defines the file accesslog sink."'),
            file: {
              '#withPath':: d.fn(help='"Path defines the file path used to expose envoy access log(e.g. /dev/stdout)."', args=[d.arg(name='path', type=d.T.string)]),
              withPath(path): { file+: { path: path } },
            },
            '#openTelemetry':: d.obj(help='"OpenTelemetry defines the OpenTelemetry accesslog sink."'),
            openTelemetry: {
              '#backendRef':: d.obj(help='"BackendRef references a Kubernetes object that represents the\\nbackend server to which the authorization request will be sent.\\n\\nDeprecated: Use BackendRefs instead."'),
              backendRef: {
                '#withGroup':: d.fn(help='"Group is the group of the referent. For example, \\"gateway.networking.k8s.io\\".\\nWhen unspecified or empty string, core API group is inferred."', args=[d.arg(name='group', type=d.T.string)]),
                withGroup(group): { openTelemetry+: { backendRef+: { group: group } } },
                '#withKind':: d.fn(help='"Kind is the Kubernetes resource kind of the referent. For example\\n\\"Service\\".\\n\\nDefaults to \\"Service\\" when not specified.\\n\\nExternalName services can refer to CNAME DNS records that may live\\noutside of the cluster and as such are difficult to reason about in\\nterms of conformance. They also may not be safe to forward to (see\\nCVE-2021-25740 for more information). Implementations SHOULD NOT\\nsupport ExternalName Services.\\n\\nSupport: Core (Services with a type other than ExternalName)\\n\\nSupport: Implementation-specific (Services with type ExternalName)"', args=[d.arg(name='kind', type=d.T.string)]),
                withKind(kind): { openTelemetry+: { backendRef+: { kind: kind } } },
                '#withName':: d.fn(help='"Name is the name of the referent."', args=[d.arg(name='name', type=d.T.string)]),
                withName(name): { openTelemetry+: { backendRef+: { name: name } } },
                '#withNamespace':: d.fn(help="\"Namespace is the namespace of the backend. When unspecified, the local\\nnamespace is inferred.\\n\\nNote that when a namespace different than the local namespace is specified,\\na ReferenceGrant object is required in the referent namespace to allow that\\nnamespace's owner to accept the reference. See the ReferenceGrant\\ndocumentation for details.\\n\\nSupport: Core\"", args=[d.arg(name='namespace', type=d.T.string)]),
                withNamespace(namespace): { openTelemetry+: { backendRef+: { namespace: namespace } } },
                '#withPort':: d.fn(help='"Port specifies the destination port number to use for this resource.\\nPort is required when the referent is a Kubernetes Service. In this\\ncase, the port number is the service port number, not the target port.\\nFor other resources, destination port might be derived from the referent\\nresource or this field."', args=[d.arg(name='port', type=d.T.integer)]),
                withPort(port): { openTelemetry+: { backendRef+: { port: port } } },
              },
              '#backendRefs':: d.obj(help='"BackendRefs references a Kubernetes object that represents the\\nbackend server to which the authorization request will be sent."'),
              backendRefs: {
                '#withFallback':: d.fn(help='"Fallback indicates whether the backend is designated as a fallback.\\nMultiple fallback backends can be configured.\\nIt is highly recommended to configure active or passive health checks to ensure that failover can be detected\\nwhen the active backends become unhealthy and to automatically readjust once the primary backends are healthy again.\\nThe overprovisioning factor is set to 1.4, meaning the fallback backends will only start receiving traffic when\\nthe health of the active backends falls below 72%."', args=[d.arg(name='fallback', type=d.T.boolean)]),
                withFallback(fallback): { fallback: fallback },
                '#withGroup':: d.fn(help='"Group is the group of the referent. For example, \\"gateway.networking.k8s.io\\".\\nWhen unspecified or empty string, core API group is inferred."', args=[d.arg(name='group', type=d.T.string)]),
                withGroup(group): { group: group },
                '#withKind':: d.fn(help='"Kind is the Kubernetes resource kind of the referent. For example\\n\\"Service\\".\\n\\nDefaults to \\"Service\\" when not specified.\\n\\nExternalName services can refer to CNAME DNS records that may live\\noutside of the cluster and as such are difficult to reason about in\\nterms of conformance. They also may not be safe to forward to (see\\nCVE-2021-25740 for more information). Implementations SHOULD NOT\\nsupport ExternalName Services.\\n\\nSupport: Core (Services with a type other than ExternalName)\\n\\nSupport: Implementation-specific (Services with type ExternalName)"', args=[d.arg(name='kind', type=d.T.string)]),
                withKind(kind): { kind: kind },
                '#withName':: d.fn(help='"Name is the name of the referent."', args=[d.arg(name='name', type=d.T.string)]),
                withName(name): { name: name },
                '#withNamespace':: d.fn(help="\"Namespace is the namespace of the backend. When unspecified, the local\\nnamespace is inferred.\\n\\nNote that when a namespace different than the local namespace is specified,\\na ReferenceGrant object is required in the referent namespace to allow that\\nnamespace's owner to accept the reference. See the ReferenceGrant\\ndocumentation for details.\\n\\nSupport: Core\"", args=[d.arg(name='namespace', type=d.T.string)]),
                withNamespace(namespace): { namespace: namespace },
                '#withPort':: d.fn(help='"Port specifies the destination port number to use for this resource.\\nPort is required when the referent is a Kubernetes Service. In this\\ncase, the port number is the service port number, not the target port.\\nFor other resources, destination port might be derived from the referent\\nresource or this field."', args=[d.arg(name='port', type=d.T.integer)]),
                withPort(port): { port: port },
              },
              '#backendSettings':: d.obj(help='"BackendSettings holds configuration for managing the connection\\nto the backend."'),
              backendSettings: {
                '#circuitBreaker':: d.obj(help='"Circuit Breaker settings for the upstream connections and requests.\\nIf not set, circuit breakers will be enabled with the default thresholds"'),
                circuitBreaker: {
                  '#perEndpoint':: d.obj(help='"PerEndpoint defines Circuit Breakers that will apply per-endpoint for an upstream cluster"'),
                  perEndpoint: {
                    '#withMaxConnections':: d.fn(help='"MaxConnections configures the maximum number of connections that Envoy will establish per-endpoint to the referenced backend defined within a xRoute rule."', args=[d.arg(name='maxConnections', type=d.T.integer)]),
                    withMaxConnections(maxConnections): { openTelemetry+: { backendSettings+: { circuitBreaker+: { perEndpoint+: { maxConnections: maxConnections } } } } },
                  },
                  '#withMaxConnections':: d.fn(help='"The maximum number of connections that Envoy will establish to the referenced backend defined within a xRoute rule."', args=[d.arg(name='maxConnections', type=d.T.integer)]),
                  withMaxConnections(maxConnections): { openTelemetry+: { backendSettings+: { circuitBreaker+: { maxConnections: maxConnections } } } },
                  '#withMaxParallelRequests':: d.fn(help='"The maximum number of parallel requests that Envoy will make to the referenced backend defined within a xRoute rule."', args=[d.arg(name='maxParallelRequests', type=d.T.integer)]),
                  withMaxParallelRequests(maxParallelRequests): { openTelemetry+: { backendSettings+: { circuitBreaker+: { maxParallelRequests: maxParallelRequests } } } },
                  '#withMaxParallelRetries':: d.fn(help='"The maximum number of parallel retries that Envoy will make to the referenced backend defined within a xRoute rule."', args=[d.arg(name='maxParallelRetries', type=d.T.integer)]),
                  withMaxParallelRetries(maxParallelRetries): { openTelemetry+: { backendSettings+: { circuitBreaker+: { maxParallelRetries: maxParallelRetries } } } },
                  '#withMaxPendingRequests':: d.fn(help='"The maximum number of pending requests that Envoy will queue to the referenced backend defined within a xRoute rule."', args=[d.arg(name='maxPendingRequests', type=d.T.integer)]),
                  withMaxPendingRequests(maxPendingRequests): { openTelemetry+: { backendSettings+: { circuitBreaker+: { maxPendingRequests: maxPendingRequests } } } },
                  '#withMaxRequestsPerConnection':: d.fn(help='"The maximum number of requests that Envoy will make over a single connection to the referenced backend defined within a xRoute rule.\\nDefault: unlimited."', args=[d.arg(name='maxRequestsPerConnection', type=d.T.integer)]),
                  withMaxRequestsPerConnection(maxRequestsPerConnection): { openTelemetry+: { backendSettings+: { circuitBreaker+: { maxRequestsPerConnection: maxRequestsPerConnection } } } },
                },
                '#connection':: d.obj(help='"Connection includes backend connection settings."'),
                connection: {
                  '#withBufferLimit':: d.fn(help="\"BufferLimit Soft limit on size of the cluster’s connections read and write buffers.\\nBufferLimit applies to connection streaming (maybe non-streaming) channel between processes, it's in user space.\\nIf unspecified, an implementation defined default is applied (32768 bytes).\\nFor example, 20Mi, 1Gi, 256Ki etc.\\nNote: that when the suffix is not provided, the value is interpreted as bytes.\"", args=[d.arg(name='bufferLimit', type=d.T.any)]),
                  withBufferLimit(bufferLimit): { openTelemetry+: { backendSettings+: { connection+: { bufferLimit: bufferLimit } } } },
                  '#withSocketBufferLimit':: d.fn(help="\"SocketBufferLimit provides configuration for the maximum buffer size in bytes for each socket\\nto backend.\\nSocketBufferLimit applies to socket streaming channel between TCP/IP stacks, it's in kernel space.\\nFor example, 20Mi, 1Gi, 256Ki etc.\\nNote that when the suffix is not provided, the value is interpreted as bytes.\"", args=[d.arg(name='socketBufferLimit', type=d.T.any)]),
                  withSocketBufferLimit(socketBufferLimit): { openTelemetry+: { backendSettings+: { connection+: { socketBufferLimit: socketBufferLimit } } } },
                },
                '#dns':: d.obj(help='"DNS includes dns resolution settings."'),
                dns: {
                  '#withDnsRefreshRate':: d.fn(help='"DNSRefreshRate specifies the rate at which DNS records should be refreshed.\\nDefaults to 30 seconds."', args=[d.arg(name='dnsRefreshRate', type=d.T.string)]),
                  withDnsRefreshRate(dnsRefreshRate): { openTelemetry+: { backendSettings+: { dns+: { dnsRefreshRate: dnsRefreshRate } } } },
                  '#withLookupFamily':: d.fn(help='"LookupFamily determines how Envoy would resolve DNS for Routes where the backend is specified as a fully qualified domain name (FQDN).\\nIf set, this configuration overrides other defaults."', args=[d.arg(name='lookupFamily', type=d.T.string)]),
                  withLookupFamily(lookupFamily): { openTelemetry+: { backendSettings+: { dns+: { lookupFamily: lookupFamily } } } },
                  '#withRespectDnsTtl':: d.fn(help='"RespectDNSTTL indicates whether the DNS Time-To-Live (TTL) should be respected.\\nIf the value is set to true, the DNS refresh rate will be set to the resource record’s TTL.\\nDefaults to true."', args=[d.arg(name='respectDnsTtl', type=d.T.boolean)]),
                  withRespectDnsTtl(respectDnsTtl): { openTelemetry+: { backendSettings+: { dns+: { respectDnsTtl: respectDnsTtl } } } },
                },
                '#healthCheck':: d.obj(help='"HealthCheck allows gateway to perform active health checking on backends."'),
                healthCheck: {
                  '#active':: d.obj(help='"Active health check configuration"'),
                  active: {
                    '#grpc':: d.obj(help="\"GRPC defines the configuration of the GRPC health checker.\\nIt's optional, and can only be used if the specified type is GRPC.\""),
                    grpc: {
                      '#withService':: d.fn(help='"Service to send in the health check request.\\nIf this is not specified, then the health check request applies to the entire\\nserver and not to a specific service."', args=[d.arg(name='service', type=d.T.string)]),
                      withService(service): { openTelemetry+: { backendSettings+: { healthCheck+: { active+: { grpc+: { service: service } } } } } },
                    },
                    '#http':: d.obj(help="\"HTTP defines the configuration of http health checker.\\nIt's required while the health checker type is HTTP.\""),
                    http: {
                      '#expectedResponse':: d.obj(help='"ExpectedResponse defines a list of HTTP expected responses to match."'),
                      expectedResponse: {
                        '#withBinary':: d.fn(help='"Binary payload base64 encoded."', args=[d.arg(name='binary', type=d.T.string)]),
                        withBinary(binary): { openTelemetry+: { backendSettings+: { healthCheck+: { active+: { http+: { expectedResponse+: { binary: binary } } } } } } },
                        '#withText':: d.fn(help='"Text payload in plain text."', args=[d.arg(name='text', type=d.T.string)]),
                        withText(text): { openTelemetry+: { backendSettings+: { healthCheck+: { active+: { http+: { expectedResponse+: { text: text } } } } } } },
                        '#withType':: d.fn(help='"Type defines the type of the payload."', args=[d.arg(name='type', type=d.T.string)]),
                        withType(type): { openTelemetry+: { backendSettings+: { healthCheck+: { active+: { http+: { expectedResponse+: { type: type } } } } } } },
                      },
                      '#withExpectedStatuses':: d.fn(help='"ExpectedStatuses defines a list of HTTP response statuses considered healthy.\\nDefaults to 200 only"', args=[d.arg(name='expectedStatuses', type=d.T.array)]),
                      withExpectedStatuses(expectedStatuses): { openTelemetry+: { backendSettings+: { healthCheck+: { active+: { http+: { expectedStatuses: if std.isArray(v=expectedStatuses) then expectedStatuses else [expectedStatuses] } } } } } },
                      '#withExpectedStatusesMixin':: d.fn(help='"ExpectedStatuses defines a list of HTTP response statuses considered healthy.\\nDefaults to 200 only"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='expectedStatuses', type=d.T.array)]),
                      withExpectedStatusesMixin(expectedStatuses): { openTelemetry+: { backendSettings+: { healthCheck+: { active+: { http+: { expectedStatuses+: if std.isArray(v=expectedStatuses) then expectedStatuses else [expectedStatuses] } } } } } },
                      '#withMethod':: d.fn(help='"Method defines the HTTP method used for health checking.\\nDefaults to GET"', args=[d.arg(name='method', type=d.T.string)]),
                      withMethod(method): { openTelemetry+: { backendSettings+: { healthCheck+: { active+: { http+: { method: method } } } } } },
                      '#withPath':: d.fn(help='"Path defines the HTTP path that will be requested during health checking."', args=[d.arg(name='path', type=d.T.string)]),
                      withPath(path): { openTelemetry+: { backendSettings+: { healthCheck+: { active+: { http+: { path: path } } } } } },
                    },
                    '#tcp':: d.obj(help="\"TCP defines the configuration of tcp health checker.\\nIt's required while the health checker type is TCP.\""),
                    tcp: {
                      '#receive':: d.obj(help='"Receive defines the expected response payload."'),
                      receive: {
                        '#withBinary':: d.fn(help='"Binary payload base64 encoded."', args=[d.arg(name='binary', type=d.T.string)]),
                        withBinary(binary): { openTelemetry+: { backendSettings+: { healthCheck+: { active+: { tcp+: { receive+: { binary: binary } } } } } } },
                        '#withText':: d.fn(help='"Text payload in plain text."', args=[d.arg(name='text', type=d.T.string)]),
                        withText(text): { openTelemetry+: { backendSettings+: { healthCheck+: { active+: { tcp+: { receive+: { text: text } } } } } } },
                        '#withType':: d.fn(help='"Type defines the type of the payload."', args=[d.arg(name='type', type=d.T.string)]),
                        withType(type): { openTelemetry+: { backendSettings+: { healthCheck+: { active+: { tcp+: { receive+: { type: type } } } } } } },
                      },
                      '#send':: d.obj(help='"Send defines the request payload."'),
                      send: {
                        '#withBinary':: d.fn(help='"Binary payload base64 encoded."', args=[d.arg(name='binary', type=d.T.string)]),
                        withBinary(binary): { openTelemetry+: { backendSettings+: { healthCheck+: { active+: { tcp+: { send+: { binary: binary } } } } } } },
                        '#withText':: d.fn(help='"Text payload in plain text."', args=[d.arg(name='text', type=d.T.string)]),
                        withText(text): { openTelemetry+: { backendSettings+: { healthCheck+: { active+: { tcp+: { send+: { text: text } } } } } } },
                        '#withType':: d.fn(help='"Type defines the type of the payload."', args=[d.arg(name='type', type=d.T.string)]),
                        withType(type): { openTelemetry+: { backendSettings+: { healthCheck+: { active+: { tcp+: { send+: { type: type } } } } } } },
                      },
                    },
                    '#withHealthyThreshold':: d.fn(help='"HealthyThreshold defines the number of healthy health checks required before a backend host is marked healthy."', args=[d.arg(name='healthyThreshold', type=d.T.integer)]),
                    withHealthyThreshold(healthyThreshold): { openTelemetry+: { backendSettings+: { healthCheck+: { active+: { healthyThreshold: healthyThreshold } } } } },
                    '#withInterval':: d.fn(help='"Interval defines the time between active health checks."', args=[d.arg(name='interval', type=d.T.string)]),
                    withInterval(interval): { openTelemetry+: { backendSettings+: { healthCheck+: { active+: { interval: interval } } } } },
                    '#withTimeout':: d.fn(help='"Timeout defines the time to wait for a health check response."', args=[d.arg(name='timeout', type=d.T.string)]),
                    withTimeout(timeout): { openTelemetry+: { backendSettings+: { healthCheck+: { active+: { timeout: timeout } } } } },
                    '#withType':: d.fn(help='"Type defines the type of health checker."', args=[d.arg(name='type', type=d.T.string)]),
                    withType(type): { openTelemetry+: { backendSettings+: { healthCheck+: { active+: { type: type } } } } },
                    '#withUnhealthyThreshold':: d.fn(help='"UnhealthyThreshold defines the number of unhealthy health checks required before a backend host is marked unhealthy."', args=[d.arg(name='unhealthyThreshold', type=d.T.integer)]),
                    withUnhealthyThreshold(unhealthyThreshold): { openTelemetry+: { backendSettings+: { healthCheck+: { active+: { unhealthyThreshold: unhealthyThreshold } } } } },
                  },
                  '#passive':: d.obj(help='"Passive passive check configuration"'),
                  passive: {
                    '#withBaseEjectionTime':: d.fn(help='"BaseEjectionTime defines the base duration for which a host will be ejected on consecutive failures."', args=[d.arg(name='baseEjectionTime', type=d.T.string)]),
                    withBaseEjectionTime(baseEjectionTime): { openTelemetry+: { backendSettings+: { healthCheck+: { passive+: { baseEjectionTime: baseEjectionTime } } } } },
                    '#withConsecutive5XxErrors':: d.fn(help='"Consecutive5xxErrors sets the number of consecutive 5xx errors triggering ejection."', args=[d.arg(name='consecutive5XxErrors', type=d.T.integer)]),
                    withConsecutive5XxErrors(consecutive5XxErrors): { openTelemetry+: { backendSettings+: { healthCheck+: { passive+: { consecutive5XxErrors: consecutive5XxErrors } } } } },
                    '#withConsecutiveGatewayErrors':: d.fn(help='"ConsecutiveGatewayErrors sets the number of consecutive gateway errors triggering ejection."', args=[d.arg(name='consecutiveGatewayErrors', type=d.T.integer)]),
                    withConsecutiveGatewayErrors(consecutiveGatewayErrors): { openTelemetry+: { backendSettings+: { healthCheck+: { passive+: { consecutiveGatewayErrors: consecutiveGatewayErrors } } } } },
                    '#withConsecutiveLocalOriginFailures':: d.fn(help='"ConsecutiveLocalOriginFailures sets the number of consecutive local origin failures triggering ejection.\\nParameter takes effect only when split_external_local_origin_errors is set to true."', args=[d.arg(name='consecutiveLocalOriginFailures', type=d.T.integer)]),
                    withConsecutiveLocalOriginFailures(consecutiveLocalOriginFailures): { openTelemetry+: { backendSettings+: { healthCheck+: { passive+: { consecutiveLocalOriginFailures: consecutiveLocalOriginFailures } } } } },
                    '#withInterval':: d.fn(help='"Interval defines the time between passive health checks."', args=[d.arg(name='interval', type=d.T.string)]),
                    withInterval(interval): { openTelemetry+: { backendSettings+: { healthCheck+: { passive+: { interval: interval } } } } },
                    '#withMaxEjectionPercent':: d.fn(help='"MaxEjectionPercent sets the maximum percentage of hosts in a cluster that can be ejected."', args=[d.arg(name='maxEjectionPercent', type=d.T.integer)]),
                    withMaxEjectionPercent(maxEjectionPercent): { openTelemetry+: { backendSettings+: { healthCheck+: { passive+: { maxEjectionPercent: maxEjectionPercent } } } } },
                    '#withSplitExternalLocalOriginErrors':: d.fn(help='"SplitExternalLocalOriginErrors enables splitting of errors between external and local origin."', args=[d.arg(name='splitExternalLocalOriginErrors', type=d.T.boolean)]),
                    withSplitExternalLocalOriginErrors(splitExternalLocalOriginErrors): { openTelemetry+: { backendSettings+: { healthCheck+: { passive+: { splitExternalLocalOriginErrors: splitExternalLocalOriginErrors } } } } },
                  },
                  '#withPanicThreshold':: d.fn(help="\"When number of unhealthy endpoints for a backend reaches this threshold\\nEnvoy will disregard health status and balance across all endpoints.\\nIt's designed to prevent a situation in which host failures cascade throughout the cluster\\nas load increases. If not set, the default value is 50%. To disable panic mode, set value to `0`.\"", args=[d.arg(name='panicThreshold', type=d.T.integer)]),
                  withPanicThreshold(panicThreshold): { openTelemetry+: { backendSettings+: { healthCheck+: { panicThreshold: panicThreshold } } } },
                },
                '#http2':: d.obj(help='"HTTP2 provides HTTP/2 configuration for backend connections."'),
                http2: {
                  '#withInitialConnectionWindowSize':: d.fn(help='"InitialConnectionWindowSize sets the initial window size for HTTP/2 connections.\\nIf not set, the default value is 1 MiB."', args=[d.arg(name='initialConnectionWindowSize', type=d.T.any)]),
                  withInitialConnectionWindowSize(initialConnectionWindowSize): { openTelemetry+: { backendSettings+: { http2+: { initialConnectionWindowSize: initialConnectionWindowSize } } } },
                  '#withInitialStreamWindowSize':: d.fn(help='"InitialStreamWindowSize sets the initial window size for HTTP/2 streams.\\nIf not set, the default value is 64 KiB(64*1024)."', args=[d.arg(name='initialStreamWindowSize', type=d.T.any)]),
                  withInitialStreamWindowSize(initialStreamWindowSize): { openTelemetry+: { backendSettings+: { http2+: { initialStreamWindowSize: initialStreamWindowSize } } } },
                  '#withMaxConcurrentStreams':: d.fn(help='"MaxConcurrentStreams sets the maximum number of concurrent streams allowed per connection.\\nIf not set, the default value is 100."', args=[d.arg(name='maxConcurrentStreams', type=d.T.integer)]),
                  withMaxConcurrentStreams(maxConcurrentStreams): { openTelemetry+: { backendSettings+: { http2+: { maxConcurrentStreams: maxConcurrentStreams } } } },
                  '#withOnInvalidMessage':: d.fn(help="\"OnInvalidMessage determines if Envoy will terminate the connection or just the offending stream in the event of HTTP messaging error\\nIt's recommended for L2 Envoy deployments to set this value to TerminateStream.\\nhttps://www.envoyproxy.io/docs/envoy/latest/configuration/best_practices/level_two\\nDefault: TerminateConnection\"", args=[d.arg(name='onInvalidMessage', type=d.T.string)]),
                  withOnInvalidMessage(onInvalidMessage): { openTelemetry+: { backendSettings+: { http2+: { onInvalidMessage: onInvalidMessage } } } },
                },
                '#loadBalancer':: d.obj(help='"LoadBalancer policy to apply when routing traffic from the gateway to\\nthe backend endpoints. Defaults to `LeastRequest`."'),
                loadBalancer: {
                  '#consistentHash':: d.obj(help='"ConsistentHash defines the configuration when the load balancer type is\\nset to ConsistentHash"'),
                  consistentHash: {
                    '#cookie':: d.obj(help='"Cookie configures the cookie hash policy when the consistent hash type is set to Cookie."'),
                    cookie: {
                      '#withAttributes':: d.fn(help='"Additional Attributes to set for the generated cookie."', args=[d.arg(name='attributes', type=d.T.object)]),
                      withAttributes(attributes): { openTelemetry+: { backendSettings+: { loadBalancer+: { consistentHash+: { cookie+: { attributes: attributes } } } } } },
                      '#withAttributesMixin':: d.fn(help='"Additional Attributes to set for the generated cookie."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='attributes', type=d.T.object)]),
                      withAttributesMixin(attributes): { openTelemetry+: { backendSettings+: { loadBalancer+: { consistentHash+: { cookie+: { attributes+: attributes } } } } } },
                      '#withName':: d.fn(help='"Name of the cookie to hash.\\nIf this cookie does not exist in the request, Envoy will generate a cookie and set\\nthe TTL on the response back to the client based on Layer 4\\nattributes of the backend endpoint, to ensure that these future requests\\ngo to the same backend endpoint. Make sure to set the TTL field for this case."', args=[d.arg(name='name', type=d.T.string)]),
                      withName(name): { openTelemetry+: { backendSettings+: { loadBalancer+: { consistentHash+: { cookie+: { name: name } } } } } },
                      '#withTtl':: d.fn(help='"TTL of the generated cookie if the cookie is not present. This value sets the\\nMax-Age attribute value."', args=[d.arg(name='ttl', type=d.T.string)]),
                      withTtl(ttl): { openTelemetry+: { backendSettings+: { loadBalancer+: { consistentHash+: { cookie+: { ttl: ttl } } } } } },
                    },
                    '#header':: d.obj(help='"Header configures the header hash policy when the consistent hash type is set to Header."'),
                    header: {
                      '#withName':: d.fn(help='"Name of the header to hash."', args=[d.arg(name='name', type=d.T.string)]),
                      withName(name): { openTelemetry+: { backendSettings+: { loadBalancer+: { consistentHash+: { header+: { name: name } } } } } },
                    },
                    '#withTableSize':: d.fn(help='"The table size for consistent hashing, must be prime number limited to 5000011."', args=[d.arg(name='tableSize', type=d.T.integer)]),
                    withTableSize(tableSize): { openTelemetry+: { backendSettings+: { loadBalancer+: { consistentHash+: { tableSize: tableSize } } } } },
                    '#withType':: d.fn(help='"ConsistentHashType defines the type of input to hash on. Valid Type values are\\n\\"SourceIP\\",\\n\\"Header\\",\\n\\"Cookie\\"."', args=[d.arg(name='type', type=d.T.string)]),
                    withType(type): { openTelemetry+: { backendSettings+: { loadBalancer+: { consistentHash+: { type: type } } } } },
                  },
                  '#slowStart':: d.obj(help='"SlowStart defines the configuration related to the slow start load balancer policy.\\nIf set, during slow start window, traffic sent to the newly added hosts will gradually increase.\\nCurrently this is only supported for RoundRobin and LeastRequest load balancers"'),
                  slowStart: {
                    '#withWindow':: d.fn(help='"Window defines the duration of the warm up period for newly added host.\\nDuring slow start window, traffic sent to the newly added hosts will gradually increase.\\nCurrently only supports linear growth of traffic. For additional details,\\nsee https://www.envoyproxy.io/docs/envoy/latest/api-v3/config/cluster/v3/cluster.proto#config-cluster-v3-cluster-slowstartconfig"', args=[d.arg(name='window', type=d.T.string)]),
                    withWindow(window): { openTelemetry+: { backendSettings+: { loadBalancer+: { slowStart+: { window: window } } } } },
                  },
                  '#withType':: d.fn(help='"Type decides the type of Load Balancer policy.\\nValid LoadBalancerType values are\\n\\"ConsistentHash\\",\\n\\"LeastRequest\\",\\n\\"Random\\",\\n\\"RoundRobin\\"."', args=[d.arg(name='type', type=d.T.string)]),
                  withType(type): { openTelemetry+: { backendSettings+: { loadBalancer+: { type: type } } } },
                },
                '#proxyProtocol':: d.obj(help='"ProxyProtocol enables the Proxy Protocol when communicating with the backend."'),
                proxyProtocol: {
                  '#withVersion':: d.fn(help='"Version of ProxyProtol\\nValid ProxyProtocolVersion values are\\n\\"V1\\"\\n\\"V2\\', args=[d.arg(name='version', type=d.T.string)]),
                  withVersion(version): { openTelemetry+: { backendSettings+: { proxyProtocol+: { version: version } } } },
                },
                '#retry':: d.obj(help='"Retry provides more advanced usage, allowing users to customize the number of retries, retry fallback strategy, and retry triggering conditions.\\nIf not set, retry will be disabled."'),
                retry: {
                  '#perRetry':: d.obj(help='"PerRetry is the retry policy to be applied per retry attempt."'),
                  perRetry: {
                    '#backOff':: d.obj(help='"Backoff is the backoff policy to be applied per retry attempt. gateway uses a fully jittered exponential\\nback-off algorithm for retries. For additional details,\\nsee https://www.envoyproxy.io/docs/envoy/latest/configuration/http/http_filters/router_filter#config-http-filters-router-x-envoy-max-retries"'),
                    backOff: {
                      '#withBaseInterval':: d.fn(help='"BaseInterval is the base interval between retries."', args=[d.arg(name='baseInterval', type=d.T.string)]),
                      withBaseInterval(baseInterval): { openTelemetry+: { backendSettings+: { retry+: { perRetry+: { backOff+: { baseInterval: baseInterval } } } } } },
                      '#withMaxInterval':: d.fn(help='"MaxInterval is the maximum interval between retries. This parameter is optional, but must be greater than or equal to the base_interval if set.\\nThe default is 10 times the base_interval"', args=[d.arg(name='maxInterval', type=d.T.string)]),
                      withMaxInterval(maxInterval): { openTelemetry+: { backendSettings+: { retry+: { perRetry+: { backOff+: { maxInterval: maxInterval } } } } } },
                    },
                    '#withTimeout':: d.fn(help='"Timeout is the timeout per retry attempt."', args=[d.arg(name='timeout', type=d.T.string)]),
                    withTimeout(timeout): { openTelemetry+: { backendSettings+: { retry+: { perRetry+: { timeout: timeout } } } } },
                  },
                  '#retryOn':: d.obj(help='"RetryOn specifies the retry trigger condition.\\n\\nIf not specified, the default is to retry on connect-failure,refused-stream,unavailable,cancelled,retriable-status-codes(503)."'),
                  retryOn: {
                    '#withHttpStatusCodes':: d.fn(help='"HttpStatusCodes specifies the http status codes to be retried.\\nThe retriable-status-codes trigger must also be configured for these status codes to trigger a retry."', args=[d.arg(name='httpStatusCodes', type=d.T.array)]),
                    withHttpStatusCodes(httpStatusCodes): { openTelemetry+: { backendSettings+: { retry+: { retryOn+: { httpStatusCodes: if std.isArray(v=httpStatusCodes) then httpStatusCodes else [httpStatusCodes] } } } } },
                    '#withHttpStatusCodesMixin':: d.fn(help='"HttpStatusCodes specifies the http status codes to be retried.\\nThe retriable-status-codes trigger must also be configured for these status codes to trigger a retry."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='httpStatusCodes', type=d.T.array)]),
                    withHttpStatusCodesMixin(httpStatusCodes): { openTelemetry+: { backendSettings+: { retry+: { retryOn+: { httpStatusCodes+: if std.isArray(v=httpStatusCodes) then httpStatusCodes else [httpStatusCodes] } } } } },
                    '#withTriggers':: d.fn(help='"Triggers specifies the retry trigger condition(Http/Grpc)."', args=[d.arg(name='triggers', type=d.T.array)]),
                    withTriggers(triggers): { openTelemetry+: { backendSettings+: { retry+: { retryOn+: { triggers: if std.isArray(v=triggers) then triggers else [triggers] } } } } },
                    '#withTriggersMixin':: d.fn(help='"Triggers specifies the retry trigger condition(Http/Grpc)."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='triggers', type=d.T.array)]),
                    withTriggersMixin(triggers): { openTelemetry+: { backendSettings+: { retry+: { retryOn+: { triggers+: if std.isArray(v=triggers) then triggers else [triggers] } } } } },
                  },
                  '#withNumRetries':: d.fn(help='"NumRetries is the number of retries to be attempted. Defaults to 2."', args=[d.arg(name='numRetries', type=d.T.integer)]),
                  withNumRetries(numRetries): { openTelemetry+: { backendSettings+: { retry+: { numRetries: numRetries } } } },
                },
                '#tcpKeepalive':: d.obj(help='"TcpKeepalive settings associated with the upstream client connection.\\nDisabled by default."'),
                tcpKeepalive: {
                  '#withIdleTime':: d.fn(help='"The duration a connection needs to be idle before keep-alive\\nprobes start being sent.\\nThe duration format is\\nDefaults to `7200s`."', args=[d.arg(name='idleTime', type=d.T.string)]),
                  withIdleTime(idleTime): { openTelemetry+: { backendSettings+: { tcpKeepalive+: { idleTime: idleTime } } } },
                  '#withInterval':: d.fn(help='"The duration between keep-alive probes.\\nDefaults to `75s`."', args=[d.arg(name='interval', type=d.T.string)]),
                  withInterval(interval): { openTelemetry+: { backendSettings+: { tcpKeepalive+: { interval: interval } } } },
                  '#withProbes':: d.fn(help='"The total number of unacknowledged probes to send before deciding\\nthe connection is dead.\\nDefaults to 9."', args=[d.arg(name='probes', type=d.T.integer)]),
                  withProbes(probes): { openTelemetry+: { backendSettings+: { tcpKeepalive+: { probes: probes } } } },
                },
                '#timeout':: d.obj(help='"Timeout settings for the backend connections."'),
                timeout: {
                  '#http':: d.obj(help='"Timeout settings for HTTP."'),
                  http: {
                    '#withConnectionIdleTimeout':: d.fn(help='"The idle timeout for an HTTP connection. Idle time is defined as a period in which there are no active requests in the connection.\\nDefault: 1 hour."', args=[d.arg(name='connectionIdleTimeout', type=d.T.string)]),
                    withConnectionIdleTimeout(connectionIdleTimeout): { openTelemetry+: { backendSettings+: { timeout+: { http+: { connectionIdleTimeout: connectionIdleTimeout } } } } },
                    '#withMaxConnectionDuration':: d.fn(help='"The maximum duration of an HTTP connection.\\nDefault: unlimited."', args=[d.arg(name='maxConnectionDuration', type=d.T.string)]),
                    withMaxConnectionDuration(maxConnectionDuration): { openTelemetry+: { backendSettings+: { timeout+: { http+: { maxConnectionDuration: maxConnectionDuration } } } } },
                    '#withRequestTimeout':: d.fn(help='"RequestTimeout is the time until which entire response is received from the upstream."', args=[d.arg(name='requestTimeout', type=d.T.string)]),
                    withRequestTimeout(requestTimeout): { openTelemetry+: { backendSettings+: { timeout+: { http+: { requestTimeout: requestTimeout } } } } },
                  },
                  '#tcp':: d.obj(help='"Timeout settings for TCP."'),
                  tcp: {
                    '#withConnectTimeout':: d.fn(help='"The timeout for network connection establishment, including TCP and TLS handshakes.\\nDefault: 10 seconds."', args=[d.arg(name='connectTimeout', type=d.T.string)]),
                    withConnectTimeout(connectTimeout): { openTelemetry+: { backendSettings+: { timeout+: { tcp+: { connectTimeout: connectTimeout } } } } },
                  },
                },
              },
              '#withBackendRefs':: d.fn(help='"BackendRefs references a Kubernetes object that represents the\\nbackend server to which the authorization request will be sent."', args=[d.arg(name='backendRefs', type=d.T.array)]),
              withBackendRefs(backendRefs): { openTelemetry+: { backendRefs: if std.isArray(v=backendRefs) then backendRefs else [backendRefs] } },
              '#withBackendRefsMixin':: d.fn(help='"BackendRefs references a Kubernetes object that represents the\\nbackend server to which the authorization request will be sent."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='backendRefs', type=d.T.array)]),
              withBackendRefsMixin(backendRefs): { openTelemetry+: { backendRefs+: if std.isArray(v=backendRefs) then backendRefs else [backendRefs] } },
              '#withHost':: d.fn(help='"Host define the extension service hostname.\\nDeprecated: Use BackendRefs instead."', args=[d.arg(name='host', type=d.T.string)]),
              withHost(host): { openTelemetry+: { host: host } },
              '#withPort':: d.fn(help='"Port defines the port the extension service is exposed on.\\nDeprecated: Use BackendRefs instead."', args=[d.arg(name='port', type=d.T.integer)]),
              withPort(port): { openTelemetry+: { port: port } },
              '#withResources':: d.fn(help="\"Resources is a set of labels that describe the source of a log entry, including envoy node info.\\nIt's recommended to follow [semantic conventions](https://opentelemetry.io/docs/reference/specification/resource/semantic_conventions/).\"", args=[d.arg(name='resources', type=d.T.object)]),
              withResources(resources): { openTelemetry+: { resources: resources } },
              '#withResourcesMixin':: d.fn(help="\"Resources is a set of labels that describe the source of a log entry, including envoy node info.\\nIt's recommended to follow [semantic conventions](https://opentelemetry.io/docs/reference/specification/resource/semantic_conventions/).\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='resources', type=d.T.object)]),
              withResourcesMixin(resources): { openTelemetry+: { resources+: resources } },
            },
            '#withType':: d.fn(help='"Type defines the type of accesslog sink."', args=[d.arg(name='type', type=d.T.string)]),
            withType(type): { type: type },
          },
          '#withMatches':: d.fn(help='"Matches defines the match conditions for accesslog in CEL expression.\\nAn accesslog will be emitted only when one or more match conditions are evaluated to true.\\nInvalid [CEL](https://www.envoyproxy.io/docs/envoy/latest/xds/type/v3/cel.proto.html#common-expression-language-cel-proto) expressions will be ignored."', args=[d.arg(name='matches', type=d.T.array)]),
          withMatches(matches): { matches: if std.isArray(v=matches) then matches else [matches] },
          '#withMatchesMixin':: d.fn(help='"Matches defines the match conditions for accesslog in CEL expression.\\nAn accesslog will be emitted only when one or more match conditions are evaluated to true.\\nInvalid [CEL](https://www.envoyproxy.io/docs/envoy/latest/xds/type/v3/cel.proto.html#common-expression-language-cel-proto) expressions will be ignored."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matches', type=d.T.array)]),
          withMatchesMixin(matches): { matches+: if std.isArray(v=matches) then matches else [matches] },
          '#withSinks':: d.fn(help='"Sinks defines the sinks of accesslog."', args=[d.arg(name='sinks', type=d.T.array)]),
          withSinks(sinks): { sinks: if std.isArray(v=sinks) then sinks else [sinks] },
          '#withSinksMixin':: d.fn(help='"Sinks defines the sinks of accesslog."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='sinks', type=d.T.array)]),
          withSinksMixin(sinks): { sinks+: if std.isArray(v=sinks) then sinks else [sinks] },
          '#withType':: d.fn(help='"Type defines the component emitting the accesslog, such as Listener and Route.\\nIf type not defined, the setting would apply to:\\n(1) All Routes.\\n(2) Listeners if and only if Envoy does not find a matching route for a request.\\nIf type is defined, the accesslog settings would apply to the relevant component (as-is)."', args=[d.arg(name='type', type=d.T.string)]),
          withType(type): { type: type },
        },
        '#withDisable':: d.fn(help='"Disable disables access logging for managed proxies if set to true."', args=[d.arg(name='disable', type=d.T.boolean)]),
        withDisable(disable): { spec+: { telemetry+: { accessLog+: { disable: disable } } } },
        '#withSettings':: d.fn(help='"Settings defines accesslog settings for managed proxies.\\nIf unspecified, will send default format to stdout."', args=[d.arg(name='settings', type=d.T.array)]),
        withSettings(settings): { spec+: { telemetry+: { accessLog+: { settings: if std.isArray(v=settings) then settings else [settings] } } } },
        '#withSettingsMixin':: d.fn(help='"Settings defines accesslog settings for managed proxies.\\nIf unspecified, will send default format to stdout."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='settings', type=d.T.array)]),
        withSettingsMixin(settings): { spec+: { telemetry+: { accessLog+: { settings+: if std.isArray(v=settings) then settings else [settings] } } } },
      },
      '#metrics':: d.obj(help='"Metrics defines metrics configuration for managed proxies."'),
      metrics: {
        '#matches':: d.obj(help='"Matches defines configuration for selecting specific metrics instead of generating all metrics stats\\nthat are enabled by default. This helps reduce CPU and memory overhead in Envoy, but eliminating some stats\\nmay after critical functionality. Here are the stats that we strongly recommend not disabling:\\n`cluster_manager.warming_clusters`, `cluster.<cluster_name>.membership_total`,`cluster.<cluster_name>.membership_healthy`,\\n`cluster.<cluster_name>.membership_degraded`，reference  https://github.com/envoyproxy/envoy/issues/9856,\\nhttps://github.com/envoyproxy/envoy/issues/14610"'),
        matches: {
          '#withType':: d.fn(help='"Type specifies how to match against a string."', args=[d.arg(name='type', type=d.T.string)]),
          withType(type): { type: type },
          '#withValue':: d.fn(help='"Value specifies the string value that the match must have."', args=[d.arg(name='value', type=d.T.string)]),
          withValue(value): { value: value },
        },
        '#prometheus':: d.obj(help='"Prometheus defines the configuration for Admin endpoint `/stats/prometheus`."'),
        prometheus: {
          '#compression':: d.obj(help='"Configure the compression on Prometheus endpoint. Compression is useful in situations when bandwidth is scarce and large payloads can be effectively compressed at the expense of higher CPU load."'),
          compression: {
            '#withBrotli':: d.fn(help='"The configuration for Brotli compressor."', args=[d.arg(name='brotli', type=d.T.object)]),
            withBrotli(brotli): { spec+: { telemetry+: { metrics+: { prometheus+: { compression+: { brotli: brotli } } } } } },
            '#withBrotliMixin':: d.fn(help='"The configuration for Brotli compressor."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='brotli', type=d.T.object)]),
            withBrotliMixin(brotli): { spec+: { telemetry+: { metrics+: { prometheus+: { compression+: { brotli+: brotli } } } } } },
            '#withGzip':: d.fn(help='"The configuration for GZIP compressor."', args=[d.arg(name='gzip', type=d.T.object)]),
            withGzip(gzip): { spec+: { telemetry+: { metrics+: { prometheus+: { compression+: { gzip: gzip } } } } } },
            '#withGzipMixin':: d.fn(help='"The configuration for GZIP compressor."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='gzip', type=d.T.object)]),
            withGzipMixin(gzip): { spec+: { telemetry+: { metrics+: { prometheus+: { compression+: { gzip+: gzip } } } } } },
            '#withType':: d.fn(help='"CompressorType defines the compressor type to use for compression."', args=[d.arg(name='type', type=d.T.string)]),
            withType(type): { spec+: { telemetry+: { metrics+: { prometheus+: { compression+: { type: type } } } } } },
          },
          '#withDisable':: d.fn(help='"Disable the Prometheus endpoint."', args=[d.arg(name='disable', type=d.T.boolean)]),
          withDisable(disable): { spec+: { telemetry+: { metrics+: { prometheus+: { disable: disable } } } } },
        },
        '#sinks':: d.obj(help='"Sinks defines the metric sinks where metrics are sent to."'),
        sinks: {
          '#openTelemetry':: d.obj(help="\"OpenTelemetry defines the configuration for OpenTelemetry sink.\\nIt's required if the sink type is OpenTelemetry.\""),
          openTelemetry: {
            '#backendRef':: d.obj(help='"BackendRef references a Kubernetes object that represents the\\nbackend server to which the authorization request will be sent.\\n\\nDeprecated: Use BackendRefs instead."'),
            backendRef: {
              '#withGroup':: d.fn(help='"Group is the group of the referent. For example, \\"gateway.networking.k8s.io\\".\\nWhen unspecified or empty string, core API group is inferred."', args=[d.arg(name='group', type=d.T.string)]),
              withGroup(group): { openTelemetry+: { backendRef+: { group: group } } },
              '#withKind':: d.fn(help='"Kind is the Kubernetes resource kind of the referent. For example\\n\\"Service\\".\\n\\nDefaults to \\"Service\\" when not specified.\\n\\nExternalName services can refer to CNAME DNS records that may live\\noutside of the cluster and as such are difficult to reason about in\\nterms of conformance. They also may not be safe to forward to (see\\nCVE-2021-25740 for more information). Implementations SHOULD NOT\\nsupport ExternalName Services.\\n\\nSupport: Core (Services with a type other than ExternalName)\\n\\nSupport: Implementation-specific (Services with type ExternalName)"', args=[d.arg(name='kind', type=d.T.string)]),
              withKind(kind): { openTelemetry+: { backendRef+: { kind: kind } } },
              '#withName':: d.fn(help='"Name is the name of the referent."', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { openTelemetry+: { backendRef+: { name: name } } },
              '#withNamespace':: d.fn(help="\"Namespace is the namespace of the backend. When unspecified, the local\\nnamespace is inferred.\\n\\nNote that when a namespace different than the local namespace is specified,\\na ReferenceGrant object is required in the referent namespace to allow that\\nnamespace's owner to accept the reference. See the ReferenceGrant\\ndocumentation for details.\\n\\nSupport: Core\"", args=[d.arg(name='namespace', type=d.T.string)]),
              withNamespace(namespace): { openTelemetry+: { backendRef+: { namespace: namespace } } },
              '#withPort':: d.fn(help='"Port specifies the destination port number to use for this resource.\\nPort is required when the referent is a Kubernetes Service. In this\\ncase, the port number is the service port number, not the target port.\\nFor other resources, destination port might be derived from the referent\\nresource or this field."', args=[d.arg(name='port', type=d.T.integer)]),
              withPort(port): { openTelemetry+: { backendRef+: { port: port } } },
            },
            '#backendRefs':: d.obj(help='"BackendRefs references a Kubernetes object that represents the\\nbackend server to which the authorization request will be sent."'),
            backendRefs: {
              '#withFallback':: d.fn(help='"Fallback indicates whether the backend is designated as a fallback.\\nMultiple fallback backends can be configured.\\nIt is highly recommended to configure active or passive health checks to ensure that failover can be detected\\nwhen the active backends become unhealthy and to automatically readjust once the primary backends are healthy again.\\nThe overprovisioning factor is set to 1.4, meaning the fallback backends will only start receiving traffic when\\nthe health of the active backends falls below 72%."', args=[d.arg(name='fallback', type=d.T.boolean)]),
              withFallback(fallback): { fallback: fallback },
              '#withGroup':: d.fn(help='"Group is the group of the referent. For example, \\"gateway.networking.k8s.io\\".\\nWhen unspecified or empty string, core API group is inferred."', args=[d.arg(name='group', type=d.T.string)]),
              withGroup(group): { group: group },
              '#withKind':: d.fn(help='"Kind is the Kubernetes resource kind of the referent. For example\\n\\"Service\\".\\n\\nDefaults to \\"Service\\" when not specified.\\n\\nExternalName services can refer to CNAME DNS records that may live\\noutside of the cluster and as such are difficult to reason about in\\nterms of conformance. They also may not be safe to forward to (see\\nCVE-2021-25740 for more information). Implementations SHOULD NOT\\nsupport ExternalName Services.\\n\\nSupport: Core (Services with a type other than ExternalName)\\n\\nSupport: Implementation-specific (Services with type ExternalName)"', args=[d.arg(name='kind', type=d.T.string)]),
              withKind(kind): { kind: kind },
              '#withName':: d.fn(help='"Name is the name of the referent."', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { name: name },
              '#withNamespace':: d.fn(help="\"Namespace is the namespace of the backend. When unspecified, the local\\nnamespace is inferred.\\n\\nNote that when a namespace different than the local namespace is specified,\\na ReferenceGrant object is required in the referent namespace to allow that\\nnamespace's owner to accept the reference. See the ReferenceGrant\\ndocumentation for details.\\n\\nSupport: Core\"", args=[d.arg(name='namespace', type=d.T.string)]),
              withNamespace(namespace): { namespace: namespace },
              '#withPort':: d.fn(help='"Port specifies the destination port number to use for this resource.\\nPort is required when the referent is a Kubernetes Service. In this\\ncase, the port number is the service port number, not the target port.\\nFor other resources, destination port might be derived from the referent\\nresource or this field."', args=[d.arg(name='port', type=d.T.integer)]),
              withPort(port): { port: port },
            },
            '#backendSettings':: d.obj(help='"BackendSettings holds configuration for managing the connection\\nto the backend."'),
            backendSettings: {
              '#circuitBreaker':: d.obj(help='"Circuit Breaker settings for the upstream connections and requests.\\nIf not set, circuit breakers will be enabled with the default thresholds"'),
              circuitBreaker: {
                '#perEndpoint':: d.obj(help='"PerEndpoint defines Circuit Breakers that will apply per-endpoint for an upstream cluster"'),
                perEndpoint: {
                  '#withMaxConnections':: d.fn(help='"MaxConnections configures the maximum number of connections that Envoy will establish per-endpoint to the referenced backend defined within a xRoute rule."', args=[d.arg(name='maxConnections', type=d.T.integer)]),
                  withMaxConnections(maxConnections): { openTelemetry+: { backendSettings+: { circuitBreaker+: { perEndpoint+: { maxConnections: maxConnections } } } } },
                },
                '#withMaxConnections':: d.fn(help='"The maximum number of connections that Envoy will establish to the referenced backend defined within a xRoute rule."', args=[d.arg(name='maxConnections', type=d.T.integer)]),
                withMaxConnections(maxConnections): { openTelemetry+: { backendSettings+: { circuitBreaker+: { maxConnections: maxConnections } } } },
                '#withMaxParallelRequests':: d.fn(help='"The maximum number of parallel requests that Envoy will make to the referenced backend defined within a xRoute rule."', args=[d.arg(name='maxParallelRequests', type=d.T.integer)]),
                withMaxParallelRequests(maxParallelRequests): { openTelemetry+: { backendSettings+: { circuitBreaker+: { maxParallelRequests: maxParallelRequests } } } },
                '#withMaxParallelRetries':: d.fn(help='"The maximum number of parallel retries that Envoy will make to the referenced backend defined within a xRoute rule."', args=[d.arg(name='maxParallelRetries', type=d.T.integer)]),
                withMaxParallelRetries(maxParallelRetries): { openTelemetry+: { backendSettings+: { circuitBreaker+: { maxParallelRetries: maxParallelRetries } } } },
                '#withMaxPendingRequests':: d.fn(help='"The maximum number of pending requests that Envoy will queue to the referenced backend defined within a xRoute rule."', args=[d.arg(name='maxPendingRequests', type=d.T.integer)]),
                withMaxPendingRequests(maxPendingRequests): { openTelemetry+: { backendSettings+: { circuitBreaker+: { maxPendingRequests: maxPendingRequests } } } },
                '#withMaxRequestsPerConnection':: d.fn(help='"The maximum number of requests that Envoy will make over a single connection to the referenced backend defined within a xRoute rule.\\nDefault: unlimited."', args=[d.arg(name='maxRequestsPerConnection', type=d.T.integer)]),
                withMaxRequestsPerConnection(maxRequestsPerConnection): { openTelemetry+: { backendSettings+: { circuitBreaker+: { maxRequestsPerConnection: maxRequestsPerConnection } } } },
              },
              '#connection':: d.obj(help='"Connection includes backend connection settings."'),
              connection: {
                '#withBufferLimit':: d.fn(help="\"BufferLimit Soft limit on size of the cluster’s connections read and write buffers.\\nBufferLimit applies to connection streaming (maybe non-streaming) channel between processes, it's in user space.\\nIf unspecified, an implementation defined default is applied (32768 bytes).\\nFor example, 20Mi, 1Gi, 256Ki etc.\\nNote: that when the suffix is not provided, the value is interpreted as bytes.\"", args=[d.arg(name='bufferLimit', type=d.T.any)]),
                withBufferLimit(bufferLimit): { openTelemetry+: { backendSettings+: { connection+: { bufferLimit: bufferLimit } } } },
                '#withSocketBufferLimit':: d.fn(help="\"SocketBufferLimit provides configuration for the maximum buffer size in bytes for each socket\\nto backend.\\nSocketBufferLimit applies to socket streaming channel between TCP/IP stacks, it's in kernel space.\\nFor example, 20Mi, 1Gi, 256Ki etc.\\nNote that when the suffix is not provided, the value is interpreted as bytes.\"", args=[d.arg(name='socketBufferLimit', type=d.T.any)]),
                withSocketBufferLimit(socketBufferLimit): { openTelemetry+: { backendSettings+: { connection+: { socketBufferLimit: socketBufferLimit } } } },
              },
              '#dns':: d.obj(help='"DNS includes dns resolution settings."'),
              dns: {
                '#withDnsRefreshRate':: d.fn(help='"DNSRefreshRate specifies the rate at which DNS records should be refreshed.\\nDefaults to 30 seconds."', args=[d.arg(name='dnsRefreshRate', type=d.T.string)]),
                withDnsRefreshRate(dnsRefreshRate): { openTelemetry+: { backendSettings+: { dns+: { dnsRefreshRate: dnsRefreshRate } } } },
                '#withLookupFamily':: d.fn(help='"LookupFamily determines how Envoy would resolve DNS for Routes where the backend is specified as a fully qualified domain name (FQDN).\\nIf set, this configuration overrides other defaults."', args=[d.arg(name='lookupFamily', type=d.T.string)]),
                withLookupFamily(lookupFamily): { openTelemetry+: { backendSettings+: { dns+: { lookupFamily: lookupFamily } } } },
                '#withRespectDnsTtl':: d.fn(help='"RespectDNSTTL indicates whether the DNS Time-To-Live (TTL) should be respected.\\nIf the value is set to true, the DNS refresh rate will be set to the resource record’s TTL.\\nDefaults to true."', args=[d.arg(name='respectDnsTtl', type=d.T.boolean)]),
                withRespectDnsTtl(respectDnsTtl): { openTelemetry+: { backendSettings+: { dns+: { respectDnsTtl: respectDnsTtl } } } },
              },
              '#healthCheck':: d.obj(help='"HealthCheck allows gateway to perform active health checking on backends."'),
              healthCheck: {
                '#active':: d.obj(help='"Active health check configuration"'),
                active: {
                  '#grpc':: d.obj(help="\"GRPC defines the configuration of the GRPC health checker.\\nIt's optional, and can only be used if the specified type is GRPC.\""),
                  grpc: {
                    '#withService':: d.fn(help='"Service to send in the health check request.\\nIf this is not specified, then the health check request applies to the entire\\nserver and not to a specific service."', args=[d.arg(name='service', type=d.T.string)]),
                    withService(service): { openTelemetry+: { backendSettings+: { healthCheck+: { active+: { grpc+: { service: service } } } } } },
                  },
                  '#http':: d.obj(help="\"HTTP defines the configuration of http health checker.\\nIt's required while the health checker type is HTTP.\""),
                  http: {
                    '#expectedResponse':: d.obj(help='"ExpectedResponse defines a list of HTTP expected responses to match."'),
                    expectedResponse: {
                      '#withBinary':: d.fn(help='"Binary payload base64 encoded."', args=[d.arg(name='binary', type=d.T.string)]),
                      withBinary(binary): { openTelemetry+: { backendSettings+: { healthCheck+: { active+: { http+: { expectedResponse+: { binary: binary } } } } } } },
                      '#withText':: d.fn(help='"Text payload in plain text."', args=[d.arg(name='text', type=d.T.string)]),
                      withText(text): { openTelemetry+: { backendSettings+: { healthCheck+: { active+: { http+: { expectedResponse+: { text: text } } } } } } },
                      '#withType':: d.fn(help='"Type defines the type of the payload."', args=[d.arg(name='type', type=d.T.string)]),
                      withType(type): { openTelemetry+: { backendSettings+: { healthCheck+: { active+: { http+: { expectedResponse+: { type: type } } } } } } },
                    },
                    '#withExpectedStatuses':: d.fn(help='"ExpectedStatuses defines a list of HTTP response statuses considered healthy.\\nDefaults to 200 only"', args=[d.arg(name='expectedStatuses', type=d.T.array)]),
                    withExpectedStatuses(expectedStatuses): { openTelemetry+: { backendSettings+: { healthCheck+: { active+: { http+: { expectedStatuses: if std.isArray(v=expectedStatuses) then expectedStatuses else [expectedStatuses] } } } } } },
                    '#withExpectedStatusesMixin':: d.fn(help='"ExpectedStatuses defines a list of HTTP response statuses considered healthy.\\nDefaults to 200 only"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='expectedStatuses', type=d.T.array)]),
                    withExpectedStatusesMixin(expectedStatuses): { openTelemetry+: { backendSettings+: { healthCheck+: { active+: { http+: { expectedStatuses+: if std.isArray(v=expectedStatuses) then expectedStatuses else [expectedStatuses] } } } } } },
                    '#withMethod':: d.fn(help='"Method defines the HTTP method used for health checking.\\nDefaults to GET"', args=[d.arg(name='method', type=d.T.string)]),
                    withMethod(method): { openTelemetry+: { backendSettings+: { healthCheck+: { active+: { http+: { method: method } } } } } },
                    '#withPath':: d.fn(help='"Path defines the HTTP path that will be requested during health checking."', args=[d.arg(name='path', type=d.T.string)]),
                    withPath(path): { openTelemetry+: { backendSettings+: { healthCheck+: { active+: { http+: { path: path } } } } } },
                  },
                  '#tcp':: d.obj(help="\"TCP defines the configuration of tcp health checker.\\nIt's required while the health checker type is TCP.\""),
                  tcp: {
                    '#receive':: d.obj(help='"Receive defines the expected response payload."'),
                    receive: {
                      '#withBinary':: d.fn(help='"Binary payload base64 encoded."', args=[d.arg(name='binary', type=d.T.string)]),
                      withBinary(binary): { openTelemetry+: { backendSettings+: { healthCheck+: { active+: { tcp+: { receive+: { binary: binary } } } } } } },
                      '#withText':: d.fn(help='"Text payload in plain text."', args=[d.arg(name='text', type=d.T.string)]),
                      withText(text): { openTelemetry+: { backendSettings+: { healthCheck+: { active+: { tcp+: { receive+: { text: text } } } } } } },
                      '#withType':: d.fn(help='"Type defines the type of the payload."', args=[d.arg(name='type', type=d.T.string)]),
                      withType(type): { openTelemetry+: { backendSettings+: { healthCheck+: { active+: { tcp+: { receive+: { type: type } } } } } } },
                    },
                    '#send':: d.obj(help='"Send defines the request payload."'),
                    send: {
                      '#withBinary':: d.fn(help='"Binary payload base64 encoded."', args=[d.arg(name='binary', type=d.T.string)]),
                      withBinary(binary): { openTelemetry+: { backendSettings+: { healthCheck+: { active+: { tcp+: { send+: { binary: binary } } } } } } },
                      '#withText':: d.fn(help='"Text payload in plain text."', args=[d.arg(name='text', type=d.T.string)]),
                      withText(text): { openTelemetry+: { backendSettings+: { healthCheck+: { active+: { tcp+: { send+: { text: text } } } } } } },
                      '#withType':: d.fn(help='"Type defines the type of the payload."', args=[d.arg(name='type', type=d.T.string)]),
                      withType(type): { openTelemetry+: { backendSettings+: { healthCheck+: { active+: { tcp+: { send+: { type: type } } } } } } },
                    },
                  },
                  '#withHealthyThreshold':: d.fn(help='"HealthyThreshold defines the number of healthy health checks required before a backend host is marked healthy."', args=[d.arg(name='healthyThreshold', type=d.T.integer)]),
                  withHealthyThreshold(healthyThreshold): { openTelemetry+: { backendSettings+: { healthCheck+: { active+: { healthyThreshold: healthyThreshold } } } } },
                  '#withInterval':: d.fn(help='"Interval defines the time between active health checks."', args=[d.arg(name='interval', type=d.T.string)]),
                  withInterval(interval): { openTelemetry+: { backendSettings+: { healthCheck+: { active+: { interval: interval } } } } },
                  '#withTimeout':: d.fn(help='"Timeout defines the time to wait for a health check response."', args=[d.arg(name='timeout', type=d.T.string)]),
                  withTimeout(timeout): { openTelemetry+: { backendSettings+: { healthCheck+: { active+: { timeout: timeout } } } } },
                  '#withType':: d.fn(help='"Type defines the type of health checker."', args=[d.arg(name='type', type=d.T.string)]),
                  withType(type): { openTelemetry+: { backendSettings+: { healthCheck+: { active+: { type: type } } } } },
                  '#withUnhealthyThreshold':: d.fn(help='"UnhealthyThreshold defines the number of unhealthy health checks required before a backend host is marked unhealthy."', args=[d.arg(name='unhealthyThreshold', type=d.T.integer)]),
                  withUnhealthyThreshold(unhealthyThreshold): { openTelemetry+: { backendSettings+: { healthCheck+: { active+: { unhealthyThreshold: unhealthyThreshold } } } } },
                },
                '#passive':: d.obj(help='"Passive passive check configuration"'),
                passive: {
                  '#withBaseEjectionTime':: d.fn(help='"BaseEjectionTime defines the base duration for which a host will be ejected on consecutive failures."', args=[d.arg(name='baseEjectionTime', type=d.T.string)]),
                  withBaseEjectionTime(baseEjectionTime): { openTelemetry+: { backendSettings+: { healthCheck+: { passive+: { baseEjectionTime: baseEjectionTime } } } } },
                  '#withConsecutive5XxErrors':: d.fn(help='"Consecutive5xxErrors sets the number of consecutive 5xx errors triggering ejection."', args=[d.arg(name='consecutive5XxErrors', type=d.T.integer)]),
                  withConsecutive5XxErrors(consecutive5XxErrors): { openTelemetry+: { backendSettings+: { healthCheck+: { passive+: { consecutive5XxErrors: consecutive5XxErrors } } } } },
                  '#withConsecutiveGatewayErrors':: d.fn(help='"ConsecutiveGatewayErrors sets the number of consecutive gateway errors triggering ejection."', args=[d.arg(name='consecutiveGatewayErrors', type=d.T.integer)]),
                  withConsecutiveGatewayErrors(consecutiveGatewayErrors): { openTelemetry+: { backendSettings+: { healthCheck+: { passive+: { consecutiveGatewayErrors: consecutiveGatewayErrors } } } } },
                  '#withConsecutiveLocalOriginFailures':: d.fn(help='"ConsecutiveLocalOriginFailures sets the number of consecutive local origin failures triggering ejection.\\nParameter takes effect only when split_external_local_origin_errors is set to true."', args=[d.arg(name='consecutiveLocalOriginFailures', type=d.T.integer)]),
                  withConsecutiveLocalOriginFailures(consecutiveLocalOriginFailures): { openTelemetry+: { backendSettings+: { healthCheck+: { passive+: { consecutiveLocalOriginFailures: consecutiveLocalOriginFailures } } } } },
                  '#withInterval':: d.fn(help='"Interval defines the time between passive health checks."', args=[d.arg(name='interval', type=d.T.string)]),
                  withInterval(interval): { openTelemetry+: { backendSettings+: { healthCheck+: { passive+: { interval: interval } } } } },
                  '#withMaxEjectionPercent':: d.fn(help='"MaxEjectionPercent sets the maximum percentage of hosts in a cluster that can be ejected."', args=[d.arg(name='maxEjectionPercent', type=d.T.integer)]),
                  withMaxEjectionPercent(maxEjectionPercent): { openTelemetry+: { backendSettings+: { healthCheck+: { passive+: { maxEjectionPercent: maxEjectionPercent } } } } },
                  '#withSplitExternalLocalOriginErrors':: d.fn(help='"SplitExternalLocalOriginErrors enables splitting of errors between external and local origin."', args=[d.arg(name='splitExternalLocalOriginErrors', type=d.T.boolean)]),
                  withSplitExternalLocalOriginErrors(splitExternalLocalOriginErrors): { openTelemetry+: { backendSettings+: { healthCheck+: { passive+: { splitExternalLocalOriginErrors: splitExternalLocalOriginErrors } } } } },
                },
                '#withPanicThreshold':: d.fn(help="\"When number of unhealthy endpoints for a backend reaches this threshold\\nEnvoy will disregard health status and balance across all endpoints.\\nIt's designed to prevent a situation in which host failures cascade throughout the cluster\\nas load increases. If not set, the default value is 50%. To disable panic mode, set value to `0`.\"", args=[d.arg(name='panicThreshold', type=d.T.integer)]),
                withPanicThreshold(panicThreshold): { openTelemetry+: { backendSettings+: { healthCheck+: { panicThreshold: panicThreshold } } } },
              },
              '#http2':: d.obj(help='"HTTP2 provides HTTP/2 configuration for backend connections."'),
              http2: {
                '#withInitialConnectionWindowSize':: d.fn(help='"InitialConnectionWindowSize sets the initial window size for HTTP/2 connections.\\nIf not set, the default value is 1 MiB."', args=[d.arg(name='initialConnectionWindowSize', type=d.T.any)]),
                withInitialConnectionWindowSize(initialConnectionWindowSize): { openTelemetry+: { backendSettings+: { http2+: { initialConnectionWindowSize: initialConnectionWindowSize } } } },
                '#withInitialStreamWindowSize':: d.fn(help='"InitialStreamWindowSize sets the initial window size for HTTP/2 streams.\\nIf not set, the default value is 64 KiB(64*1024)."', args=[d.arg(name='initialStreamWindowSize', type=d.T.any)]),
                withInitialStreamWindowSize(initialStreamWindowSize): { openTelemetry+: { backendSettings+: { http2+: { initialStreamWindowSize: initialStreamWindowSize } } } },
                '#withMaxConcurrentStreams':: d.fn(help='"MaxConcurrentStreams sets the maximum number of concurrent streams allowed per connection.\\nIf not set, the default value is 100."', args=[d.arg(name='maxConcurrentStreams', type=d.T.integer)]),
                withMaxConcurrentStreams(maxConcurrentStreams): { openTelemetry+: { backendSettings+: { http2+: { maxConcurrentStreams: maxConcurrentStreams } } } },
                '#withOnInvalidMessage':: d.fn(help="\"OnInvalidMessage determines if Envoy will terminate the connection or just the offending stream in the event of HTTP messaging error\\nIt's recommended for L2 Envoy deployments to set this value to TerminateStream.\\nhttps://www.envoyproxy.io/docs/envoy/latest/configuration/best_practices/level_two\\nDefault: TerminateConnection\"", args=[d.arg(name='onInvalidMessage', type=d.T.string)]),
                withOnInvalidMessage(onInvalidMessage): { openTelemetry+: { backendSettings+: { http2+: { onInvalidMessage: onInvalidMessage } } } },
              },
              '#loadBalancer':: d.obj(help='"LoadBalancer policy to apply when routing traffic from the gateway to\\nthe backend endpoints. Defaults to `LeastRequest`."'),
              loadBalancer: {
                '#consistentHash':: d.obj(help='"ConsistentHash defines the configuration when the load balancer type is\\nset to ConsistentHash"'),
                consistentHash: {
                  '#cookie':: d.obj(help='"Cookie configures the cookie hash policy when the consistent hash type is set to Cookie."'),
                  cookie: {
                    '#withAttributes':: d.fn(help='"Additional Attributes to set for the generated cookie."', args=[d.arg(name='attributes', type=d.T.object)]),
                    withAttributes(attributes): { openTelemetry+: { backendSettings+: { loadBalancer+: { consistentHash+: { cookie+: { attributes: attributes } } } } } },
                    '#withAttributesMixin':: d.fn(help='"Additional Attributes to set for the generated cookie."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='attributes', type=d.T.object)]),
                    withAttributesMixin(attributes): { openTelemetry+: { backendSettings+: { loadBalancer+: { consistentHash+: { cookie+: { attributes+: attributes } } } } } },
                    '#withName':: d.fn(help='"Name of the cookie to hash.\\nIf this cookie does not exist in the request, Envoy will generate a cookie and set\\nthe TTL on the response back to the client based on Layer 4\\nattributes of the backend endpoint, to ensure that these future requests\\ngo to the same backend endpoint. Make sure to set the TTL field for this case."', args=[d.arg(name='name', type=d.T.string)]),
                    withName(name): { openTelemetry+: { backendSettings+: { loadBalancer+: { consistentHash+: { cookie+: { name: name } } } } } },
                    '#withTtl':: d.fn(help='"TTL of the generated cookie if the cookie is not present. This value sets the\\nMax-Age attribute value."', args=[d.arg(name='ttl', type=d.T.string)]),
                    withTtl(ttl): { openTelemetry+: { backendSettings+: { loadBalancer+: { consistentHash+: { cookie+: { ttl: ttl } } } } } },
                  },
                  '#header':: d.obj(help='"Header configures the header hash policy when the consistent hash type is set to Header."'),
                  header: {
                    '#withName':: d.fn(help='"Name of the header to hash."', args=[d.arg(name='name', type=d.T.string)]),
                    withName(name): { openTelemetry+: { backendSettings+: { loadBalancer+: { consistentHash+: { header+: { name: name } } } } } },
                  },
                  '#withTableSize':: d.fn(help='"The table size for consistent hashing, must be prime number limited to 5000011."', args=[d.arg(name='tableSize', type=d.T.integer)]),
                  withTableSize(tableSize): { openTelemetry+: { backendSettings+: { loadBalancer+: { consistentHash+: { tableSize: tableSize } } } } },
                  '#withType':: d.fn(help='"ConsistentHashType defines the type of input to hash on. Valid Type values are\\n\\"SourceIP\\",\\n\\"Header\\",\\n\\"Cookie\\"."', args=[d.arg(name='type', type=d.T.string)]),
                  withType(type): { openTelemetry+: { backendSettings+: { loadBalancer+: { consistentHash+: { type: type } } } } },
                },
                '#slowStart':: d.obj(help='"SlowStart defines the configuration related to the slow start load balancer policy.\\nIf set, during slow start window, traffic sent to the newly added hosts will gradually increase.\\nCurrently this is only supported for RoundRobin and LeastRequest load balancers"'),
                slowStart: {
                  '#withWindow':: d.fn(help='"Window defines the duration of the warm up period for newly added host.\\nDuring slow start window, traffic sent to the newly added hosts will gradually increase.\\nCurrently only supports linear growth of traffic. For additional details,\\nsee https://www.envoyproxy.io/docs/envoy/latest/api-v3/config/cluster/v3/cluster.proto#config-cluster-v3-cluster-slowstartconfig"', args=[d.arg(name='window', type=d.T.string)]),
                  withWindow(window): { openTelemetry+: { backendSettings+: { loadBalancer+: { slowStart+: { window: window } } } } },
                },
                '#withType':: d.fn(help='"Type decides the type of Load Balancer policy.\\nValid LoadBalancerType values are\\n\\"ConsistentHash\\",\\n\\"LeastRequest\\",\\n\\"Random\\",\\n\\"RoundRobin\\"."', args=[d.arg(name='type', type=d.T.string)]),
                withType(type): { openTelemetry+: { backendSettings+: { loadBalancer+: { type: type } } } },
              },
              '#proxyProtocol':: d.obj(help='"ProxyProtocol enables the Proxy Protocol when communicating with the backend."'),
              proxyProtocol: {
                '#withVersion':: d.fn(help='"Version of ProxyProtol\\nValid ProxyProtocolVersion values are\\n\\"V1\\"\\n\\"V2\\', args=[d.arg(name='version', type=d.T.string)]),
                withVersion(version): { openTelemetry+: { backendSettings+: { proxyProtocol+: { version: version } } } },
              },
              '#retry':: d.obj(help='"Retry provides more advanced usage, allowing users to customize the number of retries, retry fallback strategy, and retry triggering conditions.\\nIf not set, retry will be disabled."'),
              retry: {
                '#perRetry':: d.obj(help='"PerRetry is the retry policy to be applied per retry attempt."'),
                perRetry: {
                  '#backOff':: d.obj(help='"Backoff is the backoff policy to be applied per retry attempt. gateway uses a fully jittered exponential\\nback-off algorithm for retries. For additional details,\\nsee https://www.envoyproxy.io/docs/envoy/latest/configuration/http/http_filters/router_filter#config-http-filters-router-x-envoy-max-retries"'),
                  backOff: {
                    '#withBaseInterval':: d.fn(help='"BaseInterval is the base interval between retries."', args=[d.arg(name='baseInterval', type=d.T.string)]),
                    withBaseInterval(baseInterval): { openTelemetry+: { backendSettings+: { retry+: { perRetry+: { backOff+: { baseInterval: baseInterval } } } } } },
                    '#withMaxInterval':: d.fn(help='"MaxInterval is the maximum interval between retries. This parameter is optional, but must be greater than or equal to the base_interval if set.\\nThe default is 10 times the base_interval"', args=[d.arg(name='maxInterval', type=d.T.string)]),
                    withMaxInterval(maxInterval): { openTelemetry+: { backendSettings+: { retry+: { perRetry+: { backOff+: { maxInterval: maxInterval } } } } } },
                  },
                  '#withTimeout':: d.fn(help='"Timeout is the timeout per retry attempt."', args=[d.arg(name='timeout', type=d.T.string)]),
                  withTimeout(timeout): { openTelemetry+: { backendSettings+: { retry+: { perRetry+: { timeout: timeout } } } } },
                },
                '#retryOn':: d.obj(help='"RetryOn specifies the retry trigger condition.\\n\\nIf not specified, the default is to retry on connect-failure,refused-stream,unavailable,cancelled,retriable-status-codes(503)."'),
                retryOn: {
                  '#withHttpStatusCodes':: d.fn(help='"HttpStatusCodes specifies the http status codes to be retried.\\nThe retriable-status-codes trigger must also be configured for these status codes to trigger a retry."', args=[d.arg(name='httpStatusCodes', type=d.T.array)]),
                  withHttpStatusCodes(httpStatusCodes): { openTelemetry+: { backendSettings+: { retry+: { retryOn+: { httpStatusCodes: if std.isArray(v=httpStatusCodes) then httpStatusCodes else [httpStatusCodes] } } } } },
                  '#withHttpStatusCodesMixin':: d.fn(help='"HttpStatusCodes specifies the http status codes to be retried.\\nThe retriable-status-codes trigger must also be configured for these status codes to trigger a retry."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='httpStatusCodes', type=d.T.array)]),
                  withHttpStatusCodesMixin(httpStatusCodes): { openTelemetry+: { backendSettings+: { retry+: { retryOn+: { httpStatusCodes+: if std.isArray(v=httpStatusCodes) then httpStatusCodes else [httpStatusCodes] } } } } },
                  '#withTriggers':: d.fn(help='"Triggers specifies the retry trigger condition(Http/Grpc)."', args=[d.arg(name='triggers', type=d.T.array)]),
                  withTriggers(triggers): { openTelemetry+: { backendSettings+: { retry+: { retryOn+: { triggers: if std.isArray(v=triggers) then triggers else [triggers] } } } } },
                  '#withTriggersMixin':: d.fn(help='"Triggers specifies the retry trigger condition(Http/Grpc)."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='triggers', type=d.T.array)]),
                  withTriggersMixin(triggers): { openTelemetry+: { backendSettings+: { retry+: { retryOn+: { triggers+: if std.isArray(v=triggers) then triggers else [triggers] } } } } },
                },
                '#withNumRetries':: d.fn(help='"NumRetries is the number of retries to be attempted. Defaults to 2."', args=[d.arg(name='numRetries', type=d.T.integer)]),
                withNumRetries(numRetries): { openTelemetry+: { backendSettings+: { retry+: { numRetries: numRetries } } } },
              },
              '#tcpKeepalive':: d.obj(help='"TcpKeepalive settings associated with the upstream client connection.\\nDisabled by default."'),
              tcpKeepalive: {
                '#withIdleTime':: d.fn(help='"The duration a connection needs to be idle before keep-alive\\nprobes start being sent.\\nThe duration format is\\nDefaults to `7200s`."', args=[d.arg(name='idleTime', type=d.T.string)]),
                withIdleTime(idleTime): { openTelemetry+: { backendSettings+: { tcpKeepalive+: { idleTime: idleTime } } } },
                '#withInterval':: d.fn(help='"The duration between keep-alive probes.\\nDefaults to `75s`."', args=[d.arg(name='interval', type=d.T.string)]),
                withInterval(interval): { openTelemetry+: { backendSettings+: { tcpKeepalive+: { interval: interval } } } },
                '#withProbes':: d.fn(help='"The total number of unacknowledged probes to send before deciding\\nthe connection is dead.\\nDefaults to 9."', args=[d.arg(name='probes', type=d.T.integer)]),
                withProbes(probes): { openTelemetry+: { backendSettings+: { tcpKeepalive+: { probes: probes } } } },
              },
              '#timeout':: d.obj(help='"Timeout settings for the backend connections."'),
              timeout: {
                '#http':: d.obj(help='"Timeout settings for HTTP."'),
                http: {
                  '#withConnectionIdleTimeout':: d.fn(help='"The idle timeout for an HTTP connection. Idle time is defined as a period in which there are no active requests in the connection.\\nDefault: 1 hour."', args=[d.arg(name='connectionIdleTimeout', type=d.T.string)]),
                  withConnectionIdleTimeout(connectionIdleTimeout): { openTelemetry+: { backendSettings+: { timeout+: { http+: { connectionIdleTimeout: connectionIdleTimeout } } } } },
                  '#withMaxConnectionDuration':: d.fn(help='"The maximum duration of an HTTP connection.\\nDefault: unlimited."', args=[d.arg(name='maxConnectionDuration', type=d.T.string)]),
                  withMaxConnectionDuration(maxConnectionDuration): { openTelemetry+: { backendSettings+: { timeout+: { http+: { maxConnectionDuration: maxConnectionDuration } } } } },
                  '#withRequestTimeout':: d.fn(help='"RequestTimeout is the time until which entire response is received from the upstream."', args=[d.arg(name='requestTimeout', type=d.T.string)]),
                  withRequestTimeout(requestTimeout): { openTelemetry+: { backendSettings+: { timeout+: { http+: { requestTimeout: requestTimeout } } } } },
                },
                '#tcp':: d.obj(help='"Timeout settings for TCP."'),
                tcp: {
                  '#withConnectTimeout':: d.fn(help='"The timeout for network connection establishment, including TCP and TLS handshakes.\\nDefault: 10 seconds."', args=[d.arg(name='connectTimeout', type=d.T.string)]),
                  withConnectTimeout(connectTimeout): { openTelemetry+: { backendSettings+: { timeout+: { tcp+: { connectTimeout: connectTimeout } } } } },
                },
              },
            },
            '#withBackendRefs':: d.fn(help='"BackendRefs references a Kubernetes object that represents the\\nbackend server to which the authorization request will be sent."', args=[d.arg(name='backendRefs', type=d.T.array)]),
            withBackendRefs(backendRefs): { openTelemetry+: { backendRefs: if std.isArray(v=backendRefs) then backendRefs else [backendRefs] } },
            '#withBackendRefsMixin':: d.fn(help='"BackendRefs references a Kubernetes object that represents the\\nbackend server to which the authorization request will be sent."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='backendRefs', type=d.T.array)]),
            withBackendRefsMixin(backendRefs): { openTelemetry+: { backendRefs+: if std.isArray(v=backendRefs) then backendRefs else [backendRefs] } },
            '#withHost':: d.fn(help='"Host define the service hostname.\\nDeprecated: Use BackendRefs instead."', args=[d.arg(name='host', type=d.T.string)]),
            withHost(host): { openTelemetry+: { host: host } },
            '#withPort':: d.fn(help='"Port defines the port the service is exposed on.\\nDeprecated: Use BackendRefs instead."', args=[d.arg(name='port', type=d.T.integer)]),
            withPort(port): { openTelemetry+: { port: port } },
          },
          '#withType':: d.fn(help='"Type defines the metric sink type.\\nEG currently only supports OpenTelemetry."', args=[d.arg(name='type', type=d.T.string)]),
          withType(type): { type: type },
        },
        '#withEnablePerEndpointStats':: d.fn(help='"EnablePerEndpointStats enables per endpoint envoy stats metrics.\\nPlease use with caution."', args=[d.arg(name='enablePerEndpointStats', type=d.T.boolean)]),
        withEnablePerEndpointStats(enablePerEndpointStats): { spec+: { telemetry+: { metrics+: { enablePerEndpointStats: enablePerEndpointStats } } } },
        '#withEnableRequestResponseSizesStats':: d.fn(help='"EnableRequestResponseSizesStats enables publishing of histograms tracking header and body sizes of requests and responses."', args=[d.arg(name='enableRequestResponseSizesStats', type=d.T.boolean)]),
        withEnableRequestResponseSizesStats(enableRequestResponseSizesStats): { spec+: { telemetry+: { metrics+: { enableRequestResponseSizesStats: enableRequestResponseSizesStats } } } },
        '#withEnableVirtualHostStats':: d.fn(help='"EnableVirtualHostStats enables envoy stat metrics for virtual hosts."', args=[d.arg(name='enableVirtualHostStats', type=d.T.boolean)]),
        withEnableVirtualHostStats(enableVirtualHostStats): { spec+: { telemetry+: { metrics+: { enableVirtualHostStats: enableVirtualHostStats } } } },
        '#withMatches':: d.fn(help='"Matches defines configuration for selecting specific metrics instead of generating all metrics stats\\nthat are enabled by default. This helps reduce CPU and memory overhead in Envoy, but eliminating some stats\\nmay after critical functionality. Here are the stats that we strongly recommend not disabling:\\n`cluster_manager.warming_clusters`, `cluster.<cluster_name>.membership_total`,`cluster.<cluster_name>.membership_healthy`,\\n`cluster.<cluster_name>.membership_degraded`，reference  https://github.com/envoyproxy/envoy/issues/9856,\\nhttps://github.com/envoyproxy/envoy/issues/14610"', args=[d.arg(name='matches', type=d.T.array)]),
        withMatches(matches): { spec+: { telemetry+: { metrics+: { matches: if std.isArray(v=matches) then matches else [matches] } } } },
        '#withMatchesMixin':: d.fn(help='"Matches defines configuration for selecting specific metrics instead of generating all metrics stats\\nthat are enabled by default. This helps reduce CPU and memory overhead in Envoy, but eliminating some stats\\nmay after critical functionality. Here are the stats that we strongly recommend not disabling:\\n`cluster_manager.warming_clusters`, `cluster.<cluster_name>.membership_total`,`cluster.<cluster_name>.membership_healthy`,\\n`cluster.<cluster_name>.membership_degraded`，reference  https://github.com/envoyproxy/envoy/issues/9856,\\nhttps://github.com/envoyproxy/envoy/issues/14610"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matches', type=d.T.array)]),
        withMatchesMixin(matches): { spec+: { telemetry+: { metrics+: { matches+: if std.isArray(v=matches) then matches else [matches] } } } },
        '#withSinks':: d.fn(help='"Sinks defines the metric sinks where metrics are sent to."', args=[d.arg(name='sinks', type=d.T.array)]),
        withSinks(sinks): { spec+: { telemetry+: { metrics+: { sinks: if std.isArray(v=sinks) then sinks else [sinks] } } } },
        '#withSinksMixin':: d.fn(help='"Sinks defines the metric sinks where metrics are sent to."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='sinks', type=d.T.array)]),
        withSinksMixin(sinks): { spec+: { telemetry+: { metrics+: { sinks+: if std.isArray(v=sinks) then sinks else [sinks] } } } },
      },
      '#tracing':: d.obj(help='"Tracing defines tracing configuration for managed proxies.\\nIf unspecified, will not send tracing data."'),
      tracing: {
        '#provider':: d.obj(help='"Provider defines the tracing provider."'),
        provider: {
          '#backendRef':: d.obj(help='"BackendRef references a Kubernetes object that represents the\\nbackend server to which the authorization request will be sent.\\n\\nDeprecated: Use BackendRefs instead."'),
          backendRef: {
            '#withGroup':: d.fn(help='"Group is the group of the referent. For example, \\"gateway.networking.k8s.io\\".\\nWhen unspecified or empty string, core API group is inferred."', args=[d.arg(name='group', type=d.T.string)]),
            withGroup(group): { spec+: { telemetry+: { tracing+: { provider+: { backendRef+: { group: group } } } } } },
            '#withKind':: d.fn(help='"Kind is the Kubernetes resource kind of the referent. For example\\n\\"Service\\".\\n\\nDefaults to \\"Service\\" when not specified.\\n\\nExternalName services can refer to CNAME DNS records that may live\\noutside of the cluster and as such are difficult to reason about in\\nterms of conformance. They also may not be safe to forward to (see\\nCVE-2021-25740 for more information). Implementations SHOULD NOT\\nsupport ExternalName Services.\\n\\nSupport: Core (Services with a type other than ExternalName)\\n\\nSupport: Implementation-specific (Services with type ExternalName)"', args=[d.arg(name='kind', type=d.T.string)]),
            withKind(kind): { spec+: { telemetry+: { tracing+: { provider+: { backendRef+: { kind: kind } } } } } },
            '#withName':: d.fn(help='"Name is the name of the referent."', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { spec+: { telemetry+: { tracing+: { provider+: { backendRef+: { name: name } } } } } },
            '#withNamespace':: d.fn(help="\"Namespace is the namespace of the backend. When unspecified, the local\\nnamespace is inferred.\\n\\nNote that when a namespace different than the local namespace is specified,\\na ReferenceGrant object is required in the referent namespace to allow that\\nnamespace's owner to accept the reference. See the ReferenceGrant\\ndocumentation for details.\\n\\nSupport: Core\"", args=[d.arg(name='namespace', type=d.T.string)]),
            withNamespace(namespace): { spec+: { telemetry+: { tracing+: { provider+: { backendRef+: { namespace: namespace } } } } } },
            '#withPort':: d.fn(help='"Port specifies the destination port number to use for this resource.\\nPort is required when the referent is a Kubernetes Service. In this\\ncase, the port number is the service port number, not the target port.\\nFor other resources, destination port might be derived from the referent\\nresource or this field."', args=[d.arg(name='port', type=d.T.integer)]),
            withPort(port): { spec+: { telemetry+: { tracing+: { provider+: { backendRef+: { port: port } } } } } },
          },
          '#backendRefs':: d.obj(help='"BackendRefs references a Kubernetes object that represents the\\nbackend server to which the authorization request will be sent."'),
          backendRefs: {
            '#withFallback':: d.fn(help='"Fallback indicates whether the backend is designated as a fallback.\\nMultiple fallback backends can be configured.\\nIt is highly recommended to configure active or passive health checks to ensure that failover can be detected\\nwhen the active backends become unhealthy and to automatically readjust once the primary backends are healthy again.\\nThe overprovisioning factor is set to 1.4, meaning the fallback backends will only start receiving traffic when\\nthe health of the active backends falls below 72%."', args=[d.arg(name='fallback', type=d.T.boolean)]),
            withFallback(fallback): { fallback: fallback },
            '#withGroup':: d.fn(help='"Group is the group of the referent. For example, \\"gateway.networking.k8s.io\\".\\nWhen unspecified or empty string, core API group is inferred."', args=[d.arg(name='group', type=d.T.string)]),
            withGroup(group): { group: group },
            '#withKind':: d.fn(help='"Kind is the Kubernetes resource kind of the referent. For example\\n\\"Service\\".\\n\\nDefaults to \\"Service\\" when not specified.\\n\\nExternalName services can refer to CNAME DNS records that may live\\noutside of the cluster and as such are difficult to reason about in\\nterms of conformance. They also may not be safe to forward to (see\\nCVE-2021-25740 for more information). Implementations SHOULD NOT\\nsupport ExternalName Services.\\n\\nSupport: Core (Services with a type other than ExternalName)\\n\\nSupport: Implementation-specific (Services with type ExternalName)"', args=[d.arg(name='kind', type=d.T.string)]),
            withKind(kind): { kind: kind },
            '#withName':: d.fn(help='"Name is the name of the referent."', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { name: name },
            '#withNamespace':: d.fn(help="\"Namespace is the namespace of the backend. When unspecified, the local\\nnamespace is inferred.\\n\\nNote that when a namespace different than the local namespace is specified,\\na ReferenceGrant object is required in the referent namespace to allow that\\nnamespace's owner to accept the reference. See the ReferenceGrant\\ndocumentation for details.\\n\\nSupport: Core\"", args=[d.arg(name='namespace', type=d.T.string)]),
            withNamespace(namespace): { namespace: namespace },
            '#withPort':: d.fn(help='"Port specifies the destination port number to use for this resource.\\nPort is required when the referent is a Kubernetes Service. In this\\ncase, the port number is the service port number, not the target port.\\nFor other resources, destination port might be derived from the referent\\nresource or this field."', args=[d.arg(name='port', type=d.T.integer)]),
            withPort(port): { port: port },
          },
          '#backendSettings':: d.obj(help='"BackendSettings holds configuration for managing the connection\\nto the backend."'),
          backendSettings: {
            '#circuitBreaker':: d.obj(help='"Circuit Breaker settings for the upstream connections and requests.\\nIf not set, circuit breakers will be enabled with the default thresholds"'),
            circuitBreaker: {
              '#perEndpoint':: d.obj(help='"PerEndpoint defines Circuit Breakers that will apply per-endpoint for an upstream cluster"'),
              perEndpoint: {
                '#withMaxConnections':: d.fn(help='"MaxConnections configures the maximum number of connections that Envoy will establish per-endpoint to the referenced backend defined within a xRoute rule."', args=[d.arg(name='maxConnections', type=d.T.integer)]),
                withMaxConnections(maxConnections): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { circuitBreaker+: { perEndpoint+: { maxConnections: maxConnections } } } } } } } },
              },
              '#withMaxConnections':: d.fn(help='"The maximum number of connections that Envoy will establish to the referenced backend defined within a xRoute rule."', args=[d.arg(name='maxConnections', type=d.T.integer)]),
              withMaxConnections(maxConnections): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { circuitBreaker+: { maxConnections: maxConnections } } } } } } },
              '#withMaxParallelRequests':: d.fn(help='"The maximum number of parallel requests that Envoy will make to the referenced backend defined within a xRoute rule."', args=[d.arg(name='maxParallelRequests', type=d.T.integer)]),
              withMaxParallelRequests(maxParallelRequests): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { circuitBreaker+: { maxParallelRequests: maxParallelRequests } } } } } } },
              '#withMaxParallelRetries':: d.fn(help='"The maximum number of parallel retries that Envoy will make to the referenced backend defined within a xRoute rule."', args=[d.arg(name='maxParallelRetries', type=d.T.integer)]),
              withMaxParallelRetries(maxParallelRetries): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { circuitBreaker+: { maxParallelRetries: maxParallelRetries } } } } } } },
              '#withMaxPendingRequests':: d.fn(help='"The maximum number of pending requests that Envoy will queue to the referenced backend defined within a xRoute rule."', args=[d.arg(name='maxPendingRequests', type=d.T.integer)]),
              withMaxPendingRequests(maxPendingRequests): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { circuitBreaker+: { maxPendingRequests: maxPendingRequests } } } } } } },
              '#withMaxRequestsPerConnection':: d.fn(help='"The maximum number of requests that Envoy will make over a single connection to the referenced backend defined within a xRoute rule.\\nDefault: unlimited."', args=[d.arg(name='maxRequestsPerConnection', type=d.T.integer)]),
              withMaxRequestsPerConnection(maxRequestsPerConnection): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { circuitBreaker+: { maxRequestsPerConnection: maxRequestsPerConnection } } } } } } },
            },
            '#connection':: d.obj(help='"Connection includes backend connection settings."'),
            connection: {
              '#withBufferLimit':: d.fn(help="\"BufferLimit Soft limit on size of the cluster’s connections read and write buffers.\\nBufferLimit applies to connection streaming (maybe non-streaming) channel between processes, it's in user space.\\nIf unspecified, an implementation defined default is applied (32768 bytes).\\nFor example, 20Mi, 1Gi, 256Ki etc.\\nNote: that when the suffix is not provided, the value is interpreted as bytes.\"", args=[d.arg(name='bufferLimit', type=d.T.any)]),
              withBufferLimit(bufferLimit): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { connection+: { bufferLimit: bufferLimit } } } } } } },
              '#withSocketBufferLimit':: d.fn(help="\"SocketBufferLimit provides configuration for the maximum buffer size in bytes for each socket\\nto backend.\\nSocketBufferLimit applies to socket streaming channel between TCP/IP stacks, it's in kernel space.\\nFor example, 20Mi, 1Gi, 256Ki etc.\\nNote that when the suffix is not provided, the value is interpreted as bytes.\"", args=[d.arg(name='socketBufferLimit', type=d.T.any)]),
              withSocketBufferLimit(socketBufferLimit): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { connection+: { socketBufferLimit: socketBufferLimit } } } } } } },
            },
            '#dns':: d.obj(help='"DNS includes dns resolution settings."'),
            dns: {
              '#withDnsRefreshRate':: d.fn(help='"DNSRefreshRate specifies the rate at which DNS records should be refreshed.\\nDefaults to 30 seconds."', args=[d.arg(name='dnsRefreshRate', type=d.T.string)]),
              withDnsRefreshRate(dnsRefreshRate): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { dns+: { dnsRefreshRate: dnsRefreshRate } } } } } } },
              '#withLookupFamily':: d.fn(help='"LookupFamily determines how Envoy would resolve DNS for Routes where the backend is specified as a fully qualified domain name (FQDN).\\nIf set, this configuration overrides other defaults."', args=[d.arg(name='lookupFamily', type=d.T.string)]),
              withLookupFamily(lookupFamily): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { dns+: { lookupFamily: lookupFamily } } } } } } },
              '#withRespectDnsTtl':: d.fn(help='"RespectDNSTTL indicates whether the DNS Time-To-Live (TTL) should be respected.\\nIf the value is set to true, the DNS refresh rate will be set to the resource record’s TTL.\\nDefaults to true."', args=[d.arg(name='respectDnsTtl', type=d.T.boolean)]),
              withRespectDnsTtl(respectDnsTtl): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { dns+: { respectDnsTtl: respectDnsTtl } } } } } } },
            },
            '#healthCheck':: d.obj(help='"HealthCheck allows gateway to perform active health checking on backends."'),
            healthCheck: {
              '#active':: d.obj(help='"Active health check configuration"'),
              active: {
                '#grpc':: d.obj(help="\"GRPC defines the configuration of the GRPC health checker.\\nIt's optional, and can only be used if the specified type is GRPC.\""),
                grpc: {
                  '#withService':: d.fn(help='"Service to send in the health check request.\\nIf this is not specified, then the health check request applies to the entire\\nserver and not to a specific service."', args=[d.arg(name='service', type=d.T.string)]),
                  withService(service): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { healthCheck+: { active+: { grpc+: { service: service } } } } } } } } },
                },
                '#http':: d.obj(help="\"HTTP defines the configuration of http health checker.\\nIt's required while the health checker type is HTTP.\""),
                http: {
                  '#expectedResponse':: d.obj(help='"ExpectedResponse defines a list of HTTP expected responses to match."'),
                  expectedResponse: {
                    '#withBinary':: d.fn(help='"Binary payload base64 encoded."', args=[d.arg(name='binary', type=d.T.string)]),
                    withBinary(binary): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { healthCheck+: { active+: { http+: { expectedResponse+: { binary: binary } } } } } } } } } },
                    '#withText':: d.fn(help='"Text payload in plain text."', args=[d.arg(name='text', type=d.T.string)]),
                    withText(text): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { healthCheck+: { active+: { http+: { expectedResponse+: { text: text } } } } } } } } } },
                    '#withType':: d.fn(help='"Type defines the type of the payload."', args=[d.arg(name='type', type=d.T.string)]),
                    withType(type): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { healthCheck+: { active+: { http+: { expectedResponse+: { type: type } } } } } } } } } },
                  },
                  '#withExpectedStatuses':: d.fn(help='"ExpectedStatuses defines a list of HTTP response statuses considered healthy.\\nDefaults to 200 only"', args=[d.arg(name='expectedStatuses', type=d.T.array)]),
                  withExpectedStatuses(expectedStatuses): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { healthCheck+: { active+: { http+: { expectedStatuses: if std.isArray(v=expectedStatuses) then expectedStatuses else [expectedStatuses] } } } } } } } } },
                  '#withExpectedStatusesMixin':: d.fn(help='"ExpectedStatuses defines a list of HTTP response statuses considered healthy.\\nDefaults to 200 only"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='expectedStatuses', type=d.T.array)]),
                  withExpectedStatusesMixin(expectedStatuses): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { healthCheck+: { active+: { http+: { expectedStatuses+: if std.isArray(v=expectedStatuses) then expectedStatuses else [expectedStatuses] } } } } } } } } },
                  '#withMethod':: d.fn(help='"Method defines the HTTP method used for health checking.\\nDefaults to GET"', args=[d.arg(name='method', type=d.T.string)]),
                  withMethod(method): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { healthCheck+: { active+: { http+: { method: method } } } } } } } } },
                  '#withPath':: d.fn(help='"Path defines the HTTP path that will be requested during health checking."', args=[d.arg(name='path', type=d.T.string)]),
                  withPath(path): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { healthCheck+: { active+: { http+: { path: path } } } } } } } } },
                },
                '#tcp':: d.obj(help="\"TCP defines the configuration of tcp health checker.\\nIt's required while the health checker type is TCP.\""),
                tcp: {
                  '#receive':: d.obj(help='"Receive defines the expected response payload."'),
                  receive: {
                    '#withBinary':: d.fn(help='"Binary payload base64 encoded."', args=[d.arg(name='binary', type=d.T.string)]),
                    withBinary(binary): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { healthCheck+: { active+: { tcp+: { receive+: { binary: binary } } } } } } } } } },
                    '#withText':: d.fn(help='"Text payload in plain text."', args=[d.arg(name='text', type=d.T.string)]),
                    withText(text): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { healthCheck+: { active+: { tcp+: { receive+: { text: text } } } } } } } } } },
                    '#withType':: d.fn(help='"Type defines the type of the payload."', args=[d.arg(name='type', type=d.T.string)]),
                    withType(type): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { healthCheck+: { active+: { tcp+: { receive+: { type: type } } } } } } } } } },
                  },
                  '#send':: d.obj(help='"Send defines the request payload."'),
                  send: {
                    '#withBinary':: d.fn(help='"Binary payload base64 encoded."', args=[d.arg(name='binary', type=d.T.string)]),
                    withBinary(binary): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { healthCheck+: { active+: { tcp+: { send+: { binary: binary } } } } } } } } } },
                    '#withText':: d.fn(help='"Text payload in plain text."', args=[d.arg(name='text', type=d.T.string)]),
                    withText(text): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { healthCheck+: { active+: { tcp+: { send+: { text: text } } } } } } } } } },
                    '#withType':: d.fn(help='"Type defines the type of the payload."', args=[d.arg(name='type', type=d.T.string)]),
                    withType(type): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { healthCheck+: { active+: { tcp+: { send+: { type: type } } } } } } } } } },
                  },
                },
                '#withHealthyThreshold':: d.fn(help='"HealthyThreshold defines the number of healthy health checks required before a backend host is marked healthy."', args=[d.arg(name='healthyThreshold', type=d.T.integer)]),
                withHealthyThreshold(healthyThreshold): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { healthCheck+: { active+: { healthyThreshold: healthyThreshold } } } } } } } },
                '#withInterval':: d.fn(help='"Interval defines the time between active health checks."', args=[d.arg(name='interval', type=d.T.string)]),
                withInterval(interval): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { healthCheck+: { active+: { interval: interval } } } } } } } },
                '#withTimeout':: d.fn(help='"Timeout defines the time to wait for a health check response."', args=[d.arg(name='timeout', type=d.T.string)]),
                withTimeout(timeout): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { healthCheck+: { active+: { timeout: timeout } } } } } } } },
                '#withType':: d.fn(help='"Type defines the type of health checker."', args=[d.arg(name='type', type=d.T.string)]),
                withType(type): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { healthCheck+: { active+: { type: type } } } } } } } },
                '#withUnhealthyThreshold':: d.fn(help='"UnhealthyThreshold defines the number of unhealthy health checks required before a backend host is marked unhealthy."', args=[d.arg(name='unhealthyThreshold', type=d.T.integer)]),
                withUnhealthyThreshold(unhealthyThreshold): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { healthCheck+: { active+: { unhealthyThreshold: unhealthyThreshold } } } } } } } },
              },
              '#passive':: d.obj(help='"Passive passive check configuration"'),
              passive: {
                '#withBaseEjectionTime':: d.fn(help='"BaseEjectionTime defines the base duration for which a host will be ejected on consecutive failures."', args=[d.arg(name='baseEjectionTime', type=d.T.string)]),
                withBaseEjectionTime(baseEjectionTime): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { healthCheck+: { passive+: { baseEjectionTime: baseEjectionTime } } } } } } } },
                '#withConsecutive5XxErrors':: d.fn(help='"Consecutive5xxErrors sets the number of consecutive 5xx errors triggering ejection."', args=[d.arg(name='consecutive5XxErrors', type=d.T.integer)]),
                withConsecutive5XxErrors(consecutive5XxErrors): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { healthCheck+: { passive+: { consecutive5XxErrors: consecutive5XxErrors } } } } } } } },
                '#withConsecutiveGatewayErrors':: d.fn(help='"ConsecutiveGatewayErrors sets the number of consecutive gateway errors triggering ejection."', args=[d.arg(name='consecutiveGatewayErrors', type=d.T.integer)]),
                withConsecutiveGatewayErrors(consecutiveGatewayErrors): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { healthCheck+: { passive+: { consecutiveGatewayErrors: consecutiveGatewayErrors } } } } } } } },
                '#withConsecutiveLocalOriginFailures':: d.fn(help='"ConsecutiveLocalOriginFailures sets the number of consecutive local origin failures triggering ejection.\\nParameter takes effect only when split_external_local_origin_errors is set to true."', args=[d.arg(name='consecutiveLocalOriginFailures', type=d.T.integer)]),
                withConsecutiveLocalOriginFailures(consecutiveLocalOriginFailures): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { healthCheck+: { passive+: { consecutiveLocalOriginFailures: consecutiveLocalOriginFailures } } } } } } } },
                '#withInterval':: d.fn(help='"Interval defines the time between passive health checks."', args=[d.arg(name='interval', type=d.T.string)]),
                withInterval(interval): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { healthCheck+: { passive+: { interval: interval } } } } } } } },
                '#withMaxEjectionPercent':: d.fn(help='"MaxEjectionPercent sets the maximum percentage of hosts in a cluster that can be ejected."', args=[d.arg(name='maxEjectionPercent', type=d.T.integer)]),
                withMaxEjectionPercent(maxEjectionPercent): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { healthCheck+: { passive+: { maxEjectionPercent: maxEjectionPercent } } } } } } } },
                '#withSplitExternalLocalOriginErrors':: d.fn(help='"SplitExternalLocalOriginErrors enables splitting of errors between external and local origin."', args=[d.arg(name='splitExternalLocalOriginErrors', type=d.T.boolean)]),
                withSplitExternalLocalOriginErrors(splitExternalLocalOriginErrors): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { healthCheck+: { passive+: { splitExternalLocalOriginErrors: splitExternalLocalOriginErrors } } } } } } } },
              },
              '#withPanicThreshold':: d.fn(help="\"When number of unhealthy endpoints for a backend reaches this threshold\\nEnvoy will disregard health status and balance across all endpoints.\\nIt's designed to prevent a situation in which host failures cascade throughout the cluster\\nas load increases. If not set, the default value is 50%. To disable panic mode, set value to `0`.\"", args=[d.arg(name='panicThreshold', type=d.T.integer)]),
              withPanicThreshold(panicThreshold): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { healthCheck+: { panicThreshold: panicThreshold } } } } } } },
            },
            '#http2':: d.obj(help='"HTTP2 provides HTTP/2 configuration for backend connections."'),
            http2: {
              '#withInitialConnectionWindowSize':: d.fn(help='"InitialConnectionWindowSize sets the initial window size for HTTP/2 connections.\\nIf not set, the default value is 1 MiB."', args=[d.arg(name='initialConnectionWindowSize', type=d.T.any)]),
              withInitialConnectionWindowSize(initialConnectionWindowSize): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { http2+: { initialConnectionWindowSize: initialConnectionWindowSize } } } } } } },
              '#withInitialStreamWindowSize':: d.fn(help='"InitialStreamWindowSize sets the initial window size for HTTP/2 streams.\\nIf not set, the default value is 64 KiB(64*1024)."', args=[d.arg(name='initialStreamWindowSize', type=d.T.any)]),
              withInitialStreamWindowSize(initialStreamWindowSize): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { http2+: { initialStreamWindowSize: initialStreamWindowSize } } } } } } },
              '#withMaxConcurrentStreams':: d.fn(help='"MaxConcurrentStreams sets the maximum number of concurrent streams allowed per connection.\\nIf not set, the default value is 100."', args=[d.arg(name='maxConcurrentStreams', type=d.T.integer)]),
              withMaxConcurrentStreams(maxConcurrentStreams): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { http2+: { maxConcurrentStreams: maxConcurrentStreams } } } } } } },
              '#withOnInvalidMessage':: d.fn(help="\"OnInvalidMessage determines if Envoy will terminate the connection or just the offending stream in the event of HTTP messaging error\\nIt's recommended for L2 Envoy deployments to set this value to TerminateStream.\\nhttps://www.envoyproxy.io/docs/envoy/latest/configuration/best_practices/level_two\\nDefault: TerminateConnection\"", args=[d.arg(name='onInvalidMessage', type=d.T.string)]),
              withOnInvalidMessage(onInvalidMessage): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { http2+: { onInvalidMessage: onInvalidMessage } } } } } } },
            },
            '#loadBalancer':: d.obj(help='"LoadBalancer policy to apply when routing traffic from the gateway to\\nthe backend endpoints. Defaults to `LeastRequest`."'),
            loadBalancer: {
              '#consistentHash':: d.obj(help='"ConsistentHash defines the configuration when the load balancer type is\\nset to ConsistentHash"'),
              consistentHash: {
                '#cookie':: d.obj(help='"Cookie configures the cookie hash policy when the consistent hash type is set to Cookie."'),
                cookie: {
                  '#withAttributes':: d.fn(help='"Additional Attributes to set for the generated cookie."', args=[d.arg(name='attributes', type=d.T.object)]),
                  withAttributes(attributes): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { loadBalancer+: { consistentHash+: { cookie+: { attributes: attributes } } } } } } } } },
                  '#withAttributesMixin':: d.fn(help='"Additional Attributes to set for the generated cookie."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='attributes', type=d.T.object)]),
                  withAttributesMixin(attributes): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { loadBalancer+: { consistentHash+: { cookie+: { attributes+: attributes } } } } } } } } },
                  '#withName':: d.fn(help='"Name of the cookie to hash.\\nIf this cookie does not exist in the request, Envoy will generate a cookie and set\\nthe TTL on the response back to the client based on Layer 4\\nattributes of the backend endpoint, to ensure that these future requests\\ngo to the same backend endpoint. Make sure to set the TTL field for this case."', args=[d.arg(name='name', type=d.T.string)]),
                  withName(name): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { loadBalancer+: { consistentHash+: { cookie+: { name: name } } } } } } } } },
                  '#withTtl':: d.fn(help='"TTL of the generated cookie if the cookie is not present. This value sets the\\nMax-Age attribute value."', args=[d.arg(name='ttl', type=d.T.string)]),
                  withTtl(ttl): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { loadBalancer+: { consistentHash+: { cookie+: { ttl: ttl } } } } } } } } },
                },
                '#header':: d.obj(help='"Header configures the header hash policy when the consistent hash type is set to Header."'),
                header: {
                  '#withName':: d.fn(help='"Name of the header to hash."', args=[d.arg(name='name', type=d.T.string)]),
                  withName(name): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { loadBalancer+: { consistentHash+: { header+: { name: name } } } } } } } } },
                },
                '#withTableSize':: d.fn(help='"The table size for consistent hashing, must be prime number limited to 5000011."', args=[d.arg(name='tableSize', type=d.T.integer)]),
                withTableSize(tableSize): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { loadBalancer+: { consistentHash+: { tableSize: tableSize } } } } } } } },
                '#withType':: d.fn(help='"ConsistentHashType defines the type of input to hash on. Valid Type values are\\n\\"SourceIP\\",\\n\\"Header\\",\\n\\"Cookie\\"."', args=[d.arg(name='type', type=d.T.string)]),
                withType(type): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { loadBalancer+: { consistentHash+: { type: type } } } } } } } },
              },
              '#slowStart':: d.obj(help='"SlowStart defines the configuration related to the slow start load balancer policy.\\nIf set, during slow start window, traffic sent to the newly added hosts will gradually increase.\\nCurrently this is only supported for RoundRobin and LeastRequest load balancers"'),
              slowStart: {
                '#withWindow':: d.fn(help='"Window defines the duration of the warm up period for newly added host.\\nDuring slow start window, traffic sent to the newly added hosts will gradually increase.\\nCurrently only supports linear growth of traffic. For additional details,\\nsee https://www.envoyproxy.io/docs/envoy/latest/api-v3/config/cluster/v3/cluster.proto#config-cluster-v3-cluster-slowstartconfig"', args=[d.arg(name='window', type=d.T.string)]),
                withWindow(window): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { loadBalancer+: { slowStart+: { window: window } } } } } } } },
              },
              '#withType':: d.fn(help='"Type decides the type of Load Balancer policy.\\nValid LoadBalancerType values are\\n\\"ConsistentHash\\",\\n\\"LeastRequest\\",\\n\\"Random\\",\\n\\"RoundRobin\\"."', args=[d.arg(name='type', type=d.T.string)]),
              withType(type): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { loadBalancer+: { type: type } } } } } } },
            },
            '#proxyProtocol':: d.obj(help='"ProxyProtocol enables the Proxy Protocol when communicating with the backend."'),
            proxyProtocol: {
              '#withVersion':: d.fn(help='"Version of ProxyProtol\\nValid ProxyProtocolVersion values are\\n\\"V1\\"\\n\\"V2\\', args=[d.arg(name='version', type=d.T.string)]),
              withVersion(version): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { proxyProtocol+: { version: version } } } } } } },
            },
            '#retry':: d.obj(help='"Retry provides more advanced usage, allowing users to customize the number of retries, retry fallback strategy, and retry triggering conditions.\\nIf not set, retry will be disabled."'),
            retry: {
              '#perRetry':: d.obj(help='"PerRetry is the retry policy to be applied per retry attempt."'),
              perRetry: {
                '#backOff':: d.obj(help='"Backoff is the backoff policy to be applied per retry attempt. gateway uses a fully jittered exponential\\nback-off algorithm for retries. For additional details,\\nsee https://www.envoyproxy.io/docs/envoy/latest/configuration/http/http_filters/router_filter#config-http-filters-router-x-envoy-max-retries"'),
                backOff: {
                  '#withBaseInterval':: d.fn(help='"BaseInterval is the base interval between retries."', args=[d.arg(name='baseInterval', type=d.T.string)]),
                  withBaseInterval(baseInterval): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { retry+: { perRetry+: { backOff+: { baseInterval: baseInterval } } } } } } } } },
                  '#withMaxInterval':: d.fn(help='"MaxInterval is the maximum interval between retries. This parameter is optional, but must be greater than or equal to the base_interval if set.\\nThe default is 10 times the base_interval"', args=[d.arg(name='maxInterval', type=d.T.string)]),
                  withMaxInterval(maxInterval): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { retry+: { perRetry+: { backOff+: { maxInterval: maxInterval } } } } } } } } },
                },
                '#withTimeout':: d.fn(help='"Timeout is the timeout per retry attempt."', args=[d.arg(name='timeout', type=d.T.string)]),
                withTimeout(timeout): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { retry+: { perRetry+: { timeout: timeout } } } } } } } },
              },
              '#retryOn':: d.obj(help='"RetryOn specifies the retry trigger condition.\\n\\nIf not specified, the default is to retry on connect-failure,refused-stream,unavailable,cancelled,retriable-status-codes(503)."'),
              retryOn: {
                '#withHttpStatusCodes':: d.fn(help='"HttpStatusCodes specifies the http status codes to be retried.\\nThe retriable-status-codes trigger must also be configured for these status codes to trigger a retry."', args=[d.arg(name='httpStatusCodes', type=d.T.array)]),
                withHttpStatusCodes(httpStatusCodes): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { retry+: { retryOn+: { httpStatusCodes: if std.isArray(v=httpStatusCodes) then httpStatusCodes else [httpStatusCodes] } } } } } } } },
                '#withHttpStatusCodesMixin':: d.fn(help='"HttpStatusCodes specifies the http status codes to be retried.\\nThe retriable-status-codes trigger must also be configured for these status codes to trigger a retry."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='httpStatusCodes', type=d.T.array)]),
                withHttpStatusCodesMixin(httpStatusCodes): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { retry+: { retryOn+: { httpStatusCodes+: if std.isArray(v=httpStatusCodes) then httpStatusCodes else [httpStatusCodes] } } } } } } } },
                '#withTriggers':: d.fn(help='"Triggers specifies the retry trigger condition(Http/Grpc)."', args=[d.arg(name='triggers', type=d.T.array)]),
                withTriggers(triggers): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { retry+: { retryOn+: { triggers: if std.isArray(v=triggers) then triggers else [triggers] } } } } } } } },
                '#withTriggersMixin':: d.fn(help='"Triggers specifies the retry trigger condition(Http/Grpc)."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='triggers', type=d.T.array)]),
                withTriggersMixin(triggers): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { retry+: { retryOn+: { triggers+: if std.isArray(v=triggers) then triggers else [triggers] } } } } } } } },
              },
              '#withNumRetries':: d.fn(help='"NumRetries is the number of retries to be attempted. Defaults to 2."', args=[d.arg(name='numRetries', type=d.T.integer)]),
              withNumRetries(numRetries): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { retry+: { numRetries: numRetries } } } } } } },
            },
            '#tcpKeepalive':: d.obj(help='"TcpKeepalive settings associated with the upstream client connection.\\nDisabled by default."'),
            tcpKeepalive: {
              '#withIdleTime':: d.fn(help='"The duration a connection needs to be idle before keep-alive\\nprobes start being sent.\\nThe duration format is\\nDefaults to `7200s`."', args=[d.arg(name='idleTime', type=d.T.string)]),
              withIdleTime(idleTime): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { tcpKeepalive+: { idleTime: idleTime } } } } } } },
              '#withInterval':: d.fn(help='"The duration between keep-alive probes.\\nDefaults to `75s`."', args=[d.arg(name='interval', type=d.T.string)]),
              withInterval(interval): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { tcpKeepalive+: { interval: interval } } } } } } },
              '#withProbes':: d.fn(help='"The total number of unacknowledged probes to send before deciding\\nthe connection is dead.\\nDefaults to 9."', args=[d.arg(name='probes', type=d.T.integer)]),
              withProbes(probes): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { tcpKeepalive+: { probes: probes } } } } } } },
            },
            '#timeout':: d.obj(help='"Timeout settings for the backend connections."'),
            timeout: {
              '#http':: d.obj(help='"Timeout settings for HTTP."'),
              http: {
                '#withConnectionIdleTimeout':: d.fn(help='"The idle timeout for an HTTP connection. Idle time is defined as a period in which there are no active requests in the connection.\\nDefault: 1 hour."', args=[d.arg(name='connectionIdleTimeout', type=d.T.string)]),
                withConnectionIdleTimeout(connectionIdleTimeout): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { timeout+: { http+: { connectionIdleTimeout: connectionIdleTimeout } } } } } } } },
                '#withMaxConnectionDuration':: d.fn(help='"The maximum duration of an HTTP connection.\\nDefault: unlimited."', args=[d.arg(name='maxConnectionDuration', type=d.T.string)]),
                withMaxConnectionDuration(maxConnectionDuration): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { timeout+: { http+: { maxConnectionDuration: maxConnectionDuration } } } } } } } },
                '#withRequestTimeout':: d.fn(help='"RequestTimeout is the time until which entire response is received from the upstream."', args=[d.arg(name='requestTimeout', type=d.T.string)]),
                withRequestTimeout(requestTimeout): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { timeout+: { http+: { requestTimeout: requestTimeout } } } } } } } },
              },
              '#tcp':: d.obj(help='"Timeout settings for TCP."'),
              tcp: {
                '#withConnectTimeout':: d.fn(help='"The timeout for network connection establishment, including TCP and TLS handshakes.\\nDefault: 10 seconds."', args=[d.arg(name='connectTimeout', type=d.T.string)]),
                withConnectTimeout(connectTimeout): { spec+: { telemetry+: { tracing+: { provider+: { backendSettings+: { timeout+: { tcp+: { connectTimeout: connectTimeout } } } } } } } },
              },
            },
          },
          '#withBackendRefs':: d.fn(help='"BackendRefs references a Kubernetes object that represents the\\nbackend server to which the authorization request will be sent."', args=[d.arg(name='backendRefs', type=d.T.array)]),
          withBackendRefs(backendRefs): { spec+: { telemetry+: { tracing+: { provider+: { backendRefs: if std.isArray(v=backendRefs) then backendRefs else [backendRefs] } } } } },
          '#withBackendRefsMixin':: d.fn(help='"BackendRefs references a Kubernetes object that represents the\\nbackend server to which the authorization request will be sent."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='backendRefs', type=d.T.array)]),
          withBackendRefsMixin(backendRefs): { spec+: { telemetry+: { tracing+: { provider+: { backendRefs+: if std.isArray(v=backendRefs) then backendRefs else [backendRefs] } } } } },
          '#withHost':: d.fn(help='"Host define the provider service hostname.\\nDeprecated: Use BackendRefs instead."', args=[d.arg(name='host', type=d.T.string)]),
          withHost(host): { spec+: { telemetry+: { tracing+: { provider+: { host: host } } } } },
          '#withPort':: d.fn(help='"Port defines the port the provider service is exposed on.\\nDeprecated: Use BackendRefs instead."', args=[d.arg(name='port', type=d.T.integer)]),
          withPort(port): { spec+: { telemetry+: { tracing+: { provider+: { port: port } } } } },
          '#withType':: d.fn(help='"Type defines the tracing provider type."', args=[d.arg(name='type', type=d.T.string)]),
          withType(type): { spec+: { telemetry+: { tracing+: { provider+: { type: type } } } } },
          '#zipkin':: d.obj(help='"Zipkin defines the Zipkin tracing provider configuration"'),
          zipkin: {
            '#withDisableSharedSpanContext':: d.fn(help='"DisableSharedSpanContext determines whether the default Envoy behaviour of\\nclient and server spans sharing the same span context should be disabled."', args=[d.arg(name='disableSharedSpanContext', type=d.T.boolean)]),
            withDisableSharedSpanContext(disableSharedSpanContext): { spec+: { telemetry+: { tracing+: { provider+: { zipkin+: { disableSharedSpanContext: disableSharedSpanContext } } } } } },
            '#withEnable128BitTraceId':: d.fn(help='"Enable128BitTraceID determines whether a 128bit trace id will be used\\nwhen creating a new trace instance. If set to false, a 64bit trace\\nid will be used."', args=[d.arg(name='enable128BitTraceId', type=d.T.boolean)]),
            withEnable128BitTraceId(enable128BitTraceId): { spec+: { telemetry+: { tracing+: { provider+: { zipkin+: { enable128BitTraceId: enable128BitTraceId } } } } } },
          },
        },
        '#samplingFraction':: d.obj(help='"SamplingFraction represents the fraction of requests that should be\\nselected for tracing if no prior sampling decision has been made.\\n\\nOnly one of SamplingRate or SamplingFraction may be specified.\\nIf neither field is specified, all requests will be sampled."'),
        samplingFraction: {
          '#withDenominator':: d.fn(help='', args=[d.arg(name='denominator', type=d.T.integer)]),
          withDenominator(denominator): { spec+: { telemetry+: { tracing+: { samplingFraction+: { denominator: denominator } } } } },
          '#withNumerator':: d.fn(help='', args=[d.arg(name='numerator', type=d.T.integer)]),
          withNumerator(numerator): { spec+: { telemetry+: { tracing+: { samplingFraction+: { numerator: numerator } } } } },
        },
        '#withCustomTags':: d.fn(help='"CustomTags defines the custom tags to add to each span.\\nIf provider is kubernetes, pod name and namespace are added by default."', args=[d.arg(name='customTags', type=d.T.object)]),
        withCustomTags(customTags): { spec+: { telemetry+: { tracing+: { customTags: customTags } } } },
        '#withCustomTagsMixin':: d.fn(help='"CustomTags defines the custom tags to add to each span.\\nIf provider is kubernetes, pod name and namespace are added by default."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='customTags', type=d.T.object)]),
        withCustomTagsMixin(customTags): { spec+: { telemetry+: { tracing+: { customTags+: customTags } } } },
        '#withSamplingRate':: d.fn(help='"SamplingRate controls the rate at which traffic will be\\nselected for tracing if no prior sampling decision has been made.\\nDefaults to 100, valid values [0-100]. 100 indicates 100% sampling.\\n\\nOnly one of SamplingRate or SamplingFraction may be specified.\\nIf neither field is specified, all requests will be sampled."', args=[d.arg(name='samplingRate', type=d.T.integer)]),
        withSamplingRate(samplingRate): { spec+: { telemetry+: { tracing+: { samplingRate: samplingRate } } } },
      },
    },
    '#withConcurrency':: d.fn(help='"Concurrency defines the number of worker threads to run. If unset, it defaults to\\nthe number of cpuset threads on the platform."', args=[d.arg(name='concurrency', type=d.T.integer)]),
    withConcurrency(concurrency): { spec+: { concurrency: concurrency } },
    '#withExtraArgs':: d.fn(help='"ExtraArgs defines additional command line options that are provided to Envoy.\\nMore info: https://www.envoyproxy.io/docs/envoy/latest/operations/cli#command-line-options\\nNote: some command line options are used internally(e.g. --log-level) so they cannot be provided here."', args=[d.arg(name='extraArgs', type=d.T.array)]),
    withExtraArgs(extraArgs): { spec+: { extraArgs: if std.isArray(v=extraArgs) then extraArgs else [extraArgs] } },
    '#withExtraArgsMixin':: d.fn(help='"ExtraArgs defines additional command line options that are provided to Envoy.\\nMore info: https://www.envoyproxy.io/docs/envoy/latest/operations/cli#command-line-options\\nNote: some command line options are used internally(e.g. --log-level) so they cannot be provided here."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='extraArgs', type=d.T.array)]),
    withExtraArgsMixin(extraArgs): { spec+: { extraArgs+: if std.isArray(v=extraArgs) then extraArgs else [extraArgs] } },
    '#withFilterOrder':: d.fn(help="\"FilterOrder defines the order of filters in the Envoy proxy's HTTP filter chain.\\nThe FilterPosition in the list will be applied in the order they are defined.\\nIf unspecified, the default filter order is applied.\\nDefault filter order is:\\n\\n- envoy.filters.http.health_check\\n\\n- envoy.filters.http.fault\\n\\n- envoy.filters.http.cors\\n\\n- envoy.filters.http.ext_authz\\n\\n- envoy.filters.http.basic_auth\\n\\n- envoy.filters.http.oauth2\\n\\n- envoy.filters.http.jwt_authn\\n\\n- envoy.filters.http.stateful_session\\n\\n- envoy.filters.http.lua\\n\\n- envoy.filters.http.ext_proc\\n\\n- envoy.filters.http.wasm\\n\\n- envoy.filters.http.rbac\\n\\n- envoy.filters.http.local_ratelimit\\n\\n- envoy.filters.http.ratelimit\\n\\n- envoy.filters.http.custom_response\\n\\n- envoy.filters.http.router\\n\\nNote: \\\"envoy.filters.http.router\\\" cannot be reordered, it's always the last filter in the chain.\"", args=[d.arg(name='filterOrder', type=d.T.array)]),
    withFilterOrder(filterOrder): { spec+: { filterOrder: if std.isArray(v=filterOrder) then filterOrder else [filterOrder] } },
    '#withFilterOrderMixin':: d.fn(help="\"FilterOrder defines the order of filters in the Envoy proxy's HTTP filter chain.\\nThe FilterPosition in the list will be applied in the order they are defined.\\nIf unspecified, the default filter order is applied.\\nDefault filter order is:\\n\\n- envoy.filters.http.health_check\\n\\n- envoy.filters.http.fault\\n\\n- envoy.filters.http.cors\\n\\n- envoy.filters.http.ext_authz\\n\\n- envoy.filters.http.basic_auth\\n\\n- envoy.filters.http.oauth2\\n\\n- envoy.filters.http.jwt_authn\\n\\n- envoy.filters.http.stateful_session\\n\\n- envoy.filters.http.lua\\n\\n- envoy.filters.http.ext_proc\\n\\n- envoy.filters.http.wasm\\n\\n- envoy.filters.http.rbac\\n\\n- envoy.filters.http.local_ratelimit\\n\\n- envoy.filters.http.ratelimit\\n\\n- envoy.filters.http.custom_response\\n\\n- envoy.filters.http.router\\n\\nNote: \\\"envoy.filters.http.router\\\" cannot be reordered, it's always the last filter in the chain.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='filterOrder', type=d.T.array)]),
    withFilterOrderMixin(filterOrder): { spec+: { filterOrder+: if std.isArray(v=filterOrder) then filterOrder else [filterOrder] } },
    '#withIpFamily':: d.fn(help='"IPFamily specifies the IP family for the EnvoyProxy fleet.\\nThis setting only affects the Gateway listener port and does not impact\\nother aspects of the Envoy proxy configuration.\\nIf not specified, the system will operate as follows:\\n- It defaults to IPv4 only.\\n- IPv6 and dual-stack environments are not supported in this default configuration.\\nNote: To enable IPv6 or dual-stack functionality, explicit configuration is required."', args=[d.arg(name='ipFamily', type=d.T.string)]),
    withIpFamily(ipFamily): { spec+: { ipFamily: ipFamily } },
    '#withMergeGateways':: d.fn(help='"MergeGateways defines if Gateway resources should be merged onto the same Envoy Proxy Infrastructure.\\nSetting this field to true would merge all Gateway Listeners under the parent Gateway Class.\\nThis means that the port, protocol and hostname tuple must be unique for every listener.\\nIf a duplicate listener is detected, the newer listener (based on timestamp) will be rejected and its status will be updated with a \\"Accepted=False\\" condition."', args=[d.arg(name='mergeGateways', type=d.T.boolean)]),
    withMergeGateways(mergeGateways): { spec+: { mergeGateways: mergeGateways } },
    '#withPreserveRouteOrder':: d.fn(help="\"PreserveRouteOrder determines if the order of matching for HTTPRoutes is determined by Gateway-API\\nspecification (https://gateway-api.sigs.k8s.io/reference/spec/#gateway.networking.k8s.io/v1.HTTPRouteRule)\\nor preserves the order defined by users in the HTTPRoute's HTTPRouteRule list.\\nDefault: False\"", args=[d.arg(name='preserveRouteOrder', type=d.T.boolean)]),
    withPreserveRouteOrder(preserveRouteOrder): { spec+: { preserveRouteOrder: preserveRouteOrder } },
    '#withRoutingType':: d.fn(help='"RoutingType can be set to \\"Service\\" to use the Service Cluster IP for routing to the backend,\\nor it can be set to \\"Endpoint\\" to use Endpoint routing. The default is \\"Endpoint\\"."', args=[d.arg(name='routingType', type=d.T.string)]),
    withRoutingType(routingType): { spec+: { routingType: routingType } },
  },
  '#mixin': 'ignore',
  mixin: self,
}
